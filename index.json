[{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 A \u0026ldquo;How to cite\u0026rdquo;/”Cite this” button for GitHub - HP1-CW2CC\nHackday Idea Proposer Stephan Druskat - stephan.druskat@dlr.de\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Software citation\nProblem To push general uptake of good practices of software citation - and the citation of software in general - it must be maximally easy for users of a software to access the relevant software citation metadata. A lot of research software is developed openly, and available on GitHub. But there is no really easy way to retrieve citation metadata through the GitHub UI directly, even if the relevant metadata is in the repository in metadata files (in a CITATION.cff or codemeta.json file). Not having easily consumable citation metadata for software impedes the progress of software citation.\nSolution Do you know the “Unpaywall” browser extension button (unpaywall.org/products/extension) that helps you find an open access version of a paper? Let’s build this for GitHub, presenting the software citation metadata for a repository in a reusable manner! This should be developed openly, so that it can potentially be extended to work with different metadata formats (CITATION.cff, codemeta.json), and different output formats (e.g., BibTeX, RIS, etc.). It could be a browser extension or - taking a good aim at the bonus prizes - a bookmarklet.\nDiagrams / Illustrations ","permalink":"https://robintw.github.io/CW-ideas/cw19-citethis/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 A \u0026ldquo;How to cite\u0026rdquo;/”Cite this” button for GitHub - HP1-CW2CC\nHackday Idea Proposer Stephan Druskat - stephan.druskat@dlr.de\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Software citation\nProblem To push general uptake of good practices of software citation - and the citation of software in general - it must be maximally easy for users of a software to access the relevant software citation metadata.","title":"A \"How to cite\"/”Cite this” button for GitHub"},{"content":"CW20 - 2020-03-31 to 2020-04-02 Idea 7 - CI7-CW20\nAdding Behaviour Driven Development to Exploratory Research Notebooks\nParticipants Jon Massey\nBen Krikler\nAnastasis Georgoulas\nMatthew Bluteau\nSteve Crouch\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all the hint text (grey, Arial 11, italic) once you no longer need it.\nDiscussion\n Jon: Trying to do SE after the fact - behaviour specs. Way to apply this instead of documentation after the fact? Pitch from SSI fellowship - taking industrial practices to academia  Anastasis: Intended behaviour of software not always known beforehand. Unsure what will work, analyses that will be done, etc. Possible to adapt it to this? At some point you transition from exploratory base to doing things properly. Understanding that transition, test from an earlier stage? How to test notebook Also get situations where code developed for ourselves gets used and adopted by others unexpectedly. Perhaps always assume this will happen - e.g. just always do TDD, or something similar. Ways to write test specs at this transitionary time? Steve: capturing requirements during exploratory phase critical for transition to more mature phase of project; “Just in Time Specification”; there is value in “faking” development/design good practices   Ben: bringing Agile/Lean principles into the process of exploratory research  Jon: Cucumber integration with Jupyter notebooks; specify what the behaviour of that notebook should be, and then actually be able to use this to test the behaviour later on Perhaps also have a linter for checking validity of Cucumber/Notebook descriptions MoSCoW - MH - 60%, SH - 20%, CH - 20%. Perhaps something here to fit behaviour back to requirements? Use BDD markups after the fact (e.g. JIT) to describe behaviour (at the point where you wish to go beyond exploratory development) Behave (Python) package: BDD descriptions in code/notebooks - explore this repository and add to it? https://pypi.org/project/behave/   Add template to a notebook with a pre-populated structure, e.g. start notebook, starts with that templated structure  Context / Research Domain General Research Software Development, and how to capture the behaviour of software\nProblem As sometimes happens in academia, that software you wrote just for yourself or to explore an idea is suddenly useful for others. Often, this means the original software form has to be reimplemented, sometimes quite drastically (e.g. refactoring a Jupyter Notebook, or reimplementing one to standalone Python scripts). What can we do to capture a software\u0026rsquo;s behaviour so it can be tested against if/when it transitions to production, and needs to be refactored/reimplemented?\nSolution Develop a way to apply Behaviour-Driven Development in the context of exploratory research software development:\n How has it been applied elsewhere? When and for what reasons has it been successful? Given that Jupyter Notebooks are a common tool used for such exploratory software development, determine how we can make best use of existing BDD tools in this environment. For example, integration of Gherkin BDD descriptions throughout a notebook to describe its behaviour Develop tool support for BDD within notebooks, e.g. automatic generation of tests based on docstrings that encapsulate BDD in a notebook (using doctest), generation of a skeleton BDD structure within a notebook for filling in behavioural details as the notebook develops  Diagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n Room 7 FTW!\n","permalink":"https://robintw.github.io/CW-ideas/cw20-behaviour-driven-development/","summary":"CW20 - 2020-03-31 to 2020-04-02 Idea 7 - CI7-CW20\nAdding Behaviour Driven Development to Exploratory Research Notebooks\nParticipants Jon Massey\nBen Krikler\nAnastasis Georgoulas\nMatthew Bluteau\nSteve Crouch\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4.","title":"Adding Behaviour Driven Development to Exploratory Research Notebooks"},{"content":"Collaborations Workshop 2018 - 2018-03-26\nAligning the Citation File Format and CodeMeta -\nHP3-CW18\nHackday Idea Proposer\nStephan Druskat - stephan.druskat@hu-berlin.de\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain\nThe domain is: Software Citation Implementations\nProblem\nThe Citation File Format (CFF, https://citation-file-format.github.io) is a human-writable and -readable, machine-readable format for the provision of software citation metadata.\nAs such, it should be aligned with the evolving standard for providing *general* software metadata, CodeMeta (https://codemeta.github.io). This is because:\n Resources in the small software citation implementation community sholdn\u0026rsquo;t be stretched across more projects than absolutely necessary. CodeMeta is enjoying upstream uptake by, e.g., repositories and is likely to gain more* support, a second format would not and *should* not aim to replicate those efforts. It seems as if CFF could be a valid and accessible way for *end users* to provide such* metadata and has enjoyed some uptake, but should also be usable as a source format for CodeMeta in a way that ensures no information is lost.  Solution\n This activity should ideally streamline CFF and CodeMeta keys to lower the barrier for completely automatic YAML-JSON conversion to and fro. It should be investigated whether CFF can be converted to CodeMeta without losing information (e.g., linked data) Can CFF YAML represent linked data without adding format overhead (such as enforcing key namespaces or similar) Can CFF be used for:  linkage (req) credit (req) discovery (req) reproducibility provenance   This activity can also be used to figure out if “tooling” is the omnipotent answer for issues in this space, and whether tooling can be developed to enforce best practices (e.g., from the Software Citation Principles)  Diagrams / Illustrations\nYou can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw18-cff-codemeta/","summary":"Collaborations Workshop 2018 - 2018-03-26\nAligning the Citation File Format and CodeMeta -\nHP3-CW18\nHackday Idea Proposer\nStephan Druskat - stephan.druskat@hu-berlin.de\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain\nThe domain is: Software Citation Implementations\nProblem\nThe Citation File Format (CFF, https://citation-file-format.github.io) is a human-writable and -readable, machine-readable format for the provision of software citation metadata.\nAs such, it should be aligned with the evolving standard for providing *general* software metadata, CodeMeta (https://codemeta.","title":"Aligning the Citation File Format and CodeMeta"},{"content":"Collaborations Workshop 2018 - 2018-03-26\nAutomated Network Map construction -\nHP13-CW18 Hackday Idea Proposer\nDiana Suleimenova - diana.n.suleimenova@gmail.com\nThis document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain\nPlease describe the context or research domain to which the problem applies\nAn idea of constructing an automated network maps initiated from refugee simulation context. However, this can be useful for other scenarios where researchers or practitioners have multiple locations and require to know how these locations are connected and their distances represented visually. There are also other domains that use simulations for animal and bird migrations, as well as vehicle movements that require visual representations (i.e. network maps).\nProblem\nPrediction of refugee movements requires network maps. As, we have several locations, and identifying their connections, distances and constructing or visualising these links are time consuming. Hence, manually constructed network maps are proven to be inefficient at this moment.\nSolution\nAutomated network map construction can be a tool (or website) to automate detection of locations, their route connections and distances. Hence, it can use a dataset (e.g. locations.csv) with location names and GPS coordinates (in csv format)\nand construct network map by following the steps below:\n Identify locations Indicate these location and provide name Connect locations Provide distances between locations Generate a file named routes.csv  Diagrams / Illustrations\nNetwork map for Burundi\n","permalink":"https://robintw.github.io/CW-ideas/cw18-autonetworkmapconstr/","summary":"Collaborations Workshop 2018 - 2018-03-26\nAutomated Network Map construction -\nHP13-CW18 Hackday Idea Proposer\nDiana Suleimenova - diana.n.suleimenova@gmail.com\nThis document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain\nPlease describe the context or research domain to which the problem applies\nAn idea of constructing an automated network maps initiated from refugee simulation context. However, this can be useful for other scenarios where researchers or practitioners have multiple locations and require to know how these locations are connected and their distances represented visually.","title":"Automated Network Map construction"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Automating Screenshots for Documentation - HP4-CW2CC\nHackday Idea Proposer Colin Sauze - cos@aber.ac.uk\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nAny application with a graphical or web interface.\nProblem Keeping documentation and code in sync with each other automatically. Informing developers when the visual look of their application changes without them realising.\nSolution Write a script using Selenium (https://www.seleniumhq.org/) to produce each screenshot. The script will specify the actions required to get the GUI in the right state for the screenshot and which part of the screen to capture.\nWhen building the software these scripts are re-run and update all the screenshots. Where the screenshot differs from its previous version the developer is alerted and differences are highlighted.\nSelenium only works with web browsers (I think), need to find a similar tool that works with general GUIs. Suggestions welcome.\nDiagrams / Illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw19-automatingscreenshots/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Automating Screenshots for Documentation - HP4-CW2CC\nHackday Idea Proposer Colin Sauze - cos@aber.ac.uk\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nAny application with a graphical or web interface.\nProblem Keeping documentation and code in sync with each other automatically.","title":"Automating Screenshots for Documentation"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 0 - CI15-CW2CC\nReporter Emmy Tsang - e.tsang@elifesciences.org\nParticipants Richard Gilham - richard.gilham@metoffice.gov.uk\nEmmy Tsang - e.tsang@elifesciences.org\nAnna Krystalli - a.krystalli@sheffield.ac.uk\nDavid Gillespie - d.gillespie@mmu.ac.uk\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all the hint text once you no longer need it.\nContext / Research Domain There are comprehensive, large sets of guidelines on software engineering/research data best practices, but these are often difficult to digest and not easy to act upon. There is a need for the development of an easy-to-use tool that can help users to distil/digest these, with the goal of producing a universal, clear set of guidelines that are easy to adopt (in a checklist format?).\nRelated resources:\n Guideline to using Github issues: https://guides.github.com/features/issues/ DLR software engineering guidelines: https://zenodo.org/record/1344612#.XKNELOtKifV The Turing Way - https://github.com/alan-turing-institute/the-turing-way Isber best practices for repositories: ISBER BEST PRACTICES FOR REPOSITORIEShttps://www.isber.org/page/BPR  Problem A lack of accessible generic tools that distill actionable guidance on appropriate practice to support open reproducible research - what is the appropriate practice for my software/research/dataset? With the aim to facilitate reuse\nSolution A scalable library of customisable handrail checklists of the appropriate practices for software/research/data with infrastructure for domain/task specific variations. This will be backed up by decision-aids to help researchers find what is right for them.\nNot every piece of work needs every facet of quality management. A 2-line script has a very different risk profile to, say, a million-line operational weather model. Getting the right amount of quality management and scaling it as your work progresses helps strike the right balance between rigour and innovation.\nMany tools exist to help people on their journey, but many different combinations may be used to achieve the desired effect. These checklists will be tool-agnostic, but with signposting to tool-specific solutions. This decouples the decision about the required quality management, the risk assessment, from the tools that are required. Decoupling the risk assessment from the tool choice provides clarity in the journey towards open and reproducible research. The two-step approach also makes it easier for researchers to get on board with the process rather than being overwhelmed by something that feels like a barrier to getting things done.\nExplanation of the solution to the problem you have identified\nDiagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nATTRIBUTION: GitHub [MIT (http://opensource.org/licenses/mit-license.php) or OFL (http://scripts.sil.org/cms/scripts/page.php?item_id=OFL_web)]\n","permalink":"https://robintw.github.io/CW-ideas/cw19-repro-checklist/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 0 - CI15-CW2CC\nReporter Emmy Tsang - e.tsang@elifesciences.org\nParticipants Richard Gilham - richard.gilham@metoffice.gov.uk\nEmmy Tsang - e.tsang@elifesciences.org\nAnna Krystalli - a.krystalli@sheffield.ac.uk\nDavid Gillespie - d.gillespie@mmu.ac.uk\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two).","title":"Best Practice Checklist"},{"content":"CW21 - 2021-03-30 Noodle - CI14-CW21\nParticipants Marion Weinzierl (Durham University)\nSam Harrison (UK Centre for Ecology \u0026amp; Hydrology)\nArielle Bennett (Alan Turing Institute, London)\nSteve Crouch (SSI, Southampton)\nMark Turner (Durham University)\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all of this hint text (Arial, italic, grey, size 11) once you no longer need it.\nNotes  Marion: How to work with and take forward legacy code? Is there a checklist to make use of for this? Or develop an automatic script to parse the repo and tell me how to improve it?  https://software.ac.uk/sites/default/files/SSI-SoftwareEvaluationCriteria.pdf - SSI\u0026rsquo;s software evaluation criteria https://github.com/RSE2-D2/RSE2-D2 https://github.com/RSE2-D2/RSE2-D2/issues/33 https://fair-software.eu/ https://bestpractices.coreinfrastructure.org/en - https://bestpractices.coreinfrastructure.org/en/criteria/0 From last years Hack Day SiccarPoint/how_wrong_is_the_code: Repo for CollabW20 hack day - how wrong is the research code base? (github.com)   Sam: training - how to on-board traditional academics who know nothing about software sustainability?  Marion: last year - how to sell the values of software practices to PIs - link to it https://software.ac.uk/blog/2020-06-10-how-do-we-persuade-funders-support-software-maintenance https://software.ac.uk/blog/2020-05-27-how-engage-research-group-leaders-sustainable-software-practices https://software.ac.uk/blog/2020-05-25-maintaining-your-legacy-tips-making-legacy-code-sustainable https://software.ac.uk/blog/2020-05-22-carrot-and-stick-approaches-promoting-research-software-community https://software.ac.uk/blog/2020-05-19-incentives-good-research-software-practices Etc… This problem seems to come up again and again!   Mark: a tool that indicates you are building up technical debt - a plugin/analysis of repo. Technical debt - builds up over time when you work on code, focusing on features not maintenance. Easy metrics to pick up A lot of communities looking into these issues, but why don\u0026rsquo;t we do it? FAIR, Turing, etc. HPC/RSE communities, Carpentries, but it\u0026rsquo;s not really happening. Is this a communication issue - a bubble? Level of communication needs to be improved, somehow incentivise and lower the barrier to entry for doing these things. Do we need to collect these things? Same idea coming up again and again Resource list somewhere? Another kind of event? Key difficulty with training e.g. PIs - availability. How to convince them? With PIs, it comes down to making them understand the importance of this, adjust expectations. Journals are increasingly requiring researchers to conform to better code practices.  Bursting the bubble: Teaching PIs the value of good code Context / Research Domain Issues with poor coding practices are typically tackled via community interest groups or training sessions (for example Carpentries training), which introduces the skills and collaboration needed to write code well. Training is also often aimed at early career researchers such as PhD students or postdocs and has been adapted to suit the needs of different scientific domains from astrophysics to zoology.\nHowever, developing an understanding of good and bad coding practices, and the benefits and risks of each, also needs to be promoted in more established researchers, such as PIs. At this career stage, their influence on the research culture and therefore coding practices of their groups and labs is significant. PIs need to be onboard with promoting good coding if the training aimed at ECRs is to stick and translate into long term culture change, right across the research domains.\nOf course, underpinning the problem is the continued use of incentives in the academic system in particular that do not reward good coding practices directly and instead focus on outputs such as papers, where code quality is of secondary importance.\nProblem\nIn our discussion there were a number of issues around engaging PIs and researchers in good software practices and applying guidelines that came up, as well as the problem of legacy code and how to improve it in an automated or at least structured way. Diving deeper into this discussions, and doing a quick online research, it turns out that these issues have been discussed (and blogged about) repeatedly in previous Collaboration Workshops, and elsewhere. Why does it still seem that no progress has been made? Why does having resources like the Turing Way Handbook, and initiatives like FAIR for software seem not to have a groundbreaking impact in research? It seems that there is an issue in both communication between communities and initiatives, and an issue in incentives and time commitment from PIs and researchers. How can we burst these bubbles and improve the communication? How can we make it easy for everyone to find the resources on good software practices that they need, and to apply them?\nSolution The key to overcoming many of these problems is gaining an appreciation of the promises and the pitfalls of software development at the level of the PI. Whilst a lot of research, tools, practices and guidance exists, we advocate that what is also needed is concrete evidence of projects that have succeeded and failed that speaks strongly to PIs understanding and interests.\nBy reviewing the existing resources and research software projects and highlighting the practical causes and criteria behind their success or failure in terms of practices, PIs may then relate these to activities within their own projects, and project potential future outcomes for those projects. From this understanding, the idea is that PIs are then incentivised to increase time and effort for practices and activities that promote better practice.\nDiagrams / Illustrations Low internal quality might seem to ‘do the job’ for short-term projects where time is of the essence. Sustainable development efforts benefit from slower development cycles that encapsulate more refactoring and greater attention to design decisions.\nLicence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-bursting-the-bubble/","summary":"CW21 - 2021-03-30 Noodle - CI14-CW21\nParticipants Marion Weinzierl (Durham University)\nSam Harrison (UK Centre for Ecology \u0026amp; Hydrology)\nArielle Bennett (Alan Turing Institute, London)\nSteve Crouch (SSI, Southampton)\nMark Turner (Durham University)\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4.","title":"Bursting the Bubble: Teaching PIs the value of good code"},{"content":"","permalink":"https://robintw.github.io/CW-ideas/bytype/","summary":"","title":"By Type"},{"content":"","permalink":"https://robintw.github.io/CW-ideas/byyear/","summary":"","title":"By Year"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 CarpenTREE - DSR12-CW2CC\nReporter Arshad Emmambux - a.emmambux@soton.ac.uk\nParticipants Patricia Herterich - p.s.herterich@bham.ac.uk\nVictor Koppejan - victorkoppejan@gmail.com\nLouise Bowler - lbowler@turing.ac.uk\nNiall Beard\nLink to initial proposal https://docs.google.com/document/d/1CQv-LJejF3pcXIFz0ve1JGMLtUperfxClbTEJbO5VYA/edit\nLink to final presentation https://docs.google.com/presentation/d/1df3kYNx7UquQLJl1x8WnCfnEzQfyYrtsUhdUGAFsaY0/edit?usp=sharing\nProblem statement Navigating software /data carpentry lessons isn’t straightforward, it’s not always clear where to go next and how much knowledge you need to start a lesson. Not many people have a complete overview of the carpentry lessons.\nAs a carpentry instructor,\nI want to create a customised lesson for a specific outcome\nIn order to deliver efficient and tailored training.\nAs a carpentries student\nI want to know which lessons would be a good follow up to what I just learned\nIn order to get the most out of the software carpentries class and material.\nEnvisioned solution / Scope We envision a tree/visualisation that helps instructors design better sessions and help newcomers design their pathway to gain the skills they want step by step. It will provide and easy overview of the content covered in carpentry lessons.\nAvailable resources Prerequisites in Carpentry lessons seem to be tagged with {: .prereq} in the index file e.g. https://github.com/swcarpentry/hg-novice/blob/gh-pages/index.md\nNot all lessons have a wrap - up - could the reference overview help? - Niall, Louise\nIf we find a reference to those in any of the more advanced, we can link those lessons.\n We could tag those lessons for ourselves and map them (PH to do that manually for one advanced lesson - and maybe use Niall’s tool to visualise) Look at the different pathway within the software / data carpentry lessons, e.g Ecology, Geospatial, Social Sciences, etc… and check for common lessons and differences. (AE to check for these)  Scrape all datasets and see where they are used Scrape for R or python libraries used Scrape all bold words in the glossary sections Scrape instructor guides  Team skills Python (except Patricia)\nC++ (Vic, Louise)\nJavascript (Niall, Louise (mostly in the context of Angular/TypeScript))\nGit (All)\nData visualisation - d3 and vega-lite (Louise - but only a couple of months experience on each)\nR (Arshad)\nRoadmap Evening: create a list of all the URLs of reference files comma separated\nOne for data carpentry, one for software carpentry?\n9-10\nLoiuse - Niall -\u0026gt; start scraping\nPH + VWK to attempt a manual mapping starting from an advanced lesson\nArshad -\u0026gt; Work on pathways (mainly data carpentry?) similarities and differences in dc curriculum\n10-10.30 Document what we have done in step one and discuss next steps\n10.30 - lunch\nSetup a small visualization sample in Tess\nContinue scraping\nWrangle some data if needed\nWork on documentation / presentation framework\nGates / Milestones Any GitHub repos:\nhttps://github.com/vwkoppejan/carpenTREE\nDo a final issue to the carpentries summarizing what we’ve done and suggestions for them to take this further.\nThink about how this could be used for other lesson material that’s not carpentries\nFuture works Branching out the branches of the TREE further\nTranslation of the carpentry lessons into multiple languages.\nCreate a dashboard filter that you could filter for lesson time etc. (shiny for R Studio)\n Advanced: add filters tags to the tree to highlight discipline specific sessions\nAdvanced: language filters\nGo meta: turn this into a data carpentry lesson\n","permalink":"https://robintw.github.io/CW-ideas/cw19-carpentree/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 CarpenTREE - DSR12-CW2CC\nReporter Arshad Emmambux - a.emmambux@soton.ac.uk\nParticipants Patricia Herterich - p.s.herterich@bham.ac.uk\nVictor Koppejan - victorkoppejan@gmail.com\nLouise Bowler - lbowler@turing.ac.uk\nNiall Beard\nLink to initial proposal https://docs.google.com/document/d/1CQv-LJejF3pcXIFz0ve1JGMLtUperfxClbTEJbO5VYA/edit\nLink to final presentation https://docs.google.com/presentation/d/1df3kYNx7UquQLJl1x8WnCfnEzQfyYrtsUhdUGAFsaY0/edit?usp=sharing\nProblem statement Navigating software /data carpentry lessons isn’t straightforward, it’s not always clear where to go next and how much knowledge you need to start a lesson. Not many people have a complete overview of the carpentry lessons.","title":"CarpenTREE"},{"content":"Collaborations Workshop 2018 - 2018-03-26\nCarpentries platform to support translations -\nHP5-CW18\nHackday Idea Proposer\nDavid Pérez-Suárez - d.perez-suarez@ucl.ac.uk This document should be used to capture the information for a Hack Day Idea.\nProblem\nCarpentries material is useful to everyone, even beyond than those that speak English. Many instructors have translated some or all of the lessons for workshops around the world\u0026hellip; However makes it difficult for central carpentries to keep an idea of what\u0026rsquo;s been done and how direct new transtributors (translator contributors) to the right place.\nSolution\nI propose to use professional translations tools to this purpose! There\u0026rsquo;s standards have been used in many other projects. However they need some preprocessing. I\u0026rsquo;ve modified a tool to be able to tockenise md files (as used in the carpentries lessons). And now we only need to build the infrastructure that makes it easier. In my vision we can do that using travis, a bit of html-css, and git submodules (+github API) to orchestrate the whole system.\nDiagrams / Illustrations\n[James Baker] David et al: I edit the Programming Historian. We have a Spanish language initiative https://programminghistorian.org/es/ which has been going for nearly 2 years and translated 30 peer-reviewed lessons. We have an editorial team who might be useful and willing user testers for your work https://programminghistorian.org/project-team We have guidelines in place for what a translation initative needs to work well https://github.com/programminghistorian/jekyll/issues/378#issuecomment-369307840 If you want to chat about this and how PH and Carpentries could collaborate, let me know.\n","permalink":"https://robintw.github.io/CW-ideas/cw18-carpentriesplatformtosupporttranslations/","summary":"Collaborations Workshop 2018 - 2018-03-26\nCarpentries platform to support translations -\nHP5-CW18\nHackday Idea Proposer\nDavid Pérez-Suárez - d.perez-suarez@ucl.ac.uk This document should be used to capture the information for a Hack Day Idea.\nProblem\nCarpentries material is useful to everyone, even beyond than those that speak English. Many instructors have translated some or all of the lessons for workshops around the world\u0026hellip; However makes it difficult for central carpentries to keep an idea of what\u0026rsquo;s been done and how direct new transtributors (translator contributors) to the right place.","title":"Carpentries platform to support translations"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Checklists for open reproducible research - HP18-CW2CC\nHackday Idea Proposer Anna Krystalli - a.krystalli@sheffield.ac.uk\nContributors Richard Gilham - richard.gilham@metoffice.gov.uk\nEmmy Tsang - e.tsang@elifesciences.org\nAnna Krystalli - a.krystalli@sheffield.ac.uk\nDavid Gillespie - d.gillespie@mmu.ac.uk\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain There are comprehensive, large sets of guidelines on software engineering/research data best practices, but these are often difficult to digest and not easy to act upon. There is a need for the development of an easy-to-use tool that can help users to distil/digest these, with the goal of producing a universal, clear set of guidelines that are easy to adopt (in a checklist format?).\nRelated resources:\n Guideline to using Github issues: https://guides.github.com/features/issues/ DLR software engineering guidelines: https://zenodo.org/record/1344612#.XKNELOtKifV The Turing Way - https://github.com/alan-turing-institute/the-turing-way Isber best practices for repositories: SBER BEST PRACTICES FOR REPOSITORIEShttps://www.isber.org/page/BPR  Problem A lack of accessible generic tools that distill actionable guidance on appropriate practice to support open reproducible research - what is the appropriate practice for my software/research/dataset? With the aim to facilitate reuse\nSolution A scalable library of customisable handrail checklists of the appropriate practices for software/research/data with infrastructure for domain/task specific variations. This will be backed up by decision-aids to help researchers find what is right for them.\nNot every piece of work needs every facet of quality management. A 2-line script has a very different risk profile to, say, a million-line operational weather model. Getting the right amount of quality management and scaling it as your work progresses helps strike the right balance between rigour and innovation.\nMany tools exist to help people on their journey, but many different combinations may be used to achieve the desired effect. These checklists will be tool-agnostic, but with signposting to tool-specific solutions. This decouples the decision about the required quality management, the risk assessment, from the tools that are required. Decoupling the risk assessment from the tool choice provides clarity in the journey towards open and reproducible research. The two-step approach also makes it easier for researchers to get on board with the process rather than being overwhelmed by something that feels like a barrier to getting things done.\nATTRIBUTION: GitHub [MIT (http://opensource.org/licenses/mit-license.php) or OFL (http://scripts.sil.org/cms/scripts/page.php?item_id=OFL_web)]\n","permalink":"https://robintw.github.io/CW-ideas/cw19-checklists/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Checklists for open reproducible research - HP18-CW2CC\nHackday Idea Proposer Anna Krystalli - a.krystalli@sheffield.ac.uk\nContributors Richard Gilham - richard.gilham@metoffice.gov.uk\nEmmy Tsang - e.tsang@elifesciences.org\nAnna Krystalli - a.krystalli@sheffield.ac.uk\nDavid Gillespie - d.gillespie@mmu.ac.uk\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain There are comprehensive, large sets of guidelines on software engineering/research data best practices, but these are often difficult to digest and not easy to act upon.","title":"Checklists for open reproducible research"},{"content":"Collaborations Workshop 2018 - 2018-03-26\nChoose-a-Visualisation - HP2-CW18\nHackday Idea Proposer\nNeil Chue Hong - n.chuehong@googlemail.com This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain\nVisualisation is important to most researchers, but we often don’t get much training in how to do it well.\nProblem\nDescription of the problem you are trying to solve\nAlmost all researchers have to visualise data in some way, but in general (like Makefiles and many other things) we tend to learn a few simple examples and stick with them, even if they are not the most effective, efficient or exciting.\nLike software engineering, visualisation is something which we don’t get a good grounding in but where a little guidance could go a long way.\nWhat if there was a simple way to help researchers see what their data looks like visualised in different ways, along with advice on how to choose the appropriate one for the research problem they are trying to demonstrate?\nSolution\nChoose-a-visualisation would be a website that would allow a researcher to either upload their data, or link to a Google Sheet, answer a few questions about the data (e.g. whether data ranges are nominal, ordinal or interval), and then it would generate a set of common visualisation types for that data.\nSpecific things that this service could do include:\n● Helping researchers understand what visualisation types are useful for what types of data, either based on the dimensionality of the data, the data contents (e.g. the range of values), or the domain the researcher is in (e.g. do they tend to use specific plot types for certain data?\n● Helping researchers understand if a different perspective might illuminate the data better, by demonstrating what the data looks like when visualised in a different way (either by focusing on a different subset of the data, visualisation type, changing axes,\u0026hellip;) ● Help researchers move away from just relying on inappropriate simple visualisations (particularly if they only use Excel) ● Provide a way of downloading visualisation images for use ● Help reinforce good practice on the questions you should ask when visualising data\nThe D3.js gallery (https://github.com/d3/d3/wiki/Gallery) is a great way of seeing the different types of visualisation but what if you could see this with your own data?\nDiagrams / Illustrations\nExamples of D3 visualisations from D3js.org\n","permalink":"https://robintw.github.io/CW-ideas/cw18-choose-a-visualisation/","summary":"Collaborations Workshop 2018 - 2018-03-26\nChoose-a-Visualisation - HP2-CW18\nHackday Idea Proposer\nNeil Chue Hong - n.chuehong@googlemail.com This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain\nVisualisation is important to most researchers, but we often don’t get much training in how to do it well.\nProblem\nDescription of the problem you are trying to solve\nAlmost all researchers have to visualise data in some way, but in general (like Makefiles and many other things) we tend to learn a few simple examples and stick with them, even if they are not the most effective, efficient or exciting.","title":"Choose-a-Visualisation"},{"content":"Collaborations Workshop 2018 - 2018-03-26\nCode is Science Manifesto - HP10-CW18\nHackday Idea Proposer\nYo Yehudi - yochannah@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nSlides:\nhttps://docs.google.com/presentation/d/1OeaUt5UtSwVGxGv2uWqZoNBPvNzJFQyoYQg3isuXBcY/edit#slide=id.p\nContext / Research Domain\nAll scientific code!\nProblem\nScience is often computing: Much of modern science involves code these days, in large part due to the amount of data available - it would be almost impossible to analyse without computational assistance.\nScience requires peer review: One of the basic prerequisites for any published scientific results is that it be reviewed by peers, to ensure the research and conclusions are valid.\nSoftware contains errors: We may try pretty hard to write software without bugs, but they definitely still happen - and errors can be hard to spot. The bug doesn’t have to cause catastrophic and obvious failure - it could be silent but sneaky.\nSolution\n Write a manifesto Create a “sign this manifesto” website infrastructure  What do we need:\n● People who care about Open Source - don’t have to be coders! ● People who would like to help code the site so people can sign the manifesto\n","permalink":"https://robintw.github.io/CW-ideas/cw18-codeissciencemanifesto/","summary":"Collaborations Workshop 2018 - 2018-03-26\nCode is Science Manifesto - HP10-CW18\nHackday Idea Proposer\nYo Yehudi - yochannah@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nSlides:\nhttps://docs.google.com/presentation/d/1OeaUt5UtSwVGxGv2uWqZoNBPvNzJFQyoYQg3isuXBcY/edit#slide=id.p\nContext / Research Domain\nAll scientific code!\nProblem\nScience is often computing: Much of modern science involves code these days, in large part due to the amount of data available - it would be almost impossible to analyse without computational assistance.","title":"Code is Science Manifesto"},{"content":"Context / Research Domain The peer-review process in academia\nProblem Peer-reviewers are often not code literate, so even if someone writes/uses code in the research and claims to publish it openly and well (with zenodo DOI and CFF file etc), the reviewers (who may be experts in the field) may not have the expertise to check the quality/reproducibility of the code (and the data)\nSolution A service and a set of guidelines that allows code-literate reviewers to register e.g Orcid ID that advertises to editors that they would be available to conduct a “technical peer-review” of academic papers.\n","permalink":"https://robintw.github.io/CW-ideas/cw19-code-review/","summary":"Context / Research Domain The peer-review process in academia\nProblem Peer-reviewers are often not code literate, so even if someone writes/uses code in the research and claims to publish it openly and well (with zenodo DOI and CFF file etc), the reviewers (who may be experts in the field) may not have the expertise to check the quality/reproducibility of the code (and the data)\nSolution A service and a set of guidelines that allows code-literate reviewers to register e.","title":"Code-literate peer-review for everyone"},{"content":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Blanch-1943 - HP3-CW21\nHack Day idea proposer Colin Sauze\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) Coding Confessions\nThis is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nContext and/or research domain Please describe the context and/or research domain to which the problem applies\nAnybody who writes code for research\nProblem Description of the problem you are trying to solve\nPeople don’t want to talk about their mistakes, publish code or submit it for review. Only positive results get published. Common reasons for this are fear that “my code isn’t good enough”, “isn’t complete enough”, “has mistakes in it”. We want to encourage people to share their coding insecurities to help normalise talking about mistakes and knowledge gaps.\nSolution Explanation of the solution to the problem you have identified\nGet people to “confess” about coding mistakes they’ve made in the past. This could either be in just to another individual or to a group. It might get run internally at a single institution or as part of a conference or workshop (mini workshop for CW22??).\nThe hack day would work on building a list of instructions on how to run a coding confession. Perhaps making a video or a transcript of an example session.\nTaking some inspiration from the Repro Hack idea we could build a central page (like https://reprohack.github.io/reprohack-hq/ ) of resources for running coding confession.\nDiagrams / illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-coding-confessions/","summary":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Blanch-1943 - HP3-CW21\nHack Day idea proposer Colin Sauze\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) Coding Confessions\nThis is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nContext and/or research domain Please describe the context and/or research domain to which the problem applies","title":"Coding Confessions"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Col-Laboratory - HP20-CW2CC\nHackday Idea Proposer Niall Beard - niallbeard@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nProblem Description of the problem you are trying to solve\nSomeone out there may be using the same technologies or data as you, seeking to pursue the same research as you, or would be interested in working with you\u0026hellip; But you don’t know they exist\nSolution Explanation of the solution to the problem you have identified\nA website that a researcher can go to and enter their ORCID.\n\nThis gets their location and research interests. The webpage then loads all the researchers who have matching research interests.\nCan then filter this list based off location, career stage, and other attributes.\nDiagrams / Illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw19-col-lab/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Col-Laboratory - HP20-CW2CC\nHackday Idea Proposer Niall Beard - niallbeard@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nProblem Description of the problem you are trying to solve\nSomeone out there may be using the same technologies or data as you, seeking to pursue the same research as you, or would be interested in working with you\u0026hellip; But you don’t know they exist","title":"Col-Laboratory"},{"content":"CW20 - 2020-03-31 to 2020-04-02 “Conferencing 3.0: ensuring equality for in-person and online participants” - CI2-CW20\nParticipants Please list the participants here (please use full names).\nEmily Lewis\nEsther Asef\nRadovan Bast\nBezaye Tesfaye\nNeil Chue Hong\nRichard Darst\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all the hint text (grey, Arial 11, italic) once you no longer need it.\n_ _\nContext / Research Domain Please describe the context or research domain to which the problem applies\nWhen the COVID-19 lockdown restrictions lift, we will see a return to people wanting to restart in-person events whilst others will want to continue the online interactions. The challenge will be to create a combination of guidance and tools to help run events when we have mixed online and in-person interaction, to make sure we don’t introduce new issues? This will apply to most research domains.\nConferencing 1.0 - traditional in-person\nConferencing 1.5 - in-person unconferences\nConferencing 2.0 - online\nConferencing 3.0 - hybrid online, in-person, synchronous and asynchronous. Equality for online and in-person participants\nProblem How will we move offline again? When we have mixed online and in-person, how do we make sure we don’t get issues? Often in video conferences with combined physical and virtual presences, the online audiences are a secondary priority. It’s also much harder to get interactions going with people you don’t know online - this gets harder when in a hybrid mode as video chats are inherently a bit awkward.\nSolution Explanation of the solution to the problem you have identified\nA guide for people running events in the future, with pointers to existing materials and tools. The guide would be open for all to contribute to.\nThis would include:\n Templates for different types/formats of meetings and events: help sessions, teaching sessions, closed / limited community workshops, open conferences Repository of useful icebreakers that work Methods to have “virtual” coffee breaks and informal networking. Methods for chatting “Twitch code review” and other sorts of peer-participation Templates for asking/documenting questions and answers. Personas of the different types of participant (everyone is not equal) Lessons learned from other communities, e.g. online gaming broadcasts  It would also ensure that we took and combined the parts of each conferencing paradigm we most liked:\n Conferencing 1.0 (traditional in-person): Coffee breaks Ice breakers Conferencing 1.5 (in-person unconference) Breakout sessions to mix up participants, introduce people to people they haven’t met Lightning talks from all / most participants, rolling a random number generator to select participants to give introductory talks. Conferencing 2.0 (online) Accessibility, open to maximum number of audience, can join remotely. Takes into account travel and care limitations. Virtual chat channels Platforms that make asking questions less intimidating Slack channel for sharing pictures of pets  We would also do a “literature review” to see if:\n Work on this already exists?  E.g. Lessons learned from Mozilla   People already working on this? We should be contributing this elsewhere?  Diagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nAdditional Notes How is COVID-19 changing the way we’ll be running events and training after lockdown\n Slack vs Twitter: Slack better for chatting, don’t have to think so much about publishing (as it is for Twitter), more like a coffee room chat But you don’t want yet another channel Online there are more distractions Text chat doesn’t interrupt the speaker Asking questions in a document allows better documentation and sharing with everyone Events will become more shareable Can be difficult to understand context, without good notes / good editing, introduce context Easier to deal with “nasty” questions, as audience know that the speaker is seeing questions and comments in real-time Making things public mean that people may be less willing to ask questions / try and fail - how do we prevent this How to allow “outside” participants to participate (Observers vs participants?)  Description of the problem you are trying to solve\n Esther: how to reach out to other researchers, especially when you can’t meet face to face. Thinking about an open consultation hour online.  What you wish to see, how to advertise and prepare   Richard: Trying to support researchers in computing fields. But there is a crisis of computing - tools are getting more complicated, but researcher preparation is getting less and less. Bezaye: How do we impose on researchers to publish every software that is implemented as part of the process of publishing a paper? Emily: Are there good tools and approaches for running a Software Carpentry workshop completely remotely Radovan: Building a prototype (leaflet) map of RSEs and RSE groups where you can share twitter/github/homepage. Issues is that it is working, but e,g, several people at the same place will show up as one. Neil: Been moving things online, what happens when we get out of the current lockdown and people are used to a different way of working? How will we develop events in the future, now that we have this new normal? What kinds of exercises and interaction modes work will online and in person. e.g. the reproducibility exercise, what other kinds of icebreakers  Resources from Carpentries Thread(2020-03-12 [discuss] Is COVID-19 virus demanding alternative software carpentry workshop delivery options?):\n Australian Research Data Commons - ARDC - Virtual Software Carpentry Workshops - key learnings to make it a success (video) Teaching Effectively During Times of Disruption, Stanford Stanford led list of resources of different organisational policies  Carpentries collecting more info:\n Quick Tips for Teaching and Learning Online by The Carpentries Community - GitHub Tips for Teaching and Learning Online by The Carpentries Community - Google Doc Greg Wilson: online teaching Q\u0026amp;A  Code Refinery manuals\n https://github.com/coderefinery/manuals/blob/master/online-training.md Run both events and help sessions Help sessions used to be people bringing laptops to get setup Now have a Zoom meeting, where participants are put into breakout rooms one to one Ensure that people know they are in a queue and they will be happy to wait Advertise via local partners, subject librarians, friends \u0026amp; family, e-mail lists  Need to adjust speed of courses - we’ll need to see how this goes in practice.\n Will people be able to follow along with live coding Will exercises take longer Will it be harder to see who’s falling behind?  Keep the Ice Breakers\nLessons learnt from Cw20 as a good reference\n","permalink":"https://robintw.github.io/CW-ideas/cw20-conferencing3.0/","summary":"CW20 - 2020-03-31 to 2020-04-02 “Conferencing 3.0: ensuring equality for in-person and online participants” - CI2-CW20\nParticipants Please list the participants here (please use full names).\nEmily Lewis\nEsther Asef\nRadovan Bast\nBezaye Tesfaye\nNeil Chue Hong\nRichard Darst\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two).","title":"Conferencing 3.0: ensuring equality for in-person and online participants"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Creating a Lessons Roadmap and Profiency Framework for Software and Data Training - HP7-CW2CC\nHackday Idea Proposer Victor Koppejan \u0026amp; Jeremy Cohen\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nLearners of software and data training topics.\nDevelopers of software and data training material.\nProblem Description of the problem you are trying to solve\nAt present, there is no “roadmap” which makes it easy for learners to understand what topics they should move on to next to improve their skills in the areas of software development and data analysis. Additionally, trainers have no standard framework that lets them tweak their lessons to different fields, by showing what skill topics and proficiency levels might be applicable to that field.\nAlthough many existing initiatives have tried to map out learning progression, many are overly complex with a level of detail that is too confusing for people who do not have a primary background in the space. They often combine general concepts with specific tools and are hard to maintain and keep up to date.\nWhat we would like is a representation of learning pathways/routes, with well-defined “prerequisites”, “learning outcomes” and “postrequisites”, that enables learners to understand what they could or should learn next, and would allow trainers to categorise/tagging their material. It then allows people to understand what are the most used / most useful things to learn in any particular discipline\nSolution Explanation of the solution to the problem you have identified\nThe biggest challenge is understanding what level of detail / granularity the information on the nodes should be at, and how to agree what the links between nodes should be.\nThis hackday pitch would work on the following tasks:\n Define a metadata schema for training material (or identify a suitable existing one) Define specific metadata for existing lesson material (including relationship to other existing material, such as “prerequisites”, “learning outcomes” and “postrequisites”) Define representation(s) for the metadata that can show relationships of interest to different types of viewers Identify an existing infrastructure (e.g. Wikidata, GitHub, Graph databases) that can be used for implementing the representation of the roadmap in a way that makes it easy to maintain Build tool(s) that visualize the relationships and the metadata. Determine how to maintain metadata over time. Setup a reviewing procedure for the points above using existing github or equivalent frameworks. (Very far fetched) build tools that automate the combination of lessons and build new syllabi based on the graph.  Notes:\n There’s a difference between the title of a lesson, and the category What’s the metadata schema that you need for each “location” on the roadmap?  Relevant Domains Proficiency Level Programming Language Generality of lesson: E.g., general concept, specific tool “High level Topic / pathway”? E.g. Data analysis (or is it data cleaning - what level)? Could use expert judgement or could mine existing materials to identify what people are already using   What examples of this are there already in different areas?  For teaching languages: https://en.wikipedia.org/wiki/Common_European_Framework_of_Reference_for_Languages SFIAplus IT Skills Framework: https://www.bcs.org/upload/pdf/sfiaplus-wallchart.pdf EU Digital Competency Framework: http://publications.jrc.ec.europa.eu/repository/bitstream/JRC106281/web-digcomp2.1pdf_(online).pdf    Diagrams / Illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw19-lessonsroadmap/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Creating a Lessons Roadmap and Profiency Framework for Software and Data Training - HP7-CW2CC\nHackday Idea Proposer Victor Koppejan \u0026amp; Jeremy Cohen\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nLearners of software and data training topics.\nDevelopers of software and data training material.","title":"Creating a Lessons Roadmap and Profiency Framework for Software and Data Training"},{"content":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Booth-1948 - HP4-CW21\nHack Day idea proposer Emma Karoune (representing The Turing Way Community)\nMalin Sandstrom (INCF, CSCCE)\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) Inclusive authorship/contributor tool\n Name ideas = Credit Me or All authors - Credit All  Context and/or research domain Relevant to all domains to attribute contributions to research projects from all contributors more fairly in the authorship of academic publications.\nProblem Current systems that attribute contributions to authors in academic outputs do not include all of the jobs/roles/tasks that are encompassed in research projects.\nIssues include:\n Capturing all roles on a project. How to capture all tasks within those roles. How to give different weight/credit to tasks completed or should they all have equal value? How to convert this into the actual authorship - will it be a to z, random, ranked or a consortium?  Solution  Expand current lists to be more inclusive - using current systems such as CRediT, INRIA, BIDS Contributors. Develop a tool to be used to record these contributions during the project such as within a Github repository. Develop a way that this can be shown on academic papers - lists, table, cinema title page? (look at e.g. Brainhack paper w 100+ authors and Living with machines).  Diagrams / illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nFrom Malin Sandstrom’s Lightning talk at CW21\nOther resources:\n https://www.natureindex.com/news-blog/researchers-embracing-visual-tools-contribution-matrix-give-fair-credit-authors-scientific-papers https://casrai.org/credit/ https://journals.plos.org/plosone/article/figure?id=10.1371/journal.pone.0226727.t002 https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0226727 https://arxiv.org/pdf/2005.11140.pdf https://hidden-ref.org/categories/   ","permalink":"https://robintw.github.io/CW-ideas/cw21-credit-all/","summary":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Booth-1948 - HP4-CW21\nHack Day idea proposer Emma Karoune (representing The Turing Way Community)\nMalin Sandstrom (INCF, CSCCE)\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) Inclusive authorship/contributor tool\n Name ideas = Credit Me or All authors - Credit All  Context and/or research domain Relevant to all domains to attribute contributions to research projects from all contributors more fairly in the authorship of academic publications.","title":"Credit All"},{"content":"CW20 - 2020-03-31 to 2020-04-02 Idea 4 - CI4-CW20\nDealing with Legacy Code\nParticipants Patricia Herterich_ _\nCat Smith_ _\nChristopher Fullerton\nRaniere Silva\nPhilipp Boersch-Supan\n Context / Research Domain All research domains which have to contend with/rely on legacy code which does not conform to best practices.\nProblem Researchers are instructed to use some legacy code written by their team, a third party or even themselves a while ago. The code isn\u0026rsquo;t documented or unit tested. Researchers face the problem of using the code in the dark. How can researchers save the legacy code and lower the learning curve for future users?\nSolution The outcome of this hack idea session is a checklist (preferably ordered by importance) which outlines things that can/should be done to help improve the code. This might need to differ for different programming languages or contexts but much will probably be similar. Sub-checklists could be useful covering topics like introducing tests into a large legacy code base, which things should be documented first, etc.\nSome ideas we already came up in our discussion and which could inform the development of such a checklist as as follows:\n Try to (1) install/setup and (2) use legacy code and document successful steps. You can start writing things in the README file and later, when the documentation starts to be too long, you can migrate to another platform and break it into sections.  Depending of the language and dependencies used by your project, is useful to future users to have a Makefile (for examples, projects in C or Fortran) or a Dockerfile (for example, projects in Django or Node.js) as those files reduce repetitive typing from users   Ask or pay someone new to the project to review the steps that you documented (particularly with regards to download/installation/setup). Undergraduate students and earlier stage RSE are great for this task as they might be also new to technologies that you are using. For example, students might be new to Git submodules and report to you that additional instructions are needed. This will also help you identify hardware configurations that need to be documented, for example Docker requires virtualisation enabled. Restructuring/Refactoring/Rewriting code in the original language can be useful:  documentation still to be worked on, but code is now clearer. Restructuring the code (e.g. main project and sub-module) can make sharing easier; Can make translating to other languages easier as you can progress with smaller sections/modules and reduce the risk of breaking with untested original code   Introducing testing is really difficult if you have one large complicated workflow it might be best, if applicable to the code, to start with overall tests that ensure the final result is correct before introducing unit tests for smaller sections Contact your university library and ask if they have a procedure to archive/register software. If they do, they might be able to provide you with additional check (for example, to have a citation file or DOI) and staff time to check your code. The Data Curation Network has created primers to review a range of data and code types that can facilitate that process: https://datacurationnetwork.org/resources/data-curation-primers/ The hackday could create an index of institutions listing the support services available.  Diagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw20-legacy-code/","summary":"CW20 - 2020-03-31 to 2020-04-02 Idea 4 - CI4-CW20\nDealing with Legacy Code\nParticipants Patricia Herterich_ _\nCat Smith_ _\nChristopher Fullerton\nRaniere Silva\nPhilipp Boersch-Supan\n Context / Research Domain All research domains which have to contend with/rely on legacy code which does not conform to best practices.\nProblem Researchers are instructed to use some legacy code written by their team, a third party or even themselves a while ago.","title":"Dealing with Legacy Code"},{"content":"CW21 - 2021-03-30 Garfield - CI7-CW21\nParticipants Please list the participants here\nMatt Cannon - Taylor \u0026amp; Francis (scribe)\nDominic Kempf / RSE, Heidelberg University\nMatthew Bluteau / RSE, UK Atomic Energy Authority\nRobin Wilson / Freelance - robin@rtwilson.com\nPaddy McCann / RSE, University of St Andrews\n Title: DEPTH: Developer Error/Problem Treasure Hunt! Context / Research Domain General RSE audiences, (and really any software developer)\nResearchers who are not RSE - could have general or very specific queries.\nProblem It is a specialist skill to be able to decipher error messages and find answers quickly online. These are skills which are not widely taught (and often under-appreciated), but are critical to being an effective developer. Often these kinds of issues are directed to a specific individual within a group/department/company which is not a good use of time/resources. This is particularly a problem for beginner programmers (who may not know what the relevant parts of their problem are), and for people working outside of software development teams with relevant experts.\nSolution We propose an interactive online course to help people with deciphering error messages, building search queries and finding solutions. We propose to do this via a treasure hunt!\nThe course would start with slides/presentation with_ _basic tips. Then moving on to give examples of errors (for example an error message or stack trace) and asking the students to then try and extract the relevant bits, do the relevant searches and find answers - with some tips along the way. Then follow up with best practice on how ‘the experts’ would have done it.\nThe examples would be carefully chosen so that the answers are definitely ‘out there’ to find, in various places (StackOverflow, blogs, forums, documentation) - and designed to gradually increase in difficulty. We are aware there would need to be considerations for different programming languages, so would suggest starting with a well-known language - Python.\nThe course would be designed to be able to be taken online by an individual alone, or alternatively as a ‘taught course’ in a group - potentially as part of a Software Carpentry course.\nDiagrams / Illustrations Our view of how a “treasure hunt” would work:\n_https://docs.google.com/presentation/d/1g-CBDLqARbWfo82Dkw9H3REcQ4LE_5mcKmwzZR60Zsc/edit?usp=sharing _\nThe “faded problem” would be that the intermediate steps would gradually be removed as the difficulty increases.\nAnd for those who have felt the pain of searching for solutions online, we give you this inadequate solace:\n(https://xkcd.com/979/ licensed CC BY-NC 2.5)\nThanks for reading!\n(l-r - Matt C, Robin, Dominic; Matt B, Paddy) Licence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-depth/","summary":"CW21 - 2021-03-30 Garfield - CI7-CW21\nParticipants Please list the participants here\nMatt Cannon - Taylor \u0026amp; Francis (scribe)\nDominic Kempf / RSE, Heidelberg University\nMatthew Bluteau / RSE, UK Atomic Energy Authority\nRobin Wilson / Freelance - robin@rtwilson.com\nPaddy McCann / RSE, University of St Andrews\n Title: DEPTH: Developer Error/Problem Treasure Hunt! Context / Research Domain General RSE audiences, (and really any software developer)\nResearchers who are not RSE - could have general or very specific queries.","title":"DEPTH: Developer error/problem treasure hunt!"},{"content":"CW20 - 2020-03-31 to 2020-04-02 Does grade inflation exist? - CI6-CW20\nParticipants Jez Cope Philip Grylls Pablo Bernabeu Frances Cooper Tania Allard\n Context / Research Domain New university students often do not have the skills expected when they begin their degree courses. One reason for this may be that universities are less able to distinguish between student skills due to grade inflation. Grade inflation is the process whereby exam questions become easier each year, meaning more students achieve higher grades. But does grade inflation actually exist?\nProblem  The secondary education system has recently undergone an overhaul of the grading system to combat grade inflation at the top end. This can be attributed to a combination of political and societal pressures for better grades along with changes to the background knowledge that students gain before and outside formal education: there isn’t enough data currently to tease these apart This was also seen at the beginning of the last decade in the introduction of A* to A-levels and has been noted in the grade distributions of undergraduate degrees; this is a particular problem as degree entry requirements often fail to track changes to the underlying pre-university curriculum.  Solution  Include suggested preparations in addition to prerequisites, especially relevant for cases in which a degree will split into very different routes (e.g., Psychology, Linguistics, ..). Could the grade inflation also be tackled through a behavioural approach, in which lecturers and students would receive expert, unified training about the need to have a coherent grade landscape? We suggest using publicly available data to create an interactive dashboard comparing different viewpoints of the problem including average grade distributions, university admission grades, and the ability to sample topics and questions from different years.  Diagrams / Illustrations Notes from the Ideas Session  Idea A: Problems and solutions to the use of tech in public administration \u0026mdash;-\nRelevant questions:\n AI and digital technologies used in the Criminal Justice system.  What is fairness?  Representative sampling Same release rates (ie white vs minority i.e. COMPASS) Same false positive (are we looking for none) Facial recognition and targeting   False negatives / false positives in prison release Boundaries:   Solutions:  How to test data sets and compare their outcomes to the people they affect How to robustly test digital technologies against the best criminological theory    Idea B: Managing digitised content of the British Library. 0++0\nThe British Library (BL) has a vast amount of paper data, some of which has been digitised.\n  Challenges:\n Digitising as much of this content as possible, which has been highlighted with crises such as Covid-19. Even once digitised, making this content available at scale has been a challenge. Funding needed.    Legal deposit: anything published in the UK must be made available to BL, both print and non-print. This includes the UK Web (.co.uk, .ac.uk, \u0026hellip;). This deposit can only be accessed by someone physically located in a Legal Deposit library1 reading room.\n  Solution: Applying firewall policy in BL infrastructure for internal analyses, and publishing results with a secure licence. Redraw relevant law to be able to grant content requests.\n The legal problem can’t be addressed by a hackday (if only!) but technological solutions might be possible to improve access within the current law E.g. DataSHIELD2 extended to do text data mining Idea C: Recurrent phone scams \u0026mdash;+    How and can this go on? Is there not enough tech to tackle it?\n  Massive corps (esp. banks) must surely have the necessary information to prevent and resolve these incidents.\n  System: Simple system of matching information would go some way to prevent these incidents.\n  Is this happening because people are using spreadsheets?\n  Idea D: Limited comp science skills in entry to some degrees +++0\nSolutions:\n Build a kind of guide about prerequisites for getting up to speed with some skills. In the context of the decrease in knowledge over time, at a national level, as forced by a gradual grade inflation, a tool could be created to assess this progression. Information could be shared in a data dashboard, achievable in a hack day. Unis would benefit from this tool. Public stats could be used to create this.  Idea E: Reproducibility in scientific computing +0 +0\n Seen as black and white - whereas the spectrum is more complex. Solution: Create a reproducibility analyser. When a new release is made, content of the repo can be analysed. Automatic report created including environment spec compared to previous release. CodeCoverage: how text is changing, how testing is being done. Useful for group leaders. Barrier of entry to somebody else’s research can be understood. Could be used to create certification as well as personal understanding. Evolving checklist. Consider FAIR data checklist and extend for purpose of reproducibility. Convenient for inclusion of wider community.  Final round!\nB\nD +++\nE +\nNotes   6 legal deposit libraries in the UK \u0026amp; ROI: The British Library, National Library of Scotland, National Library of Wales, Bodleian Library (University of Oxford), Cambridge University Library, Trinity College Library (Dublin) \u0026#x21a9;\u0026#xfe0e;\n \u0026ldquo;DataSHIELD | DataSHIELD | Newcastle University.\u0026rdquo; http://www.datashield.ac.uk/. Accessed 1 Apr. 2020. \u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://robintw.github.io/CW-ideas/cw20-grade-inflation/","summary":"CW20 - 2020-03-31 to 2020-04-02 Does grade inflation exist? - CI6-CW20\nParticipants Jez Cope Philip Grylls Pablo Bernabeu Frances Cooper Tania Allard\n Context / Research Domain New university students often do not have the skills expected when they begin their degree courses. One reason for this may be that universities are less able to distinguish between student skills due to grade inflation. Grade inflation is the process whereby exam questions become easier each year, meaning more students achieve higher grades.","title":"Does grade inflation exist?"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 11 - CI3-CW2CC\nDUQI\n(Document Utility and Quality Interrogator)\nReporter Adam Jackson\nParticipants Douglas Lowe (douglas.lowe@manchester.ac.uk)\nBecky Arnold (rjarnold1@sheffield.ac.uk)\nArshad Emmambux (a.emmambux@soton.ac.uk)\nAdam Jackson (a.j.jackson@physics.org)\nDiego Alonso-Álvarez (d.alonso-alvarez@imperial.ac.uk)\nCarina Haupt (carina.haupt@dlr.de)\n Context / Research Domain All research domains. Helping people improve their documentation. Specifically this should benefit small projects without established documentation practices.\nProblem\nA common question researchers trying to improve their code quality ask is “how do I know if what I’ve written is good, and how do I know what I need to improve?”. One of the biggest problems with code is poor documentation, with faults such as undefined variables, few comments, no docstrings and broken links. In many small projects, the majority of the documentation consists of comments within the codebase; and this is perfectly acceptable if that is easily navigable.\nHowever there are not easy-to-use tools available for checking for faults such as these, and reporting them. While tools exist for automatic API documentation (e.g. Doxygen) they are relatively complicated and intended more for complex libraries than for the simple scripts that many researchers use for their own work (which can then, later, grow into shared libraries).\nChecking documentation quality can be laborious and time consuming, especially for a pre-existing codebase. This means even for experienced coders that are fully aware of best practice, an automated documentation quality reporting tool would be highly desirable.\nSolution A program which takes code files as input and provides a report/statistics about different facets of documentation quality. Checks/measures could include:\n Success rate of external link resolution (i.e. find stale web links) Comment to code ratio Completeness of docstrings based on analysis of function definitions  Where possible these would be implemented in a generic way, allowing application to multiple programming languages (e.g. Python, R and Fortran) via a parsing/translation layer. This tool should also be extensible so that modules that check further facets of documentation quality can be included.\nIf time permits an extension to this project could be to add a documentation enhancement tool. Via this tool following reporting, optional enhancements may be provided (e.g. missing function arguments and type specifications), allowing the coder to edit the existing information. A final step if there has been any enhancement will be to dump the new documentation back to the source code files.\nDiagrams / Illustrations ","permalink":"https://robintw.github.io/CW-ideas/cw19-duqi-prop/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 11 - CI3-CW2CC\nDUQI\n(Document Utility and Quality Interrogator)\nReporter Adam Jackson\nParticipants Douglas Lowe (douglas.lowe@manchester.ac.uk)\nBecky Arnold (rjarnold1@sheffield.ac.uk)\nArshad Emmambux (a.emmambux@soton.ac.uk)\nAdam Jackson (a.j.jackson@physics.org)\nDiego Alonso-Álvarez (d.alonso-alvarez@imperial.ac.uk)\nCarina Haupt (carina.haupt@dlr.de)\n Context / Research Domain All research domains. Helping people improve their documentation. Specifically this should benefit small projects without established documentation practices.\nProblem\nA common question researchers trying to improve their code quality ask is “how do I know if what I’ve written is good, and how do I know what I need to improve?","title":"DUQI (Document Utility and Quality Interrogator)"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 DUQI\n(Documentation Utility \u0026amp; Quality Interrogator) - HP8-CW2CC\nHackday Idea Proposer Rebecca J Arnold - rjarnold1@sheffield.ac.uk\n Idea formed in discussion with group 11\nContext / Research Domain All research domains. Helping people improve their documentation. Specifically this should benefit small projects without established documentation practices.\nProblem\nA common question researchers trying to improve their code quality ask is “how do I know if what I’ve written is good, and how do I know what I need to improve?”. One of the biggest problems with code is poor documentation, with faults such as undefined variables, few comments, no docstrings and broken links. In many small projects, the majority of the documentation consists of comments within the codebase; and this is perfectly acceptable if that is easily navigable.\nHowever there are not easy-to-use tools available for checking for faults such as these, and reporting them. While tools exist for automatic API documentation (e.g. Doxygen) they are relatively complicated and intended more for complex libraries than for the simple scripts that many researchers use for their own work (which can then, later, grow into shared libraries).\nChecking documentation quality can be laborious and time consuming, especially for a pre-existing codebase. This means even for experienced coders that are fully aware of best practice, an automated documentation quality reporting tool would be highly desirable.\nSolution A program which takes code files as input and provides a report/statistics about different facets of documentation quality. Checks/measures could include:\n Success rate of external link resolution (i.e. find stale web links) Comment to code ratio Completeness of docstrings based on analysis of function definitions  Where possible these would be implemented in a generic way, allowing application to multiple programming languages (e.g. Python, R and Fortran) via a parsing/translation layer. This tool should also be extensible so that modules that check further facets of documentation quality can be included.\nIf time permits an extension to this project could be to add a documentation enhancement tool. Via this tool following reporting, optional enhancements may be provided (e.g. missing function arguments and type specifications), allowing the coder to edit the existing information. A final step if there has been any enhancement will be to dump the new documentation back to the source code files.\n","permalink":"https://robintw.github.io/CW-ideas/cw19-duqi/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 DUQI\n(Documentation Utility \u0026amp; Quality Interrogator) - HP8-CW2CC\nHackday Idea Proposer Rebecca J Arnold - rjarnold1@sheffield.ac.uk\n Idea formed in discussion with group 11\nContext / Research Domain All research domains. Helping people improve their documentation. Specifically this should benefit small projects without established documentation practices.\nProblem\nA common question researchers trying to improve their code quality ask is “how do I know if what I’ve written is good, and how do I know what I need to improve?","title":"DUQI (Documentation Utility \u0026 Quality Interrogator)"},{"content":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Batey-1941 - HP2-CW21\nHack Day idea proposer Neil Chue Hong and Stephan Druskat\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nEnabling analysis of research software: Creating an enhanced research software corpus\nContext and/or research domain Please describe the context and/or research domain to which the problem applies\nResearch on research software (cross-domain)\nProblem Description of the problem you are trying to solve\nUntil very recently, a key challenge in trying to understand the research software landscape was that we didn’t know how to find research software - there was no single, comprehensive “research software directory” or curated lists of commonly used research software, though there are discipline-specific catalogues and lists (e.g. on Wikipedia), an increasing number of entries on Wikidata (e.g. for SQLite), and recent initiatives such as the NLeSC Research Software Directory and the Research Software Encyclopedia.\nMany approaches took publications as a starting point, often manually identifying software that was mentioned in the publication. Domain registries such as swMath for mathematical software and ASCL.net for astrophysics software which accept author-led suggestions also use these techniques to identify possible candidates for inclusion. Other approaches relied on automatically mining code repositories looking for key markers, such as citation files or DOIs.\nThis year, two datasets have been released which have gone further to produce a “gold standard” corpus that can be used for other research. The SoftCite project is a human curated list of 4,093 software mentions in life sciences and social sciences, as a TEI/XML file: https://github.com/howisonlab/softcite-dataset. This, in turn, was used by a team at CZI to train a machine learning model that has been used to identify software references in COVID-19 research papers, collectively CORD-19, which has been published as a raw dataset: https://doi.org/10.5061/dryad.vmcvdncs0\nWe would like to make this data more useful for those wanting to undertake research in this area.\nSolution Explanation of the solution to the problem you have identified\nPotential ways of improving this include:\n Analysing and cleaning the CORD-19 software mentions to create a canonical list of software along with common aliases (e.g. MS Excel, Excel, Microsoft Excel should all be related) Annotating the datasets to provide additional useful metadata such as DOIs, URLs to code repositories where they exist, release dates Creating processes and tools that assist with the above  This could then be used to provide some basic metrics around the research software landscape e.g.\n What is the most popular license for research software? Has this changed through time? Is the most popular software updated more often? How many people contribute code to research software on average? Distribution of usage, contributions, updates → guidance for funding, sustainability of RS Does the set of contributors to research software shift, which could be a marker for reuse? How many software projects provide citation information?  possible look into citation network, contributor network, dependency network (and/or overlap between these)    It could also be used to demonstrate things that we could do with such a corpus\n Demonstrate the state of FAIRness of software, and track the development of FAIRness Use it for testing and benchmarking software engineering methods, e.g., automated program repair, test generation, etc.  And, of course, the big one:\n What software is most important to COVID-19 research?  As suggested by the OSCAR collaborative ideas group, there are many things that could be done to analyse the dataset, to identify statistics or trends that could illustrate issues. These include the key role software has played in responding to COVID-19 (and lack of recognition of its importance), the issues in citation of research software (and possibly findability and accessibility of the software), methods to identify key software infrastructure.\nSome of the questions we could hope to answer are:\n Is information provided about the software authors to give them credit? How many/which pieces of software are repeatedly mentioned (and could possibly be defined as critical research infrastructure)? How was the software mentioned? (e.g. proper references to the software, in-line in the text, footnote, etc.) How was the software itself referenced (e.g. A GitHub page to a project, a GitHub page to a release, a Zenodo DOI to an archive, a Software Heritage link to a release, etc.) What percentage of all articles mention software? How many pieces of software are mentioned per paper? What was the software used for (e.g. platform, analysis) Subdiscipline analysis - is there some smaller set of the dataset (eg a subdiscipline) where the answers to any of these questions differ to that of the whole dataset, that might illuminate where a community is doing things differently/better?  Diagrams / illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nWhat do we want to see in a data set from different perspectives?\n_What do we want to answer regarding the prevalence of software and what metadata would capture it? _\n","permalink":"https://robintw.github.io/CW-ideas/cw21-creating-an-enhanced-research-software-corpus/","summary":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Batey-1941 - HP2-CW21\nHack Day idea proposer Neil Chue Hong and Stephan Druskat\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nEnabling analysis of research software: Creating an enhanced research software corpus","title":"Enabling analysis of research software: Creating an enhanced research software corpus"},{"content":"CW21 - 2021-03-30\nFelix - CI6-CW21\n Participants Eli Chadwick Iain Barrass Alice Minotto Yo Yehudi  Context / Research Domain Planning for continuation of dissemination of research outputs is an established part of a research grant application. We frequently see requests for ongoing costs for website hosting, placement of datasets in repositories or hosting of developed code in an online version control system. However, it is less frequent that considerations are made of ongoing technical staff attention to support staff responsible for code sustainability, maintanence, or data updates. Code \u0026ldquo;end of project plans\u0026rdquo;, which detail what attention has been paid to issues around what happens to support developed research software at the end of a PhD project or research grant will help to assure those other users of the software of its ongoing sustainability, can be a crucial part of this support. Avoiding the curse of \u0026ldquo;PhD-ware\u0026rdquo; assures PIs within a research group that future work of the group can successfully build on a substantial investment of intellectual effort.\nFor this session we propose development of a project to assure software sustainability when that software comes from a short fixed-term project.\nProblem Two main situations can arise: either the software is not maintained and virtually \u0026ldquo;left to die out\u0026rdquo;, or the original developer keeps maintaining it at the new institution, keeping them away from new duties. In the latter scenario we can still encounter problems tracking down and contacting the developer. Well documented and annotated code is only part of the solution, especially when we consider sizable projects. Currently there is no widely accepted agreement nor policy about whom the responsibility of code maintenance lies with.\nEven when there\u0026rsquo;s a maintenance plan for funding and grants, this generally includes technical costs (e.g. hosting, domain and SSL certificate purchases), but not the time/people needed.\nSolution A short (~5 minutes) questionnaire that leads to a badge for your README indicating your maintenance/end-of-life plans. This should be a minimal amount of work to encourage people to consider maintenance without becoming overwhelmed by the options\nQuestions include:  How much maintenance do you want to do? None/a tiny bit/a lot/etc. Do you have funding for maintenance? Have you identified funding opportunities for further maintenance? How long do you intend to maintain for? Will you continue maintenance after funding runs out? Who is the contact person at the end of the project? Do you expect to ever come back to this project for further development? I.e. is this a development gap, not end-of-life Do you welcome new development from other people? Are you able to answer questions/open to being contacted? Do you support/help track forks for new development?  Diagrams / Illustrations Licence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-assure-software-sustainability/","summary":"CW21 - 2021-03-30\nFelix - CI6-CW21\n Participants Eli Chadwick Iain Barrass Alice Minotto Yo Yehudi  Context / Research Domain Planning for continuation of dissemination of research outputs is an established part of a research grant application. We frequently see requests for ongoing costs for website hosting, placement of datasets in repositories or hosting of developed code in an online version control system. However, it is less frequent that considerations are made of ongoing technical staff attention to support staff responsible for code sustainability, maintanence, or data updates.","title":"End of Life Plans for Software"},{"content":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Cave-Brown-Cave-1916 - HP5-CW21\nHack Day idea proposer  This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) Escape room: Translating between RSEs and Arts \u0026amp; Humanities Researchers (Part 1)\nThis is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nContext and/or research domain Please describe the context and/or research domain to which the problem applies\nSoftware development for research in the Arts and Humanities\nProblem Description of the problem you are trying to solve\nResearchers in the Arts \u0026amp; Humanities can benefit greatly from research software, but often don’t have the kind of background in formally-structured design that a physicist or engineer does. This can make developing research software for them challenging- particularly when A\u0026amp;H problems are often defined in ways that are very different from how computational problems are defined.\nWe want to help researchers in A\u0026amp;H and RSEs to communicate better, so that they can collaborate on building research software more easily.\nUsing gamified versions of boring and dry training materials for software development, we want to make learning about software development fun and accessible.\nSolution Explanation of the solution to the problem you have identified\nVirtual escape room: Solve a set of connected puzzles to escape the virtual game room. In the course of solving the puzzles, the participants will learn key concepts from research software development.\nOur pitch: develop the Part 1 of this escape room series:Theme: Gamified activities to learn the meaning of common jargon words. E.g. API, Object, function, Sprint, version, Agile, automation\nThe escape room will be themed around learning to translate an alien language (Software development) expressed in an unusual way, so that the unfamiliar concepts can be understood in the context of our work. For example: which of these flow diagrams is the correct one? What analogy of a RSE concept can we find in humanities?\n Format: Online, can use existing websites or a GitHub repository with questions and clues to find information. Learning journey. **Aim: **The aim is to encourage participants to look for information and find out resources about software development practices and RSE related concepts themselves as they find answers to solve the puzzles. Outcome of the escape room activity: participants are familiar with 4 concepts/jargon words usually used by software developers. Participants are now in a better position to work/interact with Research Software Engineers- or to go on and learn to become digital humanities developers themselves.  Potential topics and set of activities for escape rooms for part 2 onwards (not proposed for this pitch, but idea for future collaboration):\n Set a repo to teach GitHub / version control (create with long history, ask people to find who did what, and on what days) Give a project goal that required chunking down one goal into different tasks and create clues (Agile development) Create puzzles to teach reproducibility Use interesting data table to teach about dataframe and coding using pandas Use a visualization tool or shiny app to solve different puzzles  Diagrams / illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nYou can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n(Copyright: This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 3.0, source: https://wireframe.raspberrypi.org/articles/out-now-pythonesque-anarchy-in-wireframe-16)\nSome ideas\n Goal: “Learn what an API is” NetHack https://www.nethack.org/ Ren py for the tech to create the room: https://www.renpy.org/ Story: maybe a professor in Computer Science goes missing and we need to investigate. There are clues left by the professor, an open browser with GitHub open. https://twinery.org/ https://giuliac.itch.io/the-british-library-simulator used http://ledoux.io/bitsy/editor.html https://gather.town/   ","permalink":"https://robintw.github.io/CW-ideas/cw21-escape-room/","summary":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Cave-Brown-Cave-1916 - HP5-CW21\nHack Day idea proposer  This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) Escape room: Translating between RSEs and Arts \u0026amp; Humanities Researchers (Part 1)\nThis is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.","title":"Escape room: Translating between RSEs and Arts \u0026 Humanities Researchers"},{"content":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Fox-1940 - HP9-CW21\nHack Day idea proposer Heather Turner\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nExploratory analysis of past Collaborative Ideas\nContext and/or research domain Please describe the context and/or research domain to which the problem applies\nProblem Description of the problem you are trying to solve\nMany of Collaborative Ideas have been proposed at past Collaborations Workshops. It would be great if there was a way to explore these ideas to see if there are recurrent themes, if proposed ideas have been taken on, etc. It would be useful for workshop organizers to identify potential themes/ideas for future events, e.g. as seed ideas for discussion or hack day pitches, so we can build on earlier ideas. It would be helpful for participants to know how their ideas fit in with what has gone before and who it would be good to talk to, particularly if they are new to the community.\nSolution Explanation of the solution to the problem you have identified\nThere are various possibilities to organize past ideas, or to provide a way past ideas could be explored:\n a tagged collection of posts issues on a git repository with tags that could be used for filtering a dataset or database a dashboard  Ideally the proposed solution would be easy to update with the ideas proposed at future collaborations workshops, or for the community to submit updates (e.g. if an idea is “resolved” by the idea being put into action in some way).\nExample data to include:\n people involved whether idea went on to be pitched/worked on at hack day theme of idea (sustainability, RSE career paths, etc)  Diagrams / illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-exploratory-analysis-of-past-collaborative-ideas/","summary":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Fox-1940 - HP9-CW21\nHack Day idea proposer Heather Turner\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nExploratory analysis of past Collaborative Ideas","title":"Exploratory analysis of past Collaborative Ideas"},{"content":"Collaborations Workshop 2018 - 2018-03-26\nGeospatial metadata sharing\nhttp://swdg.io/cw18- HP11-CW18\nHackday Idea Proposer\nStuart Grieve - stuart.grieve@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain\nEarth scientists who use topography data have a number of recognised data formats for their grids. These files are O(100) MBs to O(10) GBs, and while there is infrastructure to manipulate these files, there is no easy way to share, regenerate, or even uniquely identify grids.*\nProblem\nPeople cannot share large data files, but could just share the associated metadata and then regenerate the data locally. Raw data is available in archives and researchers typically cite the dataset they use but do not specify the bounds of the area of interest. Because people do not share their processed data, it becomes challenging to reproduce peoples work without dreaded emails or shipping hard drives.\nSolution\n“Least effort for most benefit”: Provide small scripts/programs to generate a reusable metadata information out of a large data file. Stretch goal to build a webapp rather than standalone scripts.\nMost of the heavy lifting has been done for this via rasterio, gdal, and other code in the OGC ecosystem but needs stitching together.\nMetadata needed:\n Dataset extent Coordinate system/projection info (OGC codes) DOI of original dataset DOI of associated paper (Optional)  Diagrams / Illustrations\n","permalink":"https://robintw.github.io/CW-ideas/cw18-geospatialmetadatasharing/","summary":"Collaborations Workshop 2018 - 2018-03-26\nGeospatial metadata sharing\nhttp://swdg.io/cw18- HP11-CW18\nHackday Idea Proposer\nStuart Grieve - stuart.grieve@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain\nEarth scientists who use topography data have a number of recognised data formats for their grids. These files are O(100) MBs to O(10) GBs, and while there is infrastructure to manipulate these files, there is no easy way to share, regenerate, or even uniquely identify grids.","title":"Geospatial metadata sharing"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 GitHub annotator/failure map - HP5-CW2CC\nHackday Idea Proposer Ilektra Christidi - ilektra.christidi@ucl.ac.uk\n Context / Research Domain Documentation in general, but especially for software project handover. All research domains.\nProblem Quite often, a lot of the detail of how and why a piece of software has been developed the way it did, is hidden inside GitHub Issue and PR discussion threads.\nThe kind of information that tends to get lost this way are the approaches that didn’t work, since the ones that did have some hope of making it to the final documentation of the package, and they are the code implementation itself. But this failures information is crucial to future developers of the code, saving them time, effort and mistakes by warning them about the things that have been tried and failed.\nAnother category of information lost this way are the “loose ends”: things that can be improved or features that can be implemented, but did not due lack of time or other reasons. These can spawn new projects/proposals, or improve the codebase in the future.\nSolution A GitHub app that would help developers keep track of the pertinent information hidden inside Issue and PR comments - not the code or commit message itself - and create a “map of failures”.\nThe easiest way seems to be to automatically populate the repo wiki with such pertinent comments, every time a predefined trigger occurs. Possible triggers could be:\n When closing an issue, you’d have to specify the reason (drop-down, prompt…?): if resolved, provide the PR that resolved it and move on with life (not added to the failures map). If not, provide a reason, which will be added to the map. Same for when closing a PR without merging. When an issue or PR stays open longer than a predefined amount of time, prompt the developer for a reason. Have a “final” kind of text that would prevent bugging them again, possibly with the option to re-start. Manually flag specific comments for persistification (with a magic string…). Hints for when to do this could be when the originally suggested way to solve an issue changes, or the development in an existing PR changes course due to code review comments\u0026hellip;  In addition to adding the comment (with a timestamp?) and the link to the Issue/PR that generated it, ideally one would like to prevent the issue, PR and related branch from being deleted in the future.\nAnother way to present the same info, but not sure how doable it would be, is to annotate a GH timeline of branches/commits with the pertinent comments.\nDiagrams / Illustrations ","permalink":"https://robintw.github.io/CW-ideas/cw19-gh-annotator/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 GitHub annotator/failure map - HP5-CW2CC\nHackday Idea Proposer Ilektra Christidi - ilektra.christidi@ucl.ac.uk\n Context / Research Domain Documentation in general, but especially for software project handover. All research domains.\nProblem Quite often, a lot of the detail of how and why a piece of software has been developed the way it did, is hidden inside GitHub Issue and PR discussion threads.\nThe kind of information that tends to get lost this way are the approaches that didn’t work, since the ones that did have some hope of making it to the final documentation of the package, and they are the code implementation itself.","title":"GitHub annotator/failure map"},{"content":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Amonette-1943 - HP1-CW21\nHack Day idea Proposer Sorrel Harriet\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nHello World! (of CI/CD)\nContext / Research Domain Please describe the context or research domain to which the problem applies\nSoftware engineering\nProblem Description of the problem you are trying to solve\nBuild a Hello World app (but make it support continuous deployment.)\nThis hack day idea is more about developing skills, and less about the idea itself.\nI want to gain experience using best practices like TDD and CI/CD, but I never seem to get around to actually doing it. I also want to explore different ways of collaborating on a group leaning/coding exercise, so this is also about experimenting with that.\nSolution Explanation of the solution to the problem you have identified\nI like the idea of doing this as a ‘mob programming’ exercise with a small group of other developers, the idea being that we can learn from and motivate each other. Maybe the end result can be packaged as an activity and/or group learning format for others to use and benefit from, but it isn’t a requirement.\nSome tutorials that might serve as starting point:\nhttps://www.digitalocean.com/community/tutorials/how-to-set-up-a-continuous-deployment-pipeline-with-gitlab-ci-cd-on-ubuntu-18-04\nhttps://hsf-training.github.io/hsf-training-cicd/06-hello-world-ci/index.html\nI think a cookbook of CI/CD recipes would be a great potential output!\nDiagrams / Illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nhttps://docs.gitlab.com/ee/ci/quick_start/\n","permalink":"https://robintw.github.io/CW-ideas/cw21-hello-world-of-ci-cd/","summary":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Amonette-1943 - HP1-CW21\nHack Day idea Proposer Sorrel Harriet\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nHello World! (of CI/CD)\nContext / Research Domain Please describe the context or research domain to which the problem applies","title":"Hello world (of CI/CD)"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 10 Idea - CI13-CW2CC\nReporter Niall Beard - niallbeard@gmail.com\nParticipants Jakob S. Jørgensen - jakob.jorgensen@manchester.ac.uk\nLucy Whalley - lucywhalley@gmail.com\nDavid Pérez-Suárez - d.perez-suarz@ucl.ac.uk\nSarah Stewart - sarah.stewart@bl.uk\nBenjamin Lee - benjamin_lee@college.harvard.edu\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all the hint text once you no longer need it.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nTraining about Programming\nProblem Description of the problem you are trying to solve\nThere was a wonderful flash talk on Monday about hovercraft and eels. The concept was that people try out new coding languages by using the paradigms and concepts of languages they’re already familiar with. However, this often doesn’t take advantage of the powerful features of the new language. This can mean they don’t get the benefits, they could suffer worse performance, and/or they find it difficult to write efficient and functioning code.\nSolution Explanation of the solution to the problem you have identified\nMy hovercraft is full of eels\nA training page that surfaces the different programming idiosyncrasies by offering them in the context of a language familiar to the learner.\nA developer seeking to learn a new language will:\n Select their target language (the language they’re seeking to learn) Select their home language (the language they’re most comfortable with) Select their current proficiency in the target language. \\  The site then presents a code implementation example in the target language side-by-side with the same implementation in the home language.\nAbout the implementation\nThe examples can easily be harvested from a website called Rosetta Code which offers example code in multiple implementations. We can select some examples that match the different tiers of proficiencies (e.g. beginner, intermediate, advanced).\nPossible Extension\nSemantic Annotations\nAdditionally, we could add semantic data to WikiData for the Rosetta Code page in order to specify what program concepts each example covers. This would enable a user to select something like ‘show me how to thread/make a web-server/iterate in Ruby as someone who knows Python’.\nPerformance\nDisplay benchmarking data for each of the examples.\nCommunity annotations\nThere are lots of ways of implementing things. Some are better than others in different usages, languages, constraints, and contexts. A community effort could be initiated to create a cumulative knowledge-base that allows users to discover the algorithms most useful for their use case. The community can contribute new example implementations, refine existing ones, and\nJupyter Notebooks\nHave these snippets as executable notebooks within the page\nDiagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n Links: Rosetta Code data here:\nhttps://github.com/acmeism/RosettaCodeData\nLinks to existing collections of guides on how to go from one language to another.\nA number of resources already exist providing introductions to features of a specific programming language, targeted at programmers familiar with other programming languages, for example\n  Moving to Python from other languages: https://wiki.python.org/moin/MovingToPythonFromOtherLanguages\n  Numpy for Matlab users: https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html\n  R for programmers used to other languages: https://www.johndcook.com/blog/r_language_for_programmers/\n  To Ruby from C/C++, Java, Perl, PHP, Python: https://www.ruby-lang.org/en/documentation/ruby-from-other-languages/\n  Matlab for C/C++ developers, video: https://www.mathworks.com/videos/matlab-for-cc-programmers-81699.html\n  C for python programmers:\nhttp://www.toves.org/books/cpy/\n  https://rosetta.alhur.es/\n  These resources are helpful but limited to non-interactive, simple lists of commands in isolation.\nWhat “My hovercraft is full of eels” provides is a dual side-by-side interactive notebook with comparisons of a feature implemented in the language a user is familiar with and a reference implementation done The Right Way in the new language.\nIdeas for design \nTable format\nSelect box \u0026amp; Visualisation\n_ of Options_\n","permalink":"https://robintw.github.io/CW-ideas/hover-eels/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 10 Idea - CI13-CW2CC\nReporter Niall Beard - niallbeard@gmail.com\nParticipants Jakob S. Jørgensen - jakob.jorgensen@manchester.ac.uk\nLucy Whalley - lucywhalley@gmail.com\nDavid Pérez-Suárez - d.perez-suarz@ucl.ac.uk\nSarah Stewart - sarah.stewart@bl.uk\nBenjamin Lee - benjamin_lee@college.harvard.edu\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two).","title":"Hover Eels"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 How do you motivate researchers to adopt better software practices? - DSR10-CW2CC\nReporter Patrick McCann - pgm5@st-andrews.ac.uk\nParticipants Rachael Ainsworth, Jason M. Gates (jmgate@sandia.gov), Jakob S. Jørgensen, Diego Alonso-Álvarez, Cerys Lewis\nNotes from the discussion Please use the area below to capture notes from the discussion session.\n   How to get people out of bad habits, create good habits.\n  \u0026ldquo;Reproducibility is like brushing your teeth\u0026rdquo;\n  Awareness? Many researchers simply don’t know there are tools which will solve these problems for them.\n  Make it easy for them\n  Onboarding checklists - can be an issue in GitHub/GitLab\n  Easier with younger developers. Hard to get older developers into open development mindset.\n  What\u0026rsquo;s in it for them? Software is not seen as the final goal, but a means to an end - why put in the extra effort.\n  Outline the benefits for them. Correlation between citations, opportunities and making outputs available.\n  Needs cultural change at senior level - software as a research output\n  GitHub as portfolio - use in recruitment\n  Some researchers don\u0026rsquo;t see themselves as programmers and their stuff not as software\n  Software publication requirements from funders, following on from OA and Open Research Data\n  Need to get people used to it.\n  Benefits to researchers of version control - ability to roll back\n  How to researchers find out about these tools? Mandatory training? Induction?\n  2-week training programme as part of the hiring process - how does that work for people already in positions?\n  These skills need to be included in education at all levels\n  Can programming lessons incorporate good practice e.g. use GitHub\n  Encourage people to start small\n  Carpentry courses can be overwhelming\n  Where are things going wrong? What good practice would address that? Agile\ndevelopment applied to team practice.\n  Link to studies that show benefits in blog\n  Software papers. Awards? Journal badges\n  Wellcome Trust policy on open research outputs\n  Altmetrics\n  Speed Blog Please use the area below to draft the speed blog. Consult https://www.software.ac.uk/speed-blogging-and-tips-writing-one for information, tips and examples.\n What are the challenges? For many researchers, the development of software is a means to an end—a chore that is necessary to allow them to get on with the real work of conducting research and publishing papers. They may not see themselves as programmers or recognise the code that they write as being software. Their supervisors or senior colleagues may not see the value of devoting perceived extra effort to following good practice.\nMoreover, good software practices can be seen as an extra burden. They involve the learning of new skills and technologies, and the application of these can seem to introduce complexity and extra work. Researchers may even be unaware of the existence of tools and resources that can help them follow good practices, let alone the benefits they may bring.\nIntroductory training events, like The Carpentries, can guide researchers into good software practices, but they can also be very intense and overwhelming, resulting in the attendees mixing concepts and without time to practice what they have learnt. If, on the contrary, researchers are left on their own, and assuming they have the interest, they might not find the correct tools or may gain an incomplete, or plainly wrong, knowledge of what developing software for research means and what adopting good software practices actually entitles.\nHowever, good software practices do bring real benefits to researchers and it is in communicating these to researchers, and in getting them to a point where they can realise those benefits, that the biggest challenge lies.\nWhat measures can be taken? Encourage people to start small. Every little bit helps. A single test is much better than no tests at all. A few lines of documentation are better than none. Spending a few minutes goes a long way. It’s not unlike going “green”: Replacing a couple single-use plastic coffee cups a week by a reusable one helps significantly. So does reducing the number of days one eats meat, which may be easier to manage for most individuals compared to going vegetarian. Hopefully the benefits become clear once started, and progress will continue from there.\nMany researchers who use good software practices have had to discover and teach themselves how to use the tools such as version control. Some universities/faculties/departments already offer training courses on such tools, but only a small part of researchers/students actually take these. Would it be possible to make mandatory Software Carpentry type course units to be taken by all students in certain subjects? This would expose students to the tools and mindset, and start them early on using good practices, or at least they would be aware of the existence of such tools later on when the need may arise. In this way the next generation of researchers would be reached. Ideally, these skills need to be included in education at higher levels, as well and across subject areas, such as part of a mandatory introduction programme as PhD student or postdoc joining the institution. Some form of credit should be given for completion; for students this would naturally be course credits toward the degree.\nOther measures that could be taken to motivate researchers to adopt better software practices are:\n Breaking down Carpentries courses into smaller blocks in order to reduce the feeling of being overwhelmed for people learning new skills. In addition, or as an alternative, to dedicated Carpentries-style training courses as part of the education, the tools could be taught indirectly by being incorporated into other courses. For example hosting course material on GitHub or using GitHub Classroom to manage a course. Can programming lessons incorporate good practice, e.g., using GitHub for distance learning (check out homework, etc.?) Using pain points within a team to find methodologies that are seen as a positive change when introduced and allowing time for these to become accepted part of day to day working. Building in training or resources as part of the onboarding process for a company or institution and making it easy to access.  The process is already well underway. Funders increasingly demand openness: Requirement of open-access publication, deposit of data sets already required by Wellcome (to be confirmed), and a natural next stage will be fully open-source code. In addition to such requirements, some more forms of positive encouragement should be considered. This could be awards for “championing” openness by making data and open-access. This could be dedicated funding opportunities to help increase open sharing of code and data. If such already exists, increase visibility.\nWhat benefits will result? Open research practices, including incorporating better software practices into the research workflow, lead to better and more efficient science. The challenges associated with encouraging researchers to adopt these practices have been described above, along with some potential solutions. But what are the benefits for researchers for working in this way?\nMcKiernan et al. (2016) demonstrates that open research is associated with increases in citations, media attention, potential collaborators, job opportunities and funding opportunities relative to more traditional closed practices. In short, the more you share your research outputs, the more opportunities you create for citations and gaining exposure.\nPublications and citations act like currency in academia, often used to assess the quality of a researcher and the metric associated with career progression. While there are flaws associated with this, one motivation for researchers to adopt better software practices is that they can lead to more publications and citable research outputs. For example, if the software is open source and well documented, it can be easily submitted to the Journal for Open Source Software, resulting in a peer-reviewed and citable publication for your software.\nOther benefits are:\n Altmetrics  Tracks impact of research output For example, tracks how many times a paper/presentation/poster/etc. has been viewed, downloaded and shared on social media (do they also track citations? - check)   “Your primary collaborator is yourself 6 months from now, and your past self doesn’t answer emails,” is a famous quote from The Carpentries. Using, for example GitHub, as a project management tool in addition to version control, allows you to easily find, access and share work.  GitHub as portfolio - use in recruitment Benefits to researchers of version control - ability to roll back   In an interview with Nature, Irakli Loladze, a mathematical biologist at Bryan College of Health Sciences in Lincoln, Nebraska says, “Reproducibility is like brushing your teeth. It is good for you, but it takes time and effort. Once you learn it, it becomes a habit.”  ","permalink":"https://robintw.github.io/CW-ideas/cw19-motivating-research/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 How do you motivate researchers to adopt better software practices? - DSR10-CW2CC\nReporter Patrick McCann - pgm5@st-andrews.ac.uk\nParticipants Rachael Ainsworth, Jason M. Gates (jmgate@sandia.gov), Jakob S. Jørgensen, Diego Alonso-Álvarez, Cerys Lewis\nNotes from the discussion Please use the area below to capture notes from the discussion session.\n   How to get people out of bad habits, create good habits.\n  \u0026ldquo;Reproducibility is like brushing your teeth\u0026rdquo;","title":"How do you motivate researchers to adopt better software practices?"},{"content":"CW21 - 2021-03-30 Bagpuss - CI2-CW21\nParticipants Sorrel Harriet (Chair)\nTeri Forey (Scribe)\nDiego Alonso Álvarez\nHeather Turner\nAlexander Konovalov\nIlian Todorov\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all of this hint text (Arial, italic, grey, size 11) once you no longer need it.\nIdeas:\n _Tool or mechanism to add comments to code, or annotating the code with feedback without creating a pull request. Better space to provide guidance. _  _Nothing wrong with paired programming or code review, but it’s synchronous (have to find time that’s convenient to everyone). If it’s in a document there’s no easy way to link it to the line of code. Almost need a google docs for code. _ Limitation with PR is you’re not reviewing the whole code. And you’re not wanting to change the code. Need something more simply than the code review packages and tools that are out there - more like editing a paper and providing a comment. https://github.com/ropensci/software-review/issues/24 - still need to copy the code chunk. _Output could be a review of existing tools. _ Can click on ‘plus’ in github to create an issue with a preview of that line of code, doesn’t work with a chunk. It’s a workaround not a solution. Could end up with loads of issues which isn’t great Collaborative calculation in the cloud - Version of jupyter notebooks which is almost like google docs where multiple users can work together. Not sure if you can have comments though - but people can add markdown cells. CoCalc.com _Could suggest a feature to an existing tool. _   _How do we fund software maintenance? _  _Almost want a kickstarter or gofundme for software, instead of something epic per funder. _ _Alternative model to finding software! Contribute to your open source. _ _Open source tool funded by kick starter - _ _Github sponsors and javascript asks for donations. _ _How do you then channel that small funding stream into an project? Is it time? One day for an RSE? Needs to be planned in. _ Improvements and maintenance funding options do exist _What about a shared pot that projects can apply? Would need a plan - but keep it lo-key. _ _Some funding could go to central RSE folk, keep the software the department is creating can be maintained. Subscription to the central RSE team to keep the software maintained. Provide it as an actual service. _ What happens when the PI (or whole lab) leaves academia? Should it continue to get maintained? Where are the benefits to the university?   Technical debt on projects. How do you keep track/monitor? Keep a record? Give an idea to the current health of a project?  Some tools can provide a guidance - like codecov Where decisions have been made but aren’t documented or compromise some part of the project - workarounds and easy choices that weren’t necessarily the best. https://ropensci.org/r-universe/ Activity on the github repo. How do you trust a project? Are the developers established? _It’s easy to make mistakes and hard to review everything. Snapshot of whether there’s potentially a problem. _ _If software grows organic it’s hard to keep track of what decisions where made and by who. _ _Needs to be no judgement - understanding that not all developers are working at the same level. _ _Technical debt can also come from a reasonable decision at the time, but then goes out of date (like versioning). _ Self evaluation of your tool, without fear of repercussions. Health check list. Make it open and visible.   _How can we improve carpentries and training to include sustainability? _  _After tests and documentation, how do we teach maintenance? Add new parts of good practise. _ _Intermediate Python course from SSI. https://www.software.ac.uk/news/new-intermediate-software-development-training-course-be-piloted _    _Could be an imaginative idea, or based on a real problem. Could be an idea what doesn’t go in hack day. _\n_ _\nThe Research Software Sustainability Concordat\nContext / Research Domain Please describe the context or research domain to which the problem applies\nResearch Software Maintenance Funding. Covers all domains of research.\nProblem Description of the problem you are trying to solve\nHow to encourage and ensure software maintenance gets sufficiently funded.\n_Creating software is good, but not enough: unlike research publications, which do not require maintenance, the software, to remain useful, needs to be maintained, and that requires funds. _\n_Inspired by various Concordats, e.g. The Concordat to Support the Career Development of Researchers (https://www.vitae.ac.uk/policy/concordat), The concordat for research integrity (https://www.universitiesuk.ac.uk/policy-and-analysis/reports/Pages/the-concordat-for-research-integrity.aspx), we would like to introduce the idea of the Research Software Sustainability Concordat. _\nSolution Explanation of the solution to the problem you have identified\n_The solution is to generate models for funding research software maintenance, then to write a white paper that is shared with funders and universities. There would be a commitment or pledge that they would sign to agree that they’d follow these principles: the Research Software Sustainability Concordat. _\nPossible models include:\n Have a public source of funding (similar to gofundme etc.) that institutions and funders could donate to and the money would be then made available to projects on application.  _Any sized project could apply, from small single-maintainer projects through to language core-developers (e.g. Python Software Foundation). _ _Application form would be very lightweight and community reviewed. _   Change the funding application form to include a section on what open-source tools will be used, and what proportion of the funding requested will be going to their maintenance (1-5% for example would go to python foundation, numpy, matplotlib). This source of funding could go straight into the plan above (instead of directly to the specific projects). In other words, this introduces a notion of Software Overheads. _Central RSE groups generate a subscription plan where projects can set aside some funding for continued maintenance, or where core funding can be set aside to support the maintenance of any software project applying to it. _ Generate awareness of the software and engage with or create a community of practitioners that can provide effort, funding or contribute to proposals to ensure the sustainability, maintenance and further development of the project. This should take into account that different projects would have different critical mass of a community, as well as different stages of the software project lyfecycle, from active development to reaching the end of shelf life.  Diagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nLicence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-getting-software-maintenance-funded/","summary":"CW21 - 2021-03-30 Bagpuss - CI2-CW21\nParticipants Sorrel Harriet (Chair)\nTeri Forey (Scribe)\nDiego Alonso Álvarez\nHeather Turner\nAlexander Konovalov\nIlian Todorov\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all of this hint text (Arial, italic, grey, size 11) once you no longer need it.","title":"How to encourage and ensure software maintenance gets sufficiently funded"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 How to map out software and data skills lessons like Duolingo - CI8-CW2CC\nReporter Neil Chue Hong - n.chuehong@googlemail.com\nParticipants Dan Katz, Jeremy Cohen, Neil Chue Hong, Olivia Mitchell, Victor Koppejan\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all the hint text once you no longer need it.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nAt present, there is no “roadmap” which makes it easy for learners to understand what topics they should move on to next to improve their skills in the areas of software development and data analysis. Additionally, trainers have no standard framework that lets them tweak their lessons to different fields, by showing what skill topics and proficiency levels might be applicable to that field.\nProblem Description of the problem you are trying to solve\nAlthough many existing initiatives have tried to map out learning progression, many are overly complex with a level of detail that is too confusing for people who do not have a primary background in the space. They often combine general concepts with specific tools and are hard to maintain and keep up to date.\nWhat we would like is a representation of learning pathways/routes, with well-defined “prerequisites”, “learning outcomes” and “postrequisites”, that enables learners to understand what they could or should learn next, and would allow trainers to categorise/tagging their material. It then allows people to understand what are the most used / most useful things to learn in any particular discipline\nThe biggest challenge is understanding what level of detail / granularity the nodes should be at, and how to agree what the links between nodes should be.\nSolution Explanation of the solution to the problem you have identified\nDefine a metadata schema for training material (or identify a suitable existing one)\nDefine specific metadata for existing lesson material (including relationship to other existing material, such as “prerequisites”, “learning outcomes” and “postrequisites”)\nDefine representation(s) for the metadata that can show relationships of interest to different types of viewers\nBuild tool(s) that visualize the relationships and the metadata.\nDetermine how to maintain metadata over time.\nSetup a reviewing procedure for the points above using existing github or equivalent frameworks.\n(Very far fetched) build tools that automate the combination of lessons and build new syllabi based on the graph.\nDiagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nDiscussion below this point Initial ideas proposed:\n Victor: Automatically scraping Carpentries material to create “Lighterweight” material, put it into Jupyter notebooks Jeremy: how do you bring together communities and link that to an understanding of how doing this might help things going forward Neil: How do we help support people who are running events to make their events better, specifically making the events more inclusive - where the support can be done via documents, not via personal support Dan: How could there be more funding for software? Making it easier for people who use open source research software to contribute money Olivia: Using Python to code (add metadata) to data, text, and images in the humanities. Making this more more useful to other subjects.  Discussion\n Dan: How does a new school/department/disciplinary community use existing material produced by others and adapt it / make it relevant with the minimum of effort  Similar to Olivia - by trying to make it easier to apply the techniques developed in one area to another   Jeremy: Roadmap for training  Software and Data Carpentry - where do I go next for each domain   Victor: did follow-up drop-in sessions and surgeries Jeremy: bottom up understanding of software development vs top down (problem focused) Olivia: learnt the techniques that were directly related to the problem to be solved, then where to go next Jeremy: how to signpost where to go next Victor: hard to explain why some programming concepts are useful, without an example  Similar underlying roadmap, with different discipline specific examples   Neil: Skill trees - e.g. learning how to cook - basic skills you need, i.e. learn how to use an oven. Then you could progress towards, say, simple cake making, etc. How would a roadmap work in practice - ensure that they are easy to translate, easy to signpost (can you easily recognise where you are on a roadmap?). Can we ensure these roadmaps are not too expensive to maintain/update? How would you create and design such a roadmap? Does this already exist?  Example: https://en.wikipedia.org/wiki/Common_European_Framework_of_Reference_for_Languages Does this become a directory of training courses?    (A bad example of how to do pathways)\n How would we keep this maintained?  How would we understand how to source the links for what next?  Is this the responsibility of the Prerequisites and (post-requisites / learning outcomes)   Developers of new courses and maintainers of existing courses could be responsible for updating the graph data for their courses, once the idea of a graph is accepted and the initial graph has been created  Use the wikipedia \u0026ldquo;rules\u0026rdquo; \u0026amp; processes to approve/edit the graph data   People would add metadata / tags to their lessons containing learning prerequisites and learning outcomes. These could be treated similarly to current issue / pull request system in place for carpentries lesson development. How do source the common identifiers for these prerequisite and postrequisite “topics” What levels should these topic   Is a tree the best representation for this?  Is it a linked graph?  The level of detail is important - you don’t need the deep level of details C.f. data science skills roadmap, want at the level of text mining, statistics, visualisation     What’s the metadata schema that you need for each “location” on the roadmap?  Relevant Domains Proficiency Level Programming Language Generality of lesson: E.g., general concept, specific tool “High level Topic / pathway”? E.g. Data analysis (or is it data cleaning - what level)? Could use expert judgement or could mine existing materials to identify what people are already using    ","permalink":"https://robintw.github.io/CW-ideas/cw19-map-skills/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 How to map out software and data skills lessons like Duolingo - CI8-CW2CC\nReporter Neil Chue Hong - n.chuehong@googlemail.com\nParticipants Dan Katz, Jeremy Cohen, Neil Chue Hong, Olivia Mitchell, Victor Koppejan\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two).","title":"How to map out software and data skills lessons like Duolingo"},{"content":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Hopper-1949 - HP12-CW21\nHack Day idea proposer Faruk Diblen, Daniel Garijo, Carlos Martinez, Mathew Bluteau, Paddy McCann\nSlack: #howdescribedis\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nHowDescribedIs\n Further automation of howfairis  Context and/or research domain Please describe the context and/or research domain to which the problem applies\nhowfairis is a tool to measure level of adherence to the five recommendations on fair-software.eu website. It allows users to automatically check the compliance of their code and produce a badge displaying the score of their software.\nExample badge generated by howfairis:\nSOMEF is a tool for extracting automatically metadata from code repositories, based on their readme file. SOMEF creates a Codemeta.json file automatically.\nProblem Description of the problem you are trying to solve\nhowfairis aims to be as easy-to-use as possible for researchers. However, meeting these recommendations requires some manual labor. We would like to automate this as much as possible, for example by automatically generating Codemeta.json files for your repo based on the descriptions that are already there.\nSolution\nExplanation of the solution to the problem you have identified\nSOMEF can help generate codemeta files automatically. With the information identified by SOMEF, we can determine which metadata is missing, hence prompting developers to improve their readmes with that information, or complete the Codemeta.json files created by SOMEF.\nWe would like to create a GitHub action which makes this happen automatically.\nThanks to this work, users will help structure their software descriptions in a machine-readable manner, making them easier to find (through keywords, faceted search, etc.)\nDiagrams / illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nCurrent workflow: Proposed approach: Action plan for hackday  Test somef Test howfairis Howfairis GH action: Create initial GH action that checks if there is a codemeta (or citation?) file  If not, run SOMEF   (Step 0) Overview of GitHub Actions (Step 1) Github action to generate codemeta.json (Step 1.1) Create codemeta.json (Step 1.2) Send a PR with created file (Step 2) Detect citation information is present (codemeta.json) (Step 2.1) If not, run action from Step 1)   ","permalink":"https://robintw.github.io/CW-ideas/cw21-howdescribedis/","summary":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Hopper-1949 - HP12-CW21\nHack Day idea proposer Faruk Diblen, Daniel Garijo, Carlos Martinez, Mathew Bluteau, Paddy McCann\nSlack: #howdescribedis\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.","title":"HowDescribedIs"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 1 - CI1-CW2CC\nReporter Rachael Ainsworth - rainswor@gmail.com\nParticipants Rachael Ainsworth (Chair), Simon Hettrick (scribe), Claire Wyatt, Gabriel Hanganu, and Chris Mentzel\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all the hint text once you no longer need it.\nAgenda \u0026amp; info: https://software.ac.uk/cw19/collaborative-ideas-and-hackday-ideas\nContext / Research Domain Please describe the context or research domain to which the problem applies\nThe success of the RSE community grew from a small group of people identifying a new role in academia that was important, growing and almost completely unrecognised. We want to identify new roles so that we can help them repeat the same success.\nProblem Description of the problem you are trying to solve\nThere are a number of roles in research that make a significant contribution to research, but go unrecognised. Once these roles have been identified, we can name them and help them gain recognition - the difficulty lies in identifying the roles.\nSolution Explanation of the solution to the problem you have identified\nWe’ll use job sites (probably jobs.ac.uk) to identify new roles:\n Scrape currently available job adverts Separate the data into different categories based on job title Start with postdoctoral positions (will require some simplification of the different titles used) and conduct a word frequency analysis on the associated job advert text to gain insight into the described roles Attempt to identify the “key responsibilities” then analyse this data (potentially using NLP methods) to simplify responsibilities which can then be compared across job adverts Identify the most similar roles (say, top five across each role) then review them manually to identify any names, terms or language that identifies the role (or is being used to identify it) Take the identified names, terms or language and search through all job adverts to identify any roles that could be associated with it. If there’s a sufficient number of similar of roles identified, use the information to build a profile of the role. And name it, if necessary. Publish all of the roles we discover and attempt to get people to rally around them.  Additional analysis\n Take the roles we’ve identified Review the balance of fixed term and permanent contracts If the role is mainly associated with permanent contracts, this could indicate that the role is accepted, if they are mainly fixed term, then it could indicate that the role is unrecognised Conduct a frequency analysis on job titles Identify job titles, other than postdoc, that are numerous and do not appear to be recognised Conduct the main analysis, as described above on postdoctoral jobs, but with these new job families.  Diagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw19-identify-new-roles/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 1 - CI1-CW2CC\nReporter Rachael Ainsworth - rainswor@gmail.com\nParticipants Rachael Ainsworth (Chair), Simon Hettrick (scribe), Claire Wyatt, Gabriel Hanganu, and Chris Mentzel\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4.","title":"Identify new roles within Academia"},{"content":"CW21 - 2021-03-30 Heathcliff - CI8-CW21\nParticipants Please list the participants here\nConnie Clare\nLouise Brown\nSam Haynes\nWill Furnass\nPatricia Herterich\n Problem Improving data visualization literacy\nResearch domain:\nResearch communication / Data science / Visualization\n“Follow the science” has become the tagline for 2020, but what is “the science”? Who defines it and is it really infallible?\nWe have all seen many graphs and statistical summaries over the last 12 months, many of them not being clear to a lay audience. This might have been because they were, accidentally or deliberately, too complex or misleading. It can be difficult for the public to interpret data and graphs.\nSolution Provide a tool which will enable the public to be able to interpret and robustly critique interpretations of data presented in the media and decide whether they are showing what they claim to show.\nPhase 1\nCreate an interactive website to show different interpretations of the same data, including many data visualisation faux pas from press articles relating to issues of broad interest. Show examples of the same set of data displayed in different ways.\nThe sort of problems that examples might expose could be log scales with 0 value, adjacent graphs with vastly different scales, heat maps with similar colour schemes but different values, disjoint axes. This could be accompanied by prose describing practices or alternative graphics that address the highlighted issues.\nPhase 2\nGrowing a community for exposing the misrepresentation of data. People can highlight examples of data visualisation/statistics that they want to question and other people/experts can pick apart issues or suggest different interpretations.\nPhase 3\n_Creating a peer review process for that community similar to the rOpenSci community to ensure that proposed reinterpretations of graphics and statistical summaries are of sufficient quality. _\nDiagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n_(https://towardsdatascience.com/stopping-covid-19-with-misleading-graphs-6812a61a57c9)_\nLicence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\nTeam ","permalink":"https://robintw.github.io/CW-ideas/cw21-improving-visualisation-literacy/","summary":"CW21 - 2021-03-30 Heathcliff - CI8-CW21\nParticipants Please list the participants here\nConnie Clare\nLouise Brown\nSam Haynes\nWill Furnass\nPatricia Herterich\n Problem Improving data visualization literacy\nResearch domain:\nResearch communication / Data science / Visualization\n“Follow the science” has become the tagline for 2020, but what is “the science”? Who defines it and is it really infallible?\nWe have all seen many graphs and statistical summaries over the last 12 months, many of them not being clear to a lay audience.","title":"Improving data visualization literacy"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19  2019-04-01 to 2019-04-03 Improving The Turing Way - HP11-CW2CC\nHackday Idea Proposer Kirstie Whitaker - kwhitaker@turing.ac.uk\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Collaboratively building a resource to make reproducible research “too easy not to do”\nProblem Reproducible research is necessary to ensure that scientific work can be trusted. Funders and publishers are beginning to require that publications include access to the underlying data and the analysis code. The goal is to ensure that all results can be independently verified and built upon in future work. This is sometimes easier said than done. Sharing these research outputs means understanding data management, library sciences, software development, and continuous integration techniques: skills that are not widely taught or expected of academic researchers and data scientists.\nSolution The Turing Way is a handbook to support students, their supervisors, funders and journal editors in ensuring that reproducible data science is “too easy not to do”. It will include training material on version control, analysis testing, and open and transparent communication with future users, and build on Turing Institute case studies and workshops. This project is openly developed and any and all questions, comments and recommendations are welcome at our github repository:https://github.com/alan-turing-institute/the-turing-way.\nhttps://the-turing-way.netlify.com\nhttps://github.com/alan-turing-institute/the-turing-way\nhttps://github.com/alan-turing-institute/the-turing-way-book\nhttps://gitter.im/alan-turing-institute/the-turing-way\nDiagrams / Illustrations Come and join our amazing community!! 😍😎🙌👾🌟✨🌈💐\n","permalink":"https://robintw.github.io/CW-ideas/cw19-improving-turing-way/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19  2019-04-01 to 2019-04-03 Improving The Turing Way - HP11-CW2CC\nHackday Idea Proposer Kirstie Whitaker - kwhitaker@turing.ac.uk\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Collaboratively building a resource to make reproducible research “too easy not to do”\nProblem Reproducible research is necessary to ensure that scientific work can be trusted. Funders and publishers are beginning to require that publications include access to the underlying data and the analysis code.","title":"Improving The Turing Way"},{"content":"o### Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03\nCollaborative Idea Group 3 - CI9-CW2CC\nReporter Aleksandra Nenadic - anenadic@gmail.com\nParticipants Aleksandra Nenadic\nRobin Long\nLouise Bowler\nJess Ward\nIlektra Christidi\nJames Graham\n Context / Research Domain Early-career researchers often attend training and workshops orientated around learning good programming techniques and other best practices for producing reproducible, robust research. Training of this type (Carpentries, short courses etc.) is applicable for researchers in a wide variety of domains.\nProblem People attending training do not always apply the learning to their research after it. There is a problem with motivation of training (e.g. people are in early stages of their PhDs and do not have a concrete problem yet) and sometimes they only realise the importance of the training once something has gone wrong - perhaps applying the lessons would have prevented / mitigated this (e.g. Version Control). There is a fine balance between teaching people these techniques too early or too late. Also, people sometimes feel overwhelmed with the stuff they have been taught (e.g. it may be too abstract) and find it difficult to take it back to their individual research problems and apply it in practice.\nSolution Infrastructure to support following up after a workshop / training session. The aim would be to keep people reminded of the lessons, but also to offer additional guidance if required to apply the training into practice.\nThis may include:\n A checklist / handbook of how to apply the lessons to your own work A way to manage volunteer time to help - e.g. office hours type thing - needs to fit the requirements of the audience Infrastructure for managing in-person meetings / surgeries (including CoC for setting a positive vibe and a welcoming environment (in particular for beginners) to ensure people feel invited to ask all sorts of questions and can bring their code in any state)  Diagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nAlternative Ideas GitHub Annotator idea Context / Research Domain Documentation in general, but especially for software project handover. All research domains.\nProblem Quite often, a lot of the detail of how and why a piece of software has been developed the way it did, is hidden inside GitHub Issue and PR discussion threads.\nThe kind of information that tends to get lost this way are the approaches that didn’t work, since the ones that did have some hope to make their way to the final documentation of the package, and they are the code implementation itself. But this information is crucial to future developers of the code, saving them time, effort and mistakes by warning them about the things that have been tried and failed.\nAnother category of information lost this way are the “loose ends”: things that can be improved or features that can be implemented, but did not due lack of time or other reasons. These can spawn new projects/proposals, or improve the codebase in the future.\nSolution A GitHub app that would help developers keep track of the pertinent information hidden inside Issue and PR comments - not the code or commit message itself - and create a “map of failures”.\nThe easiest way seems to be to automatically populate the repo wiki with such pertinent comments, every time a predefined trigger occurs. Possible triggers could be:\n When closing an issue, you’d have to specify the reason (drop-down, prompt…?): if resolved, provide the PR that resolved it and move on with life (not added to the failures map). If not, provide a reason, which will be added to the map. Same for when closing a PR without merging. When an issue or PR stays open longer than a predefined amount of time, prompt the developer for a reason. Have a “final” kind of text that would prevent bugging them again, possibly with the option to re-start. Manually flag specific comments for persistification (with a magic string…). Hints for when to do this could be when the suggested way to solve an issue changes, or the development in an existing PR changes course due to code review comments\u0026hellip;  In addition to adding the comment (with a timestamp?) and the link to the Issue/PR that generated it, ideally one would like to prevent the issue, PR and related branch from being deleted in the future.\nAnother way to present the same info, but not sure how doable it would be, is to annotate a GH timeline of branches/commits with the pertinent comments.\nDiagrams / Illustrations Notes:\nIllekra: documentation needed for handover, issues and pull requests hide many information and wealth of knowledge and documentation. What happens if something fails or is abandoned. Or pull requests stays for a year unattended. What do you do when someone else inherits this projects. Pull requests to stay open too long - to poke the person responsible, why something is abandoned, flag things to trigger certain actions and transfer them into wiki into github.\nLouise: Thing that are useful, important - a way to flag them is needed.\n_Jess: Map of the failures, so you do not take the same turn that people have already been before that did not work. _\n_Annotate a timeline? Talking about comments not a commit. Shove comments into permanent #documentation. _\nIdea 2 - Docuflow Context / Research Domain Please describe the context or research domain to which the problem applies\nDocumentation in software or projects\nProblem Description of the problem you are trying to solve\nMany pieces of software lack documentation. There can be many reasons for this such as not knowing: How to document, Why to document, What types or documentation, or what methods exist to document.\nSolution Explanation of the solution to the problem you have identified\nCreate a flow chart / board displaying concepts under categories. This links to descriptions of Why that concept is need, how to enact it, and tools/links that can be useful.\nDiagrams / Illustrations ReadMe:\nWhy?\nREADME files should help people get started with installing the software and running it. Without it user may not know how to install or use the software.\nHow?\nREADME files are usually a text file (.txt). These would README files typically contain instructions and additional help as well as details about patches or updates.\nYou can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nRobin: how to document things - documentation templates - simple web page resource information you select the type for documentation that you want or are creating with info on how to comment e.g. for a programming language and there are links to read more about each of the resources (with a small description for each). Almost like a hidden flowchart of things that need to be done.\n_James: You should provide licence, that gives you one start, then more metadata gives you 2 stars, building like levels of progression of what needs to be done with an idea of building onto what can I do to make my dataset better. _\nAleks: Guidelines are useful. It’s often not obvious to people what decisions they should be making. E.g. Should I have a readme (yes), should it be Markdown? Are other formats okay?\n_Louise: Guidance and having step by step ways of doing things is important. _\nIllekra: are there standards or guidelines for this.\nJames: level one: README and licence files, but then more higher up people would argue what goes in the process. Some helps and prompt and links about what licence to chose, what should go into README file, etc.\nJess: even very fundamental guidance what goes into README.\n_Robin - in the templates - we need guidance with info on why this particular things is important to do this and how to do it. _\nLouise: Community ready checklist built into GitHub - under a repo within a github organisation then Insights/Community but only for public repos - maybe pro only accounts on GitHub have this. But only one person from a group knows about this and the rest were not aware.\nIdea 3 (more of a problem at this stage!) - some sort of infrastructure to follow up after training Context / Research Domain Please describe the context or research domain to which the problem applies\nEarly-career researchers often attend training and workshops orientated around learning good programming techniques and other best practices for producing reproducible, robust research. Training of this type (Carpentries, short courses etc.) is applicable for researchers in a wide variety of domains.\nProblem Description of the problem you are trying to solve\nPeople attending training do not always apply the learning to their research after it. There is a problem with motivation of training (e.g. people are in early stages of their PhDs and do not have a concrete problem yet) and sometimes they only realise the importance of the training once something has gone wrong - perhaps applying the lessons would have prevented / mitigated this (e.g. Version Control). There is a fine balance between teaching people these techniques too early or too late. Also, people sometimes feel overwhelmed with the stuff they have been taught (e.g. it may be too abstract) and find it difficult to take it back to their individual research problems and apply it in practice.\nSolution Explanation of the solution to the problem you have identified\nInfrastructure to support following up after a workshop / training session. The aim would be to keep people reminded of the lessons, but also to offer additional guidance if required to apply the training into practice.\nThis may include:\n A checklist / handbook of how to apply the lessons to your own work A way to manage volunteer time to help - e.g. office hours type thing - needs to fit the requirements of the audience Infrastructure for managing in-person meetings / surgeries (including CoC for setting a positive vibe and a welcoming environment (in particular for beginners) to ensure people feel invited to ask all sorts of questions and can bring their code in any state)  Diagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nLouise: Reproducible research - courses given to students - but they still do not know how to do it and take it into practice.\nPost-workshop surgeries to help with this. LEt people come for training for the second time.\nJess: Give pilot projects to students post training e.g. play with git.\n_Problem with motivation - people come too early and do not know why this teaching is valuable. _\n_Illektra: mentoring scheme, follow up with students, set monthly meetings for this. Sitting and coding with them also helps, 1-2-1 approach. _\nAleks: Like a post-workshop aftercare? Some people come to SWC twice, the first time they didn’t quite see why it was important, come back once they’ve had the problem and understand the importance\nRobin: Bring your own problem, almost 1-2-1 sessions\nJames: some RSGs have this - an RSE comes and spends an hour every other week with a certain project, almost like a temporary RSE placement in a particular group or project.\nLouise: The above is great - really rewarding when it works, but time is an issue for most RSE groups.\n_Illektra: Community version of support - remote and using screen sharing, distributed mentoring. _\nRobin \u0026amp; Illektra: we may need github for this and than have some sort of matching between requests and mentors, or they can just scroll through and give comments\nJess: Someone volunteers an hour of their time and people can come and talk, would be useful for beginners in particular, set the vibe that there are no stupid questions\nJames: most people do not think their code is good enough to share, but need to make clear that we do not judge people for their code and some kind of policy or guidance to help improve and give advice to researchers writing code - make sure it’s fair and constructive - they have been trying to implement this at Soton, would like to do this but still at the initial policy level\nRobin: not specific RSE help but questions around - am I putting enough comments, is my code in the right style for the programing language used?\nJess: documentation around whether someone else can reproduce this piece of code?\nIllektra: The SSI should provide this system in some way for local RSGs to use\n","permalink":"https://robintw.github.io/CW-ideas/cw19-afterworkshopsupport/","summary":"o### Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03\nCollaborative Idea Group 3 - CI9-CW2CC\nReporter Aleksandra Nenadic - anenadic@gmail.com\nParticipants Aleksandra Nenadic\nRobin Long\nLouise Bowler\nJess Ward\nIlektra Christidi\nJames Graham\n Context / Research Domain Early-career researchers often attend training and workshops orientated around learning good programming techniques and other best practices for producing reproducible, robust research. Training of this type (Carpentries, short courses etc.) is applicable for researchers in a wide variety of domains.","title":"Infrastructure to support following up after a workshop / training session"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Interoperability \u0026amp; Continuous Integration - DSR2-CW2CC\nReporter Alejandra Gonzalez-Beltran - University of Oxford, http://agbeltran.github.io/,twitter: @alegonbel alejandra.gonzalez.beltran@gmail.com\nParticipants  Kirstie Whitaker, Alan Turing Institute, https://whitakerlab.github.io, twitter: @kirstie_j, kwhitaker@turing.ac.uk Mosè Giordano, UCL, https://giordano.github.io, Twitter: @MoseGiordano Richard Gilham (Met Office) richard.gilham@metoffice.gov.uk Aleksandra Nenadic, The Software Sustainability Institute, a.nenadic@manchester.ac.uk Alexander Konovalov, University of St Andrews, alexander.konovalov@st-andrews.ac.uk Adrian Castravete, figshare, adrian@figshare.com  Notes from the discussion Please use the area below to capture notes from the discussion session.\n What is the definition of interoperability? Data (validation), systems, configuration\nMetadata in github and check validation\nSwagger for API definitions, describe what your data should look like for request and response\nIntegration tests to check the data\nMeta-languages\nWhat kind of training is needed in this aspect? What SSI can do to support this intermediary level training? What materials are needed?\nWhat is the meaning of being interoperable? What is the metric that measures interoperability? Continuous integration as the tool that could help to achieve it. Interoperability as an end goal.\nOther view is continuous integration as the tool that allows you to do integration testing and then interoperability as one of the steps along the way\nWhat do you we mean for continuous integration?\nCI for testing but actually is a part.\nMaking sure that your systems communicate like that\nRegression tests, continuous means I’m running them for any change in the code; the action is triggered by every commit.\nWeekly test payloads - HPC for testing to deal with the Met Office data\nFoundation of interoperability - as CI runs in a “different machine”\nFreezing/pinning library versions -\nDefining continuous integration:\n integration: you’re combining all the new versions into the main project and running tests to see if you’ve changed the behaviour of the software continuous: you’re ALWAYS testing, every change you make triggers a new run of the suite of tests  Defining integration:\nProblem with dependencies - mock testing - how can CI help in testing system interoperability? Can it be used?\nDocumentation-driven development vs test-driven development, this is the next step - you need to figure out what you need and what you are going to output - then you write your doc stings/method signatures - then write the tests based on the spec and then you write the code.\nIn terms of training, can you talk about testing and testing quality, without mentioning interoperability? Yes, you can teach them separately and then bring them together. One is a practice , another one is a goal. It is the mindset, you need to understand the concept of someone else will be doing something else with your code or extending your code or dataset - there should be some consideration a priory of what that person\u0026rsquo;s will need. System interoperability is moving towards continuous integration. No one knows how to review code when it is submitted to a journal.\nNotion that someone else will use your code, someone else will use your dataset\nData standards\nMRI data, brain imaging, machine learning people would like interoperability standards, so it is driven by research.\nStandard, not a tool. Standard as a concept, not just a tool. You are working with concepts rather than specific things, as people get bogged down in a specific tool. People need to appreciate that the value is not in their lines of code or their data it’s what they do with it. People who see value in their source code - they won’t share. It is closed off and not interoperable.\nSoftware horror stories due to interoperability issues: NASA, use of metrics units and English units.\nSpeed Blog Please use the area below to draft the speed blog. Consult https://www.software.ac.uk/speed-blogging-and-tips-writing-one for information, tips and examples.\n What is the relationship between continuous integration practices and interoperability? Continuous integration (CI) practices and interoperability are two separate concepts that can also complement each other in practical terms, but first let’s try to motivate why different people in an academic ecosystem would care about these two concepts.\nCase study 1: Jane, a researcher who wants other people to use her data.\nJane needs to think at the beginning of her study about what the other users will need to know when the data collection is complete. She thinks about documenting her protocol, adding metadata to each of the variables she collects, and (if available) adhering to a particular data standard relevant to her research field. She wants to make it really easy for new people to download her data and know what each row, column and file contains.\nIt’s great that Jane is thinking about interoperability at the start of her project\u0026hellip;but we all know that things may change as the real data starts coming in. Maybe there needs to be an additional column or free text comment? Perhaps there will be an additional file to note repeated measurements? In these cases it’s good to think about some tests to make sure that the documentation stays in sync with the actual data. Specially when using an existing data standard, it is necessary to add tests checking that the representation is valid after every change. Thus, we’d recommend that she continuously integrates her data with tests as she proceeds with her study, rather than wait until the end to fix all the things that changed in the design.\nCase study 2: João is a research software engineer who wants other people to use his software.\nWe recommend that João talks to a lot of potential users of his code. The main thing he needs to think about at the beginning of the project is what format they’re expecting to read the data in from, and how they expect the output data to look. What he’ll probably find is that different teams have different requirements, so he might want to consider building a few different input/output commands, and adding some continuous integration tests to make sure that they work as he builds the code. If the researchers have to do some additional work to re-format their datasets before they hit this point in their workflow they’re much less likely to use this new tool. If his software is interoperable with other tools that researchers are using then hopefully they will adopt this new process.\nCase study 3:Juan is a data librarian who wants to make it easy for researchers in the digital humanities to access and reuse lots of different datasets for their natural language processing analyses.\nEach of these different research groups are using different corpora and that means their analysis code is written specifically for their corpora and it makes it difficult to adapt their code for others. One thing that Juan can do is work on making the most popular collections interoperable. He can write a little piece of code that will move one corpus into the format of a different one. Before the researchers use this transformed data they should probably check that it matches what they expect! Are there any empty columns? Are the values scaled in a different way? If not, then they should tell Juan that his piece of code needs updating. If they are continuously integrating these changes then Juan doesn’t have to go running around the department making sure that everyone else is using the most up to date (and most correct) version!\nWhat is interoperability? Interoperability is usually defined as the capability of a system to exchange and make use of information. There are different aspects of interoperability: interoperability at the data level (systems exchanging data) and interoperability at the systems level (systems interacting and sharing common interfaces). Data interoperability can be further categorised between syntactic and semantic interoperability. Syntactic interoperability concerns the use of data formats, while semantic interoperability refers to the uses of common vocabularies. Standards are fundamental resources to achieve interoperability.\nWhat are continuous integration practices? Continuous integration is a tool that can help in achieving data and system interoperability. For example, via continuous integration it is possible to validate data against the specific standards. CI can also be used to verify requests and responses when defining API interfaces.\nContinuous integration (often abbreviated as CI) is the next step after the project established a set of regression tests (which could be integration tests, unit tests, or both). Using CI tools, one can run these tests for every change made in the code (e.g. commit to the master branch) or being proposed (in the form of a pull request). It helps to ensure that suggested/committed changes do not break the functionality of the application. “Continuous” means that the set of tests is run for EVERY change and not, for example, nightly or weekly - the latter approach will work if computational resources are limited, but will make identifying changes that broke it more difficult. Note: using CI efficiently requires certain commit discipline: we recommend to commit often and made commits atomic: e.g. do not combine several unrelated changes in one commit, and do not spread related changes in several commits (this will break bisecting the history of changes). [Maybe too many technical details, needs shortening].\nCI tools allow to automate testing in a range of different combination of settings (OS, dependencies, configuration, etc.)\nWhat you can test with CI if you have data, not software?\n Run automated tests that check data integrity (e.g. format of each entry matches the documentation) and consistency (e.g. there are no logical contradictions between values of different variables) That data may be processed by a variety of tools working under different OS, built in various settings (e.g. 32-bit, 64-bit)  How Continuous Integration can help achieve interoperability? What is the metric that measures or maintains interoperability? Continuous integration is a tool that can help to achieve interoperability by providing means to test what you are interested in over all plausible use cases. Successful use of integration testing achieves the aim of interoperability.\nInteroperability is about standards and concepts, not reliance on specific tools. Tools can help ease the workflow to achieving it.\nFoundation of interoperability - that fact that CI runs on a “different machine”.\nOther view is continuous integration as the tool that allows you to do integration testing and then interoperability as one of the steps along the way.\nWhat do you we mean for continuous integration?\n_CI for testing but actually is a part. _\nMaking sure that your systems communicate like that\nRegression tests, continuous means I’m running them for any change in the code; the action is triggered by every commit.\nWeekly test payloads - HPC for testing to deal with the Met Office data\nHow can training help addressing the potential skills gap to apply Continuous Integration in the context of Interoperability? Courses on CI and interoperability can be totally independent of each other, and in fact, teaching on each of these concepts does not need to include mentions of the other concept. We believe that there is an opportunity to offer separate training courses around (1) quality of code and testing and (2) interoperability, and then bring them together. One can be thought of as a good practice, while the other one is the end goal. Interoperability is also the mindset - people need to understand and be trained in the concept of someone else using, extending or doing something entirely else with their code or dataset - so there should be some consideration a priory of what that next person\u0026rsquo;s may do or need.\n","permalink":"https://robintw.github.io/CW-ideas/cw19-interoperability-integration/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Interoperability \u0026amp; Continuous Integration - DSR2-CW2CC\nReporter Alejandra Gonzalez-Beltran - University of Oxford, http://agbeltran.github.io/,twitter: @alegonbel alejandra.gonzalez.beltran@gmail.com\nParticipants  Kirstie Whitaker, Alan Turing Institute, https://whitakerlab.github.io, twitter: @kirstie_j, kwhitaker@turing.ac.uk Mosè Giordano, UCL, https://giordano.github.io, Twitter: @MoseGiordano Richard Gilham (Met Office) richard.gilham@metoffice.gov.uk Aleksandra Nenadic, The Software Sustainability Institute, a.nenadic@manchester.ac.uk Alexander Konovalov, University of St Andrews, alexander.konovalov@st-andrews.ac.uk Adrian Castravete, figshare, adrian@figshare.com  Notes from the discussion Please use the area below to capture notes from the discussion session.","title":"Interoperability \u0026 Continuous Integration"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Is your online training material accessible? - HP17-CW2CC\nHackday Idea Proposer David Perez-Suarez - d.perez-suarez@ucl.ac.uk\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nProblem Description of the problem you are trying to solve\nOnline materials may not be accessible for everyone.\nSolution Explanation of the solution to the problem you have identified\nA CI plugin that will review your lessons and give you a report of what you need to change to make it better, more accessible.\nDiagrams / Illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw19-accessibility/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Is your online training material accessible? - HP17-CW2CC\nHackday Idea Proposer David Perez-Suarez - d.perez-suarez@ucl.ac.uk\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nProblem Description of the problem you are trying to solve\nOnline materials may not be accessible for everyone.","title":"Is your online training material accessible?"},{"content":"CW21 - 2021-03-30 Koko - CI11-CW21\nParticipants  Stephan Druskat (stephan.druskat@dlr.de) Sammie Buzzard (BuzzardS@cardiff.ac.uk) Bailey Harrington (baileythegreen@gmail.com) Leyla Jael G. Castro (ljgarcia@zbmed.de) Abhishek Dasgupta (abhishek.dasgupta@cs.ox.ac.uk)   The Adventurous Architect - \\ A Blueprinter for Research Software Skills\nContext / Research Domain Cross-domain (research software education/learning)\nProblem Learners completing a basic Software (or other) Carpentry workshop don’t have clear next steps for how to continue their education, and those next steps will be different for many career paths.\nAt the same time, there exist many Carpentries-like lessons “in the wild” that complement the core Carpentries lessons, adapt them to specific situations at institutions or other working environments (e.g., high-performance computing), or specific learning requirements for domains. There is also a need for more ‘intermediate’ Carpentries or Carpentry-style lessons for tools that are useful for software development, such as Vim/Emacs and IDEs; for testing software, such as continuous integration; and for making code nicely formatted and correcting common errors, such as linters.\nSolution Create a curated list of Carpentries and Carpentries-based lessons which will help learners who have completed the software carpentry curriculum (introductory courses on shell, Git, and Python/R) to find their next course. Based on this list, creating a decision tree will help people pick their custom learning path across all these Carpentries and Carpentries-like resources.\nThe decision tree can also be used as input for a serious game or form to help people build their learning path, based on an endpoint, e.g., a specific skill set.\nAt the same time, using the decision tree will help identify gaps in the Carpentries curriculum, and can support the development of new, especially intermediate, lessons.\nLater, an AI-based recommender system can suggest useful learning paths based on inputs describing a specific research situation: “Hello System, I have this genomics dataset in JSON and want to do reproducible research on it to visualize this-and-that. I have done a Carpentries Git lesson but cannot use Python for this project, what should I learn?”\nDiagrams / Illustrations Licence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-koko/","summary":"CW21 - 2021-03-30 Koko - CI11-CW21\nParticipants  Stephan Druskat (stephan.druskat@dlr.de) Sammie Buzzard (BuzzardS@cardiff.ac.uk) Bailey Harrington (baileythegreen@gmail.com) Leyla Jael G. Castro (ljgarcia@zbmed.de) Abhishek Dasgupta (abhishek.dasgupta@cs.ox.ac.uk)   The Adventurous Architect - \\ A Blueprinter for Research Software Skills\nContext / Research Domain Cross-domain (research software education/learning)\nProblem Learners completing a basic Software (or other) Carpentry workshop don’t have clear next steps for how to continue their education, and those next steps will be different for many career paths.","title":"Koko"},{"content":"CW21 - 2021-03-30 Leo - CI12-CW21\nParticipants Please list the participants here\nEmma Rand emma.rand@york.ac.uk\nAida Mehonic\nHannah Williams Hannah.Williams@phe.gov.uk\nCarlos Martinez-Ortiz\n_Flic Anderson contact@felicityanderson.co.uk _\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all of this hint text (Arial, italic, grey, size 11) once you no longer need it.\nConnECT ProjECT - an Exciting Collaboration Tool for discovering project similarities Context / Research Domain Collaboration - not research domain specific\nProblem _Lots of individuals/groups working on projects (for example a large funded project), but it can be difficult to identify commonalities, opportunities for collaboration and start useful discussions. _\n Share knowledge across domains Avoid duplications _Encourage collaboration _ _Would be good to link between organisations too _ _Bumping into the right person at the coffee machine has become impossible for teams over 70 people - to share knowledge _  Solution Either a form (useful for non-repository projects) or some sort of automated tagging for remotely hosted repositories (e.g. GitHub repos) which feeds into a dashboard, to visualise commonalities:\n Topics / domain fields, but not only this (to avoid “it’s not my domain” turn-off). Methods that repositories have in common (e.g. unit testing, particular statistical tests, project management methods) Language/tools similarities (might be able to tie into existing analysis by GitHub of repos for example, but collect this information for projects at other stages or in other formats too) Visual prompt to start conversations / know which discussions to have. Prompt when another member of the group/team adds a project that is similar, to maintain collaborations throughout the life-cycle of x (e.g. invitation to code review ‘most similar’ projects, or a “other projects like yours have used x technology/method” suggestion prompt) Prompt when starting from scratch - have you seen x?  Elements of the solution: (how to break it down for implementation)\n Form to gather data from non-version-controlled projects \u0026amp; save data  web-form?   API tool to scrape/gather same information for GitHub repositories \u0026amp; save data  Scan READMEs (if exist) Scrape code (look for keywords, check for words/functions matching ontologies) Project staff can add extras tags (somehow link ‘scraped’ results to webform)   Tidy gathered data into one structure (\u0026amp; clean) Dashboard UI to display project ‘tags’ (ie similarities) \u0026amp; highlight similarities (ideally .pdf or .html version which can be shared by link to start conversations between project staff/managers)  Show ‘most similar’ projects \u0026amp; key contacts Tickmarks for shared ‘tags’    Possible Gotchas:\n Data security / GDP - contact detail sharing for example Levels of access \u0026amp; authorisation between projects and institutions Inter-organisation barriers Secrecy or lack of confidence in sharing? Requires all to be on board with using readmes, documentation, mentioning keywords etc.  Diagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nLicence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-leo/","summary":"CW21 - 2021-03-30 Leo - CI12-CW21\nParticipants Please list the participants here\nEmma Rand emma.rand@york.ac.uk\nAida Mehonic\nHannah Williams Hannah.Williams@phe.gov.uk\nCarlos Martinez-Ortiz\n_Flic Anderson contact@felicityanderson.co.uk _\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4.","title":"Leo"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Team 7 - CI5-CW2CC\nReporter Sam Mangham - mangham@gmail.com\nParticipants Al_exandra Simperler, alex@simperler-consulting.com,_\nMario Antonioletti - mario@epcc.ed.ac.uk,\n_Sam Mangham - s.w.mangham@soton.ac.uk, _\nBen Krikler - b.krikler@cern.ch,\nAlejandra Gonzalez-Beltran - alejandra.gonzalez.beltran@gmail.com,\nTyler Whitehouse\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all the hint text once you no longer need it.\nContext / Research Domain Developers in any research domain that want to find appropriate libraries (this could be extended to other resources).\nProblem Developers can find it hard to identify suitable software libraries for their work. Given a problem, deciding on which libraries to use is difficult; even if you know one, it’s hard to find other libraries that do the same thing, or equivalent libraries in other languages. What is the approach with the most traction, particularly within a given community? Which libraries are popular, but low-quality? Serendipitous discovery of libraries is also particularly hard.\nSolution Building a recommendation system that incorporates feedback, using information from similar individuals, and what packages are present (what signal) in your GitHub repo. Based on these, a NetFlix-style recommendation system could suggest possible libraries, and you could give feedback on how suitable a suggested library is for your application. With sufficient iteration, it would be possible to build up a profile of your tastes or needs and how they relate to other users. This would also make it possible to aid discovery by recommending libraries that other similar developers use.\nA decentralised, user-maintained business model might be easier to sustain. As a result, an initial implementation could work by providing a script or tool that queries existing package and library aggregators and rankers. A user would configure this tool by cloning a template repository from the official github, and setting it to run regularly within a continuous integration pipeline. Specific customisations like types of packages, licensing, etc, is left in the configuration of the user’s cloned repository. Additionally, automated summaries of the user’s code (styles, typical package uses, languages, etc) can be produced using the developed tools and stored in the user’s repository. Recommender functionality that looks at collaborator’s styles and dependencies can work by querying colleague’s public clone of the same repository.\nDiagrams / Illustrations  Preliminary Notes\n What do people want from an open simulation platform interface? Interoperability requirements  Identifying user needs   Software scouting- increasing accessibility/discoverability for tools.  Registries? They tend to go out of date. Ways to recommend solutions Can you de-centralise a registry?  Peer-to-peer registries? Deciding on a vocabulary, tagging pages a la Schema.org Not a lot of scientific content on it Encourage users to adopt this existing standard to aid discoverability via Google/existing tools Schema.org One person lingua franca is another person’s dying language   Determining what tools/techniques/sites have the most traction, and focus on them. Positive feedback loop.  Use big names/brand recognition to break into new fields, rather than relying on ‘if you build it they will come’. ‘Metrics for movements’ is the hard part. Current use vs new adoption. Difficulty of selecting easy-to-calculate/search on metrics GitHub starring/cloning etc. metrics exist, but may not be advertised. Libraries.io does this a bit Proper, visible metrics BUT avoiding information overflow. Concise, interactive, easy-access information Problem: Popularity != quality. Differentiate between popular but low-quality content and popular good content. How?  Automated (e.g. code quality/unit testing) Fair Sharing standards for events etc. Matching tools \u0026amp; metrics e.g. like booking.com/dating sites! (similar: Matching RSEs to work)     Service on top of the github api that provides different metrics or indicators  You get to choose the metrics so that you can make sure results are per an “educated choice”   Tag libraries \u0026amp; resources to make it easy to find similar ones and compare the quality/popularity Preferential attachment - high degree nodes attract more connections; it can work poorly Educated choice - a service that would give you all the metrics that allow you to make a choice Daily newsletter (i.e. libraries.io generated) that gives you what you know but also let’s novel things bubble up into your feed (satisfies need and bias but presents things that are “orthogonal” to your perspective)  Promotion of new content that is seeing a substantial increase in popularity. Threshold for speed of adoption -\u0026gt; promotion.   Recommendation service for libraries.  Follow people on github to get repository starring information. Curators? Serendipitous discovery by following people and discovering the stuff they use. Dating-service-like feedback on quality of recommendations.   “Tell me your code and I’ll tell you who you are” Modify recommendations with jitter/noise to escape echo-chamber    ","permalink":"https://robintw.github.io/CW-ideas/cw19-netflix-recommender/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Team 7 - CI5-CW2CC\nReporter Sam Mangham - mangham@gmail.com\nParticipants Al_exandra Simperler, alex@simperler-consulting.com,_\nMario Antonioletti - mario@epcc.ed.ac.uk,\n_Sam Mangham - s.w.mangham@soton.ac.uk, _\nBen Krikler - b.krikler@cern.ch,\nAlejandra Gonzalez-Beltran - alejandra.gonzalez.beltran@gmail.com,\nTyler Whitehouse\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two).","title":"LibFlix"},{"content":"o### CW21 - 2021-03-30\nMacavity - CI13-CW21\nParticipants Louise Chisholm\nMalin Sandstrom (chair?)\nFlorian Mannseicher\nEmma Karoune (scribe)\nAndrew Brown (scribe)\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all of this hint text (Arial, italic, grey, size 11) once you no longer need it.\nIDEAS:\nSkills Wheel for RSEs\nIdeas:\nCommunity management\nHow to be an RSE: define the professional identity, especially for young people starting out\n_Training materials portal: practices, tools, languages etc. _\nCarpentries address skills, this portal could address the (professional?) framework\nSkills wheel\nDifferent ways into RSE: direct training, researchers who incorporate RSE practices etc. how to merge these?\nHow to startwith diversity\nOverview of skills, followed by specialisation\n_Encourage long term thinking: documenting workflow (e.g) _\n_Explaining why best practice is important _\n_Soft skills: empowering research, communication etc. _\nResources in The Turing Way - https://the-turing-way.netlify.app/welcome\nContext / Research Domain Researchers developing software skills\nProblem It can be difficult for researchers new to software development to orient themselves in the professional RSE landscape, and find out how to develop the skills needed. Some researchers develop their skills in an ad hoc way based on specific research project needs, while others are trained as software engineers specifically. This will impact the development of the community, especially the ‘onboarding’ of new members. Researchers who do not have programming background need a level of understanding of research software, while those with a technical or research background may need more training in the professional or soft skills. While many resources are available for each specific area, the intersection of required skills and knowledge for RSE may make the community seem inaccessible.\nSolution Explanation of the solution to the problem you have identified\n_Provide a ‘front-end’ for RSE-skills resources, resolved into Professional, Technical and Soft skills, to allow people coming from different backgrounds and communities better to find the information they need. _\n“Enabling tool development in research” portal\n Professional skills for RSE  _ data management and governance, FAIR, research reproducibility, licensing, project design, costing projects, managing a team, Continuous Professional Development, mentoring, recognition/authorship for contributions, _   _Technical skills for research software engineering _  programming languages, research reproducibility tools, engineering thinking, version control, file formats, testing, pedagogy   _Soft skills _  communication, awareness of accessibility, digital collaboration, user forum, community building Community mgmt 101 https://www.software.ac.uk/top-tips-managing-your-open-source-project-community-effectively    _In the portal develop a skills wheel/venn diagram and link to professional requirements and resources i _\nCreating a course for researchers who do not code or data to understand engineering thinking and concepts that are important in research software engineering and data analysis.\nDiagrams / Illustrations We suggest adapting/using the idea of the wheel from CSCCE developed for Community managers and reuse idea for RSE skills and to make it interactive, so people can explore the different skills. Each skill will be linked to training resources/courses so that each skill can be explored and developed by the reader.\nWhat does a scientific community manager do? Check out the CSCCE Skills Wheel and accompanying guidebook! - CSCCE\nLicence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-macavity/","summary":"o### CW21 - 2021-03-30\nMacavity - CI13-CW21\nParticipants Louise Chisholm\nMalin Sandstrom (chair?)\nFlorian Mannseicher\nEmma Karoune (scribe)\nAndrew Brown (scribe)\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all of this hint text (Arial, italic, grey, size 11) once you no longer need it.","title":"Macavity"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Maintainable Tutorials Made Quickly - HP16-CW2CC\nHackday Idea Proposer Adam Jackson - magicguy@gmail.com\n Context / Research Domain This tool assists documentation of small command-line programs as created by novices\nProblem Many researchers have a limited time/energy allocation for their software development. Documentation tends to be a low priority, and within the documentation tutorial/how-to content is somewhat intimidating. This is a problem as this content is especially important for bringing in additional users, who may be able to contribute experience (and code!) to help the project develop.\nSome specific challenges for tutorial and how-to documentation are\n Creating an attractive and communicative layout Accurately capturing inputs/outputs Keeping the tutorial content up-to-date with API changes  Solution A tool to quickly create a tutorial/how-to page as automatically as possible.\n This is a template which can be annotated with additional commentary This should be able to somehow integrate with a shell session to capture the input commands and outputs; in addition it should be easy to flag generated files and screenshots as belonging to a particular step. The generated page is rich with styling/javascript functionality to fold/unfold levels of detail and extracted information A program is generated/supplied which can be added to a test suite. This executes the tutorial code blocks and verifies the output if possible. This will flag errors and provide a level of confidence that the tutorials remain up-to-date.  Diagrams / Illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw19-tutorials-quickly/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Maintainable Tutorials Made Quickly - HP16-CW2CC\nHackday Idea Proposer Adam Jackson - magicguy@gmail.com\n Context / Research Domain This tool assists documentation of small command-line programs as created by novices\nProblem Many researchers have a limited time/energy allocation for their software development. Documentation tends to be a low priority, and within the documentation tutorial/how-to content is somewhat intimidating. This is a problem as this content is especially important for bringing in additional users, who may be able to contribute experience (and code!","title":"Maintainable Tutorials Made Quickly"},{"content":"CW20 - 2020-03-31 to 2020-04-02 Idea 3 - Message in e Bottle: work more effectively with ephemeral teams across timezones. - CI3-CW20\nParticipants Shoaib Sufi (shoaib.sufi@software.ac.uk), Carlos Martinez (c.martinez@esciencecenter.nl) (scribe), Alessandro Felder (a.felder@ucl.ac.uk) (chair), Emmy Tsang (e.tsang@elifesciences.org), Aleksandra Nenadic (a.nenadic@manchester.ac.uk)\nOriginal slide at - _https://docs.google.com/presentation/d/1GbwxVrWpqw_Nk9Mg9dinLUUThHSfetVsg7KD2SiGIkk/edit?usp=sharing _\nContext / Research Domain Are you:\n A workshop host delivering a session to participants from multiple time zones? A hackathon organiser facilitating collaborations between newcomers and experienced community members in teams spread across different time zones? A conference organising team hoping to virtually deliver keynotes, poster sessions and demos and build a sustainable community?  Message in e bottle is your solution – a personal, semi-asynchronous, efficient system to facilitate collaborations and improve team productivity across multiple time zones.\nProblem It is hard to collaborate online, and even harder to collaborate across different time zones with people you have not met before. One of the largest challenges is to pass messages effectively. Interactions can be awkward and not personal: it is not clear at what time of day and how the messaging should happen. Not knowing how to pronounce each other’s name impedes the forming of a collaborative human bond.\nSolution Message in e bottle – a service that allows you to handover a workshop so you can run a collaboration workshop across multiple time zones.\nWhen a team working on a particular time zone runs out of time to contribute to the workshop, the team will ‘bottle’ their progress.\nThe next team to come online can ‘open’ the bottle to receive an update on the current state of the workshop and continue from that point onwards.\nWhat should a message contain?\nA message should be easy to digest and should allow people to take work up easily. It should allow newcomers to become familiar with individuals in the team at a human level: voice messages and familiar faces, coding languages they know/ tools they work with.\nUsing existing technologies\nExisting platforms like youtube or instagram could work in a first instance. Be aware that there are privacy considerations that need to be taken into account.\nMessage in e Bottle is brought to you by - Team Idea 3! ","permalink":"https://robintw.github.io/CW-ideas/cw20-message-in-ebottle/","summary":"CW20 - 2020-03-31 to 2020-04-02 Idea 3 - Message in e Bottle: work more effectively with ephemeral teams across timezones. - CI3-CW20\nParticipants Shoaib Sufi (shoaib.sufi@software.ac.uk), Carlos Martinez (c.martinez@esciencecenter.nl) (scribe), Alessandro Felder (a.felder@ucl.ac.uk) (chair), Emmy Tsang (e.tsang@elifesciences.org), Aleksandra Nenadic (a.nenadic@manchester.ac.uk)\nOriginal slide at - _https://docs.google.com/presentation/d/1GbwxVrWpqw_Nk9Mg9dinLUUThHSfetVsg7KD2SiGIkk/edit?usp=sharing _\nContext / Research Domain Are you:\n A workshop host delivering a session to participants from multiple time zones? A hackathon organiser facilitating collaborations between newcomers and experienced community members in teams spread across different time zones?","title":"Message in e-Bottle: work more effectively with ephemeral teams across timezones"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Netflix of libraries - HP12-CW2CC\nHackday Idea Proposer ben krikler - mr.krikler@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Developers in any research domain that want to find appropriate libraries (this could be extended to other resources).\nProblem Developers can find it hard to** identify suitable software libraries for their work**. Given a problem, deciding on which libraries to use is difficult; even if you know one, it’s hard to f**ind other libraries that do the same thing**, or equivalent libraries in other languages. What is the **approach with the most traction**, particularly within a given community? Which l**ibraries are popular, but low-quality**? **Serendipitous discovery** of libraries is also particularly hard.\nOriginal document: https://docs.google.com/document/d/1HAIAaHoJCBPi_kG9aNIod2ww2dR3uYbtQ9UGUbH_ZkY/edit?usp=sharing\nSolution Building a recommendation system that incorporates feedback, using information from similar individuals, and what packages are present (what signal) in your GitHub repo. Based on these, a NetFlix-style recommendation system could suggest possible libraries, and you could give feedback on how suitable a suggested library is for your application. With sufficient iteration, it would be possible to build up a profile of your tastes or needs and how they relate to other users. This would also make it possible to aid discovery by recommending libraries that other similar developers use.\nA decentralised, user-maintained business model might be easier to sustain. As a result, an initial implementation could work by providing a script or tool that queries existing package and library aggregators and rankers. A user would configure this tool by cloning a template repository from the official github, and setting it to run regularly within a continuous integration pipeline. Specific customisations like types of packages, licensing, etc, is left in the configuration of the user’s cloned repository. Additionally, automated summaries of the user’s code (styles, typical package uses, languages, etc) can be produced using the developed tools and stored in the user’s repository. Recommender functionality that looks at collaborator’s styles and dependencies can work by querying colleague’s public clone of the same repository.\nDiagrams / Illustrations ","permalink":"https://robintw.github.io/CW-ideas/cw19-netflix-libraries/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Netflix of libraries - HP12-CW2CC\nHackday Idea Proposer ben krikler - mr.krikler@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Developers in any research domain that want to find appropriate libraries (this could be extended to other resources).\nProblem Developers can find it hard to** identify suitable software libraries for their work**.","title":"Netflix of libraries"},{"content":"CW20 - 2020-03-31 to 2020-04-02 Idea 8 - Online Community Cookie Cutter c3- CI8-CW20\n**Overview of the project: **Guiding documents/tools for leading and sustaining online research communities facilitated by collaborative projects or events.\nParticipants  Will Furnass: Scribe Colin Sauze Louise Bowler: Chair Malvika Sharan (malvikasharan@gmail.com) Jo Leng (j.leng@leeds.ac.uk) Mateusz Kuzak (@matkuzak)  Back up zoom: https://turing-uk.zoom.us/s/6507227126 (Malvika)\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all the hint text (grey, Arial 11, italic) once you no longer need it.\nNotes on options:  Jo: tools/training for generating understanding of the structure of existing code, particularly w.r.t. data structures Mateusz + Malvika: guidance/documentation for running remote hackathons - roles, responsibilities, checklists. How to set up events quickly but by covering all areas? Colin: Tool to bootstrap an online community quickly: CoC, license, comms platform etc. Cookiecutter template? Will: automated report card for research workflows. Mateusz: ELIXIR integrate with https://openebench.bsc.es https://bio.tools Mateusz: could we have automated report cards/checklists for setting up online communities / running online events? Jo: could include things in guidance/documentation for communities/events to help with cross-disciplinary work e.g. glossary?  Most interested in tools/guidance for quickly creating open online communities. What roles required? Mateusz: chair, treasurer, secretary on steering committee - sufficient to start with. Can then spin out task forces/sub-committees to work on specific challenges, which may include steering committee members. Other roles: maintainers. How to reward volunteers? How to avoid burnout - need documented ‘off-boarding’ exit strategy to complement on-boarding documentation. We as a community need training in leadership/project management?\nAre we considering developing guidance for setting up online events/communties and/or tooling?\nColin: what’s the least one needs to know to set up an online community/event?\nMalvika: how can people ask for help within these communities? Need to provide guidance? Jo: mentoring program useful within this?\nMateusz: ‘hackathons’ as a name is problematic - only appeals to a particular crowd and suggests staying up all night and eating pizza?\nCan we put these ideas as chapters in the Turing way?\n Here is a preview that has only placeholders for things that are planned but don’t exist: https://deploy-preview-977\u0026ndash;the-turing-way.netlify.com/welcome Here is a PR on remote collaboration: https://github.com/alan-turing-institute/the-turing-way/pull/962 Content ideas for remote collaboration: https://github.com/alan-turing-institute/the-turing-way/tree/ms-collaboration-book/book/content/remote_collaboration Checklists on the online events: https://github.com/alan-turing-institute/the-turing-way/blob/ms-collaboration-book/book/content/remote_collaboration/checklist/checklist.md What’s missing is how to support an online community that is being formed due to your event (i.e. hackathon etc.)?  Summary:\n Guiding documents/tools for building, leading and sustaining online research communities sprouted from an event.   Context / Research Domain Please describe the context or research domain to which the problem applies\n In Brief: Support and guidance for online communities working on open research Researchers and research software engineers are rarely trained in community organisation. They may get involved in training and organising events, but they often will learn on the job on the go and rarely have access to support or guidance on current (or best) practices around community organisation. This has been a long term problem for the RSE and other communities. The response to the COVID-19 pandemic and the resulting lockdown has forced many people to work from home and developing and sustaining online communities is ever more important. We want to use the experience and expertise from those activities ignited by COVID and document, to make it easier for future community organisers (researchers or RSEs) to start online communities.  Problem Description of the problem you are trying to solve\nMuch guidance and many resources exist online on how to build communities or organize events. Several are being specifically developed for online communities. However, what is sorely needed is accessible guidance to leading and sustaining online research communities that get formed organically due to online events.\nAs we continue to work from home due to the COVID-19 situation worldwide and suspect that this will continue for a foreseeable future, we have felt a need for such a guidance in our network. This is due to the fact that online events and projects can be organized without the need for expensive resources like venue, catering or travelling. This situation has created a unique and equitable opportunity for anyone with the internet to lead such an event, however many of us need skills to lead and sustain such online projects and people working on them.\nResearchers without any prior experience with project leadership would benefit from a one-stop-shop for guidance or signposts on how to lead their projects and the resulted communities. For example, there have been some efforts to address the need for leadership/management training in the RSE/data science communities (e.g RSE Aspiring Leaders workshop). However, there isn’t yet clear guidance on these topics in general and much of this training is geared towards managing/leading within hierarchical institutional structures rather than within agile cross-institutional teams.\nTo effectively and inclusively lead their projects, we want help volunteer leaders to understand and deploy tasks related to onboarding members, establishing help/guide or mentoring structure for them, rewarding their contributors, offboarding ideas so that people can leave any time (specifically to avoid burnout), reviewing/enforcing Code of Conduct, sustaining infrastructure/services, ensuring data privacy and information on project governance.\n**Solution ** A cookie-cutter-like tool to guide you through creating a community\n Either a “choose your own adventure” style guide to gamify the process An interactive tool (or similar) that takes you through each of the essential steps and provides the user with options and recommendations based on your preferences (like an expanded version of the “Choose a licence” website)  And/or\nA set of documents to capture best practice:\n We could prepare a chapter for the Project Design section of the Turing Way: see https://deploy-preview-977\u0026ndash;the-turing-way.netlify.com/project-design.html The text for the chapter could overlap with the content for the interactive tool suggested above a list of organisations (communities of practice) that can support new community organisers on their path  And/or\nMaking an interactive section to the Turing Way using Jupyter Book\nDiagrams / Illustrations\nYou can include one or two diagrams in this section. Please ensure you have the right to use the image(s) and include attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw20-cookie-cutter/","summary":"CW20 - 2020-03-31 to 2020-04-02 Idea 8 - Online Community Cookie Cutter c3- CI8-CW20\n**Overview of the project: **Guiding documents/tools for leading and sustaining online research communities facilitated by collaborative projects or events.\nParticipants  Will Furnass: Scribe Colin Sauze Louise Bowler: Chair Malvika Sharan (malvikasharan@gmail.com) Jo Leng (j.leng@leeds.ac.uk) Mateusz Kuzak (@matkuzak)  Back up zoom: https://turing-uk.zoom.us/s/6507227126 (Malvika)\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea.","title":"Online Community Cookie Cutter c\u003csup\u003e3\u003c/sup\u003e"},{"content":"CW21 - 2021-03-30 Oscar - CI15-CW21\nParticipants Please list the participants here\nMichelle Barker\nShoaib Suf\nDaniel S Katz\nCarina Haupt\nCallum Rollo\n Title: Open Source Covid Analysis of References (OSCAR) Context / Research Domain Please describe the context or research domain to which the problem applies\nSoftware’s use in the Covid19 pandemic is somewhat hidden but ubiquitous. Understanding the impact of software in the pandemic would give it the credit that software deserves, raise its profile and potentially highlight the software readiness that would help in any future public health emergency.\nCZI initially made 77,000 articles on Covid19 available (called CORD-19) for analysis. In an effort to automate the process of identifying and analyzing the use of software in biomedical research, Alex Wade and Ivana Williams developed a SciBERT-based machine learning model to extract mentions of software. They trained the model on a dataset collected by James Howison and colleagues (called SoftCite), and then ran it on the CORD-19 dataset of articles, resulting in this dataset of the papers and the software mentioned in each.\nProblem How to analyse the dataset of the papers that mentioned software, and thus evidence and highlight the importance of research software to funders and policy makers?\nA study was undertaken by Nangia and Katz on software mentions in a sample of 40 Nature papers could provide ideas, as it found that 80% of papers mentioned software, with an average of 6 distinct pieces of software mentioned per paper. Could similar analysis be undertaken on this much larger database, or are there other fantastic statistics that could be unearthed?\nSolution It would be useful to consider different ways to analyse the dataset, to identify statistics or trends that could illustrate issues such as - the key role software has played in responding to COVID-19 (and lack of recognition of its importance), the issues in citation of research software (and possibly findability and accessibility of the software), methods to identify key software infrastructure.\nSome of the questions OSCAR hope to answer are:\n Is information provided about the software authors to give them credit? How many/which pieces of software are repeatedly mentioned (and could possibly be defined as critical research infrastructure)? How was the software mentioned? (e.g. proper references to the software, in-line in the text, footnote, etc.) How was the software itself referenced (e.g. A GitHub page to a project, a GitHub page to a release, a Zenodo DOI to an archive, a Software Heritage link to a release, etc.) What percentage of all articles mention software? How many pieces of software are mentioned per paper? What was the software used for (e.g. platform, analysis) Subdiscipline analysis - is there some smaller set of the dataset (eg a subdiscipline) where the answers to any of these questions differ to that of the whole dataset, that might illuminate where a community is doing things differently/better?  Diagrams / Illustrations Nathan Riley onUnsplash\nEND IDEA\n NOTES BEGIN\nNotes from session:\nThis document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all of this hint text (Arial, italic, grey, size 11) once you no longer need it.\nThe ideas:\nMentoring toolkit\nStandards/systems on formulating knowledge bases or toolkits for capturing and sharing knowledge in a domain (e.g. data management or computational techniques)\nCZI machine model pulling out software mentions in 77,000 covid19 articles (dataset here) - similar to other work finding different software mentions in a set of 40 Nature papers. 4\nSmall library to extract software datasets out of a GitLab - filtering (activity, language, etc); help with software analytics - how does it change over time, developers churn, activity levels. Are they FAIR, license, could compare local performance vs Gitlab in the wild or a business. 3\nDisability related - tools/experience/awareness raising - accessible check (screen reader, colour checking, etc) - is it possible in a generic way - many proprietary tools, take away some ability and then see if the experience was still useful (differently enabled) 3\nAmplifying this morning’s panel discussion message - brainstorm ways to share challenges faced eg blog on this morning’s panel, ask RSE podcasts to interview one of the panelists 1\nDisability monitoring system - for new members of staff and link disability offices with schools 1\nLicence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-oscar/","summary":"CW21 - 2021-03-30 Oscar - CI15-CW21\nParticipants Please list the participants here\nMichelle Barker\nShoaib Suf\nDaniel S Katz\nCarina Haupt\nCallum Rollo\n Title: Open Source Covid Analysis of References (OSCAR) Context / Research Domain Please describe the context or research domain to which the problem applies\nSoftware’s use in the Covid19 pandemic is somewhat hidden but ubiquitous. Understanding the impact of software in the pandemic would give it the credit that software deserves, raise its profile and potentially highlight the software readiness that would help in any future public health emergency.","title":"Open Source Covid Analysis of References (OSCAR)"},{"content":"Collaborations Workshop 2018 - 2018-03-26\nProductivity Approximator - HP7-CW18\nHackday Idea Proposer\nM. H. Beals - drmelodeebeals@gmail.com\n Context / Research Domain\nTracking productivity and mood (work-life-enjoyment balance)\nProblem\nIn a world of increasing institutional, governmental and social metrics, we don’t need another one\u0026ndash;or do we? Productivity is extremely difficult to track. Can we measure it in lines of code, miles run or words written? What about analysis, thought and revision? What about discussion? How does “work done” really relate to “productivity”? And how does all this “work” affect us as human beings?\nSolution\nCreate a smartphone app (or desktop app) that allows you to quickly record the following:\n● Task: A note about what you’ve just done (not will do / doing)\n● Task status: Was this a new task, are you continuing a task or are you now done?\n● Quantitative record: Numerical record of how long your spent / how much you’ve finished on the task, with drop down of counters: minutes, words, lines, coffees\n● Mood at end of task: Happy / Unhappy, Excited / Bored, Anxious / Relaxed And provide mild metrics on how much you’ve done, and how certain tasks correlate with your mood / time / date. Are you happiest after a morning 100-word writing session or completing 3000 lines of code at 2am?\nDiagrams / Illustrations\n","permalink":"https://robintw.github.io/CW-ideas/cw18-productivityapproximator/","summary":"Collaborations Workshop 2018 - 2018-03-26\nProductivity Approximator - HP7-CW18\nHackday Idea Proposer\nM. H. Beals - drmelodeebeals@gmail.com\n Context / Research Domain\nTracking productivity and mood (work-life-enjoyment balance)\nProblem\nIn a world of increasing institutional, governmental and social metrics, we don’t need another one\u0026ndash;or do we? Productivity is extremely difficult to track. Can we measure it in lines of code, miles run or words written? What about analysis, thought and revision?","title":"Productivity Approximator"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Discussion group 8 - Ready to deposit? - CI14-CW2CC\nReporter Stephan Druskat - stephan.druskat@dlr.de\nParticipants Emily Bell\nDav Clark\nStephan Druskat\nRobert Haines\nPatrick McCann\nTom Russell\nInitial ideas discussion\n Guidance for researchers on how to deposit software  Ref: “Software Deposit: What to deposit” https://doi.org/10.5281/zenodo.1327325 Tool: Repository checker for what to deposit? Tool that checks all necessary files and metadata is available for  As a GitHub commit probot?     Tool: “Cite this” button for GitHub as browser extension Out-of-order execution?!? - Proof-of-concept for tracking activity in Stencila SemVer checker: Checks what your next version should be based on whether a system/integration/acceptance test suite breaks the API (up the major), doesn’t (up the minor), or looks like a bug fix (up the patch)   This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all the hint text once you no longer need it.\nContext / Research Domain Software deposit; FAIR principles; Reproducible research\nProblem People aren’t depositing their software enough \u0026ndash; even national institutions like libraries don’t have searchable archives of software which use their own collections.\nDepositing their software would make it possible to have it cited according to the Software Citation Principles (i.e., citing the thing itself, not a description of it, or a paper about it), acknowledging that software is on par in this respect with all other research output.\nDeposits enable discoverability, reproducibility, sustainability, credit.\nPeople just need to do it, but may not be sure if their software is ready for deposit yet.\nSolution Ready to Deposit?\nProvide an automated checklist for people to consult whenever they consider depositing a version of their software to an archival repository, such as Zenodo, figshare or an institutional archive.\nThe checklist is tied to version control systems - submit the link to your repository and the tool will provide a summary of existing and missing information. Some of this process will be automated; other parts will require input from the user. It will provide advice on how to complete any missing steps. The tool will certify the readiness of the software for deposit based on a three level scale, shown in figure 1. It will also provide automated deposit of the checked version to different archives upon completion of the checklist.\nThe tool will check for the existence of the following files for a minimal deposit:\n README LICENCE CONTRIBUTORS  It will then ask the user about the contents of the README\nIt will check for a codeMeta.json and CITATION.cff file and ask the user if the relevant further details are present in the documentation and README for a runnable deposit.\nIt will ask the user about the additional features that are necessary for a comprehensive deposit.\nA badge can be added to the ReadMe to indicate the deposit level readiness, see figure 3.\nHack day implementation suggestions:\n Input boxes on a website JS/Python command line tool Bookmarklet (see figure 2) GitHub App / webhook for GitLab / Bitbucket Scaffold / skeleton generation Badge  Diagrams / Illustrations Figure 1: The three levels of deposit readiness. From Michael Jackson. (2018, August 7). Software Deposit: What to deposit (Version 1.0). Zenodo. http://doi.org/10.5281/zenodo.1327325.\nFigure 2: A proposed UI for the R2D? Button.\nFigure 3: Proposed badges for the three levels of deposit readiness.\n","permalink":"https://robintw.github.io/CW-ideas/cw19-ready2deposit/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Discussion group 8 - Ready to deposit? - CI14-CW2CC\nReporter Stephan Druskat - stephan.druskat@dlr.de\nParticipants Emily Bell\nDav Clark\nStephan Druskat\nRobert Haines\nPatrick McCann\nTom Russell\nInitial ideas discussion\n Guidance for researchers on how to deposit software  Ref: “Software Deposit: What to deposit” https://doi.org/10.5281/zenodo.1327325 Tool: Repository checker for what to deposit? Tool that checks all necessary files and metadata is available for  As a GitHub commit probot?","title":"Ready to deposit?"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Reproducibility and Collaboration Challenges in interactive / exploratory research\nReporter Adam Jackson - magicguy@gmail.com\nParticipants Dav Clark\nProgrammer / Evangelist at Gigantum.\nAdam Jackson\nComputational scientist / researcher (from pure PostDoc -\u0026gt; RSE). Produced code as part of research, mostly glue for expensive HPC.\nBecky Arnold\n_Astrophysics PhD at Sheffield. Worked on Turing Institute project. _\nBen Krikler\nMore of a user - particle physicist at CERN. Cluster-based computing. Often exploratory, determine appropriate distributions, features, etc. Python - more Jupyter, using Binder for interactive reporting (though not for sharing back very much).\n“Data gravity” is a problem? Data replication with URI is a solution used there. Some increase in sharing software.\nJoanna Leng\nC++ enthusiast. EPSRC (UK org) RSE fellow. Works with physicists on imaging data, recently with sociologists. Also works at Diamond Light Source - funding for soft matter microscopy vs. hard matter. Is working across modalities, which leads to desired common software base.\nNotes from the discussion NOT for inclusion in blog One concern (Dav+Joanna): enabling collaboration between diverse skillsets (e.g. sociology + RSE).\nProblematising current RSE title - maybe needs to be differentiated more, allowing for different kinds of roles.\nFunding for tools that are useful outside of one grant.\nAlso concern about losing true expertise. Faculties are being reduced and integrated - using same tools. Tension between disciplinary boundaries vs. fluid interdisciplinarity.\nMinimizing lines of explanation about the exploratory process (e.g., “this didn’t converge, so we nudged it”).Conversion of programs to a literate product. More on the post-processing (not the expensive stuff).\nConcern about cache hanging around in notebooks.\nInteractive / exploratory visualization.\nChris Woods (from Bristol) about future of Cloud computing -\u0026gt; shifting HPC to the cloud. Ben is working on this as well. Working with Oracle for cluster in the cloud. Enables doing viz while computation is happening. Concern about user support for Cloud.\nHow could we do bursty exploratory analysis? Probably leads to under-utilization of system. Maybe if you have a set of expected potential outcomes you can code this a little more efficiently.\nTopics\n Rapid Human QA / Viz  e.g., well-designed plots for brain imaging 3D plots are hard to do any way except interactive Infinite set of ways that things can be wrong - human visual system is so fancy Hypothesis generation - concerns about automated data cleaning   Understanding outputs of complex, automated analyses  Understanding machine learning for separation of examples - what has the algorithm done?   Transparency / Reproducibility  Version control everything Restricted data (esp. for reproducibility) Capture computational environment  Containers are hard to design without knowing what data will be used, what will be persisted   Git all the time, changelog? Capturing meaningful points in time?   Scaling from locally tested to scaled-up/out, etc.  Data portability Data restrictions Availability / cost of compute     Speed Blog Please use the area below to draft the speed blog. Consult https://www.software.ac.uk/speed-blogging-and-tips-writing-one for information, tips and examples.\n At the Software Sustainability Institute’s 2019 Collaborations Workshop, many discussions for the speed-blogging session focused on deposit of relatively fixed data and analysis code. Our group noted that there is value in reproducibility across the research process - e.g., in facilitating collaboration within a team, or even portability across compute environments within a lab. Moreover, it is well documented that even basic computational reproducibility with the same code and data remains a challenge. Baking in concerns about reproducibility starting at the earliest explorations could increase the number of projects that are genuinely reproducible and amenable to extension and further exploration. Below we highlight key topics and include example suggestions, practices, and tools that can facilitate reproducibility and collaboration from the start of the research project.\nReproducibility/transparency\nExploratory research often treads a winding path, circling back on itself and running into dead ends. This presents a barrier to reproducibility as it makes it difficult to track backwards from the final conclusions of a research output and the path of code/results/hypothesis that lead to them.\nMaking extensive use of a version control tool such as Git can be a big step towards mitigating/eliminating this problem. By using atomic commits (committing each small unit of work to version control) with a detailed commit message explaining why the step was taken can allow others (or your future self) to “retrace your steps”.\nAnother important step for making research reproducible is to capture the computational environment it was conducted in as the behaviour of software can change depending on it environment. In research this translated to the same piece of code generating different results on different computers- i.e. the result will be irreproducible. There are a number of ways of capturing computational environments, all of which have their own strengths and weaknesses. Containers offer possibly the most “complete” or fully-controlled approach to replication, but present a steep learning curve. Further they can be inflexible if, after further exploratory research, the environment needs to be changed, for example by adding another piece of software.\nAnother barrier to reproducible research is when the research involves working with confidential information such as medical or commercially sensitive data. In cases like these, full anonymisation of results may be difficult and laborious, making it undesirable to apply to every step of the research process. This skirts the boundaries of open research and reproducible research. Research can be reproduced far more widely if it is open, but reproducible research does not necessarily have to be open. Even if only those with clearance to access the information are able to reproduce it, the research is still reproducible. As such it is good practice to carefully document and version control all steps of the research process, even if those cannot be shared. Working reproducibly has a myriad of benefits for research quality even if the research cannot be shared.\nInteractive exploratory research presents another barrier to reproducibility. Say a researcher generates a 3D plot, interacts with it, spins it around, and comes to a conclusion, then that process and what that researcher exactly saw can be difficult to reproduce. This is an example of why it is so important for researchers to take extensive and detailed notes.\nPortability and Subsetting of data\nExploratory work will often be performed with relatively “raw” data, which in turn can involve large files and mixed formats. In the early stages of a study it may not be clear how high-quality or noisy the data is, or indeed what is relevant to later outcomes. As a result, some of the best-practices for reproducible research (“upload everything with human- and machine-readable metadata to somewhere as available and immutable as possible”) become more cumbersome or even technically or economically infeasible.\nDuring an interactive process we want to access and process data quickly, which generally means working with a local copy. It is not generally practical (or even permissible) to upload all of the data that was even considered for analysis, which means a curation/pruning step is needed to present a reproducible environment. Containers are an emerging and powerful tool for robust well-defined computational processes, but the technology is led with a focus on web applications. The run-time environment of a container is destroyed when the container is stopped, and best-practices around durable data persistence are not well defined. For example, bind-mounts may incur a large performance penalty (especially on Windows or macOS) but at the same time, they provide easy persistence and accessibility.\nThe results is that separate protocols are needed for making data available to a container session, and also for extracting and persisting useful outputs. There seems to be a conflict between the design to make sessions independent and predictable, and the desire to freely explore while logging the progress (a conflict that is similarly expressed in the problems of invisible state persisting between Jupyter cell executions)\n.\nPortability and Easy Configurability of Compute\nMobility of compute is defined by Greg Kurtzer in his paper describing Singularity. The basic idea is that compared to the bits required to describe your data, the bits required to describe your computational steps are typically far fewer - and therefore more portable. A challenge arises due to the dramatic differences between some compute contexts. For example:\n file systems differ, including distributed networks; different compute architectures may be available: multi-core, GPU, other accelerators  (In some cases, libraries (e.g. linear algebra) may need to be compiled specifically for an architecture and may have even have different semantics); and   different modes of interaction may be required, e.g. desktop vs. batch systems.  So, while in theory container approaches like Docker or Singularity “solve” the challenge of portability of compute, there are many details that remain to be addressed.\nWe are aware of a variety of approaches to addressing these remaining challenges. The approach adopted by Gigantum is to reduce cognitive load and streamline standardized strategies. E.g., by defining a dataset which may be attached to a compute project, and which can intelligently fetch only needed data for local tyre-kicking, and provides sensible descriptors for data location on an HPC system. Another class of approaches is to define an API that intelligently maps onto a variety of back end compute architectures. For example, Dask reproduces a subset of numpy and pandas APIs that work on distributed clusters (cf. Spark, etc.), libraries like PyTorch flexibly work across CPU and GPU, and the PARSL library provides annotations that allow users to inform the runtime of what functions can be run in parallel.\nEven having solved these technical challenges, most strategies are still going to require a modest amount of “dev ops” sophistication. Docker can be cumbersome, designing good requirements files for package installation requires a balance between hard requirements and flexibility of working across versions of needed packages. While many voices in reproducible research advocate for training and practices, there remains a clear place for innovation in tools. For example, the repo2docker project provides a set of standard approaches that will reliably support a binder instance that can be inspected by anyone. Tools like Gigantum take this further by automating Git and providing a UI around things like package management and Dockerfile generation and execution.\nRapid Human Quality Assurance / Visualisation\nExploratory data analysis and visualisation is the process of iteratively improving your understanding of the underlying data and physical processes in order to respond to a particular research question.\nIt occurs in two possible research processes, either in incremental research when an existing research approach and work flow is being slightly updated or tested on relatively similar, but new, data; or in disruptive research when a completely new approach to the experiment or analysis is used.\nIn incremental research, one normally has an understanding of what to expect, and open-ended exploration will only kick in when an anomaly is observed. Being able to compare the anomaly to a previous result, or using a simulated or parameterised model can help understand how the anomaly has occurred. Alternatively, variation of the analysis workflow can allow the researcher to test several different hypothesis for what has produced the anomaly. In both cases, getting new updated results quickly and keeping them organised is important to identify what has gone wrong.\nIn a disruptive approach, however, there is some expectation as to what the data will show but the approach needs to be open to spotting problems. Often in this case the research question itself might evolve, as will the analysis workflow, since it is difficult to predict before starting the research process what will be the best approach to answer the research question.\nSummary\nThe contributors to this post widely agreed on the clear challenges for computational reproducibility, and how these challenges are exacerbated by the demands of interactive and exploratory work. Our suggestions range from training and practices for manually tracking activity and computational environments to near-complete automation in an integrated graphical environment. We look forward to hearing from others in the larger conversation as we proceed to improve the state of reproducibility and collaboration across the entire research lifecycle!\n","permalink":"https://robintw.github.io/CW-ideas/cw19-repro-challenges/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Reproducibility and Collaboration Challenges in interactive / exploratory research\nReporter Adam Jackson - magicguy@gmail.com\nParticipants Dav Clark\nProgrammer / Evangelist at Gigantum.\nAdam Jackson\nComputational scientist / researcher (from pure PostDoc -\u0026gt; RSE). Produced code as part of research, mostly glue for expensive HPC.\nBecky Arnold\n_Astrophysics PhD at Sheffield. Worked on Turing Institute project. _\nBen Krikler\nMore of a user - particle physicist at CERN.","title":"Reproducibility and Collaboration Challenges in interactive / exploratory research"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 collab_ideas_group_5 - CI10-CW2CC\nReporter Sarah Gibson - sgibson@turing.ac.uk\nParticipants Jason M. Gates, Joanna Leng, Catherine Smith, Sarah Gibson, Colin Sauze, Alexander Konovalov\n Context / Research Domain RSE Careers\nProblem HERA (Higher Education Role Analysis) is a tool which is used to analyse roles found in Higher Education institutions (see http://www.ecc.ac.uk/about-us/ for further information). They were written about 15 years ago. While there were subsequent changes to REF procedures, and RSEs did not exist at the point they were written, the descriptions stay the same. As a result, it is not obvious for HR departments how to classify an RSE job. This hinders career paths of RSEs.\nSolution We propose to look through the national job descriptions provided by HERA and suggest updates to include RSE, data scientists and similar roles. Having appropriate job roles is important for recognition and promotion.\nThe word “software” doesn’t appear in many university’s technical HERA job descriptions.\nWe need to raise the issue with trade unions (UCU) as they are responsible for negotiating this with the universities as recognised in the Researchers’ Concordat. The Researchers’ Concordat currently covers academic researchers but is in the process of consultation to start including the gray areas around research.\nFor examples of HERA job descriptions see https://www.st-andrews.ac.uk/hr/gradingrewardandconditions/jobfamiliesgenericroledescriptors/ (St Andrews) and https://www.aber.ac.uk/en/media/departmental/humanresources/frameworkagreement/technicalcomputeroperatorprofilestco/Technical-\u0026amp;-Computer-Operator-8\u0026mdash;EN.pdf (Aberystwyth)\n","permalink":"https://robintw.github.io/CW-ideas/cw19-hera4rses/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 collab_ideas_group_5 - CI10-CW2CC\nReporter Sarah Gibson - sgibson@turing.ac.uk\nParticipants Jason M. Gates, Joanna Leng, Catherine Smith, Sarah Gibson, Colin Sauze, Alexander Konovalov\n Context / Research Domain RSE Careers\nProblem HERA (Higher Education Role Analysis) is a tool which is used to analyse roles found in Higher Education institutions (see http://www.ecc.ac.uk/about-us/ for further information). They were written about 15 years ago. While there were subsequent changes to REF procedures, and RSEs did not exist at the point they were written, the descriptions stay the same.","title":"RSE Careers"},{"content":"CW20 - 2020-03-31 to 2020-04-02 RSE2_D2 - CI10-CW20\nParticipants Yo Yehudi - Software dev and EngD student (Cambridge and Manchester)\nDavid Perez-Suarez - RSE at UCL\nBlair Archibald - 2017 fellow, Postdoc Glasgow (soft spot for Haskell)\nMarion Weinzierl - RSE at Durham University, Not a fellow\u0026hellip; yet!\nVahid Garousi - Belfast\n Context / Research Domain A long time ago, in an office far, far away, RSEs and researchers were developing software and may not be aware of all the good practices and are in need of a bit of motivation.\nProblem The researchers of the universe need help with their software, but where can they turn? Where else but to set their communicators to Twitter to ask for help and advice from the one and only RSE2-D2.\nSolution RSE2-D2 is a twitter bot providing advice about creating/maintaining research software. It provides, amongst other things (see images below):\n  Automated analysis of github links\n “Help @RSE2_D2 analyse! github.com/OpenResearcher/somecoolproject. You’re my only hope” Adding a readme/license Revisit some old issues that haven\u0026rsquo;t been labeled To praise to new contributors To praise long term contributors To praise maintainers Add a CoC No CI detected! No style followed? Try this tool for this language! GH: @pep8speak \u0026hellip;    Share moral lessons and horror stories\n https://www5.in.tum.de/~huckle/bugse.html #horrorstories slack room links    Share motivational tweets and useful reminders - commit your code! Use a colleague as a rubber duckie. Check your contributing guidelines are up to date! Don’t forget to write a docstring for that method. It’s a feature, not a bug.\n  Today is a good day for writing a new test! #MondayMotivation #Testing\n  Updates about new open science tooling\n  Daily/weekly updates on test coverage\n  Reminders to write documentation / tests\n  Something along the lines of @CodeWisdom on Twitter https://twitter.com/CodeWisdom\n  Check how many/which Github issues are open and flag one up every so often\n Triage Tweets: “Project y” needs some help (based on issues)    A competition with other users, you get points for documentation, test coverage, … You can win a 1-2-1 chat with a real-life RSE to talk about your code!\n  Check if tools are unmaintained: @scipy we haven’t seen a commit recently, you alright?\n  Language month/week. Tweet about podcasts, resources, link to other tweet accounts of that particular language\n  Tip of the day\n  A help! Command to summon a real RSE\n  Diagrams / Illustrations _R2-D2 image via https://www.shopdisney.co.uk/disney-store-r2-d2-interactive-action-figure-star-wars-461010647492.html _\nOriginal brainstorm notes\nDiscussion:\nBrainstorming session:\nBlair: Try to automate make files. Strace can wrap the commands they will use and \u0026ldquo;basically\u0026rdquo; get all that into a make file. Then you can edit it. Stop recording or whatever it is\u0026hellip;. You can get reproducibility from it. One issue is that you can\u0026rsquo;t use strace in windows.\nQ: Are makefiles contemporary and still popular? A: good for workflow if not for software.\nQ: Other tools like snakemake?\nYo: During discussion group yesterday they talked about covid. What was found that they need project leadership. Project leadership training programme to be deployed quickly and used by others.\nQ: Delivery length?\nMarion: Legacy software that hasn\u0026rsquo;t been touch for a long time, for example a fortran and c++ code that are tied and they involved a set of scripts/languages that glue them together. It\u0026rsquo;s there a way that helps to understand how they work, debug them, \u0026hellip;\nHow to bootstrap messy code?\nIt\u0026rsquo;s up to the maintainers to modernise, a chicken-egg situation because all it\u0026rsquo;s entangled.\nWhen should we put it under git? It should go from the beginning, then you can track the changes better.\nHorror stories blog, piece of art, messy code of piece of poetry\nDavid: Maybe we could analyse messy code with metrics and recommendations. E.g. shellcheck for shell scripts, give hints to tools (high level code checkers etc) - interaction tools etc. Tips for integrating certain technologies (front end/back end), what might be better in other languages/APIs/Structure. Success stories to drive the guidance. A wizard RSE\nQ: What about RSEBot, the twitter bot/ RoboRSE\n  Detect github links: and recommend (maybe not all at once, but if they are many they can be delivered one per week\u0026hellip;.)\n adding a readme/license Revisit some old issues that haven\u0026rsquo;t been labeled To praise to new contributors To praise long term contributors To praise maintainers Add a CoC No CI detected! No style followed? Try this tool for this language! GH: @pep8speak \u0026hellip;    @rse_bot analyse!\n- Maybe some metric, e.g. “looking great”, “how about some more licencing” (needs to fit in the 280 Character limit (wow that’s a lot more than I thought!)    Share moral lessons and horror stories\n https://www5.in.tum.de/~huckle/bugse.html #horrorstories slack room links    Share motivational tweets and useful reminders - commit your code! Use a colleague as a rubber duckie. Check your contributing guidelines are up to date! Don’t forget to write a docstring for that method. It’s a feature, not a bug.\n  Today is a good day for writing a new test! #MondayMotivation #Testing\n  Updates about new open science tooling\n  Daily/weekly updates on test coverage\n  Reminders to write documentation / tests\n  Something along the lines of @CodeWisdom on Twitter https://twitter.com/CodeWisdom\n  Check how many/which Github issues are open and flag one up every so often\n Triage Tweets: Project y needs some help (based on issues)    A competition with other users, you get points for documentation, test coverage, … You can win a 1-2-1 chat with a real-life RSE to talk about your code!\n  Check if tools are unmaintained: @scipy we haven’t seen a commit recently, you alright?\n  Language month/week. Tweet about podcasts, resources, link to other tweet accounts of that particular language\n  Tip of the day\n  A help! Command to summon a real RSE (maybe it is a wizard…)\n  ","permalink":"https://robintw.github.io/CW-ideas/cw20-rse2_d2/","summary":"CW20 - 2020-03-31 to 2020-04-02 RSE2_D2 - CI10-CW20\nParticipants Yo Yehudi - Software dev and EngD student (Cambridge and Manchester)\nDavid Perez-Suarez - RSE at UCL\nBlair Archibald - 2017 fellow, Postdoc Glasgow (soft spot for Haskell)\nMarion Weinzierl - RSE at Durham University, Not a fellow\u0026hellip; yet!\nVahid Garousi - Belfast\n Context / Research Domain A long time ago, in an office far, far away, RSEs and researchers were developing software and may not be aware of all the good practices and are in need of a bit of motivation.","title":"RSE2_D2"},{"content":"CW21 - 2021-03-30 Charlie - CI3-CW21\nRunning a Dugnad in a research group Participants Please list the participants here\nSarah Gibson\nSarah Jaffa\nWarrick Ball\nNeil Chue Hong\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all of this hint text (Arial, italic, grey, size 11) once you no longer need it.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nAstrophysics (as a pilot for other areas with similar deepset culture issues)\nProblem Description of the problem you are trying to solve\nIn astrophysics, there are a lot of self-taught coders who are not being trained in practices that would make their lives easier, including software engineering, using tools like version control, reproducibility for yourself through continuous integration/analysis.\nCodes for astrophysics simulations are often built over many years, not documented or tested, with no structure for passing on knowledge - knowledge that is lost when people leave as accounts are deleted. This means the continuity of knowledge within a research group is lost.\nECRs recognise this, but people in power think it’s a timesink to encourage ECRs to pursue training in these topics. How can we get the decision makers on board? How do we get buy-in? Often evidence of impact is not enough on its own.\nWhat is needed are ways of improving group practices, that help a group lead and the members of the group. By emphasising the importance to the research group, it becomes easier to get buy-in. By making it social and communal, it helps improve group cohesion and identity.\nSolution Explanation of the solution to the problem you have identified\nRunning a Dugnad in a research group A dugnad is a Norwegian term for voluntary work done as a group, where a community comes together to collaborate on communal tasks. This is often accompanied by social aspects, such as a shared meal.\nWe propose running dugnads for research groups that bring together all group members to collectively undertake important research software tasks. More experienced members might tackle important software sustainability issues, while less experienced coders can learn from observing and discussing and still help the group by performing other ‘group admin’ tasks such as writing updates for the website, testing others code and giving feedback on ease of use from a novice perspective, or try some code challenges to improve their skills.\nBenefits of running at a group level:\n Group cohesion and sharing best practice Work from students and postdocs on short term contracts can be collated into a group repository and shared with others within the group, so knowledge and code is not lost when they move institutions or leave the field. Community standards can be shared so that work can be easily transferred between people in the group, new students can hit the ground running using specialised tools rather than reinventing the wheel every time (wastes time, more error prone). Research cohesion for the lead of the group Social aspect: becoming familiar with each other’s work, not feeling isolated with an issue  The outputs from a hackathon related to this idea would be:\n A set of example dugnads (see below for potential ideas) with agendas, potential tasks, and tips for how to make it fun/social Exemplars showing how these different dugnad types could be applied to astrophysics groups and beyond the domain An engagement and communication plan that describes how successful examples of dugnads that have been run could be disseminated to the community, to persuade them to run their own (e.g. incorporating as a chapter in the Turing Way)  Things that might happen at a successful Dugnad:\n Postdoc A and PhD student B both use an old F77 simulations code. Postdoc A has some scripts to make it easier to create input files, which, motivated by B, they document and add to the group repository. New PhD student Z sits with finishing PhD student Y and learns some basic version control skills. Latest results and project ideas can be added to the University or Group webpage to advertise to potential collaborators, hires and funders. Makes the group look more active. New postdoc B has joined from a slightly different research area but quickly survey’s the group’s public webpages and creates a list of changes to request from IT. PI notices that Postdoc C could use an obscure option in the F77 monster that would make it run a bit faster, though without changing scientific results (and hence they’d never discussed it before). The PI sees how amazing sustainable software practices are, even internally, and becomes evangelical. Someone found and fixed an obscure bug in an external code. More experienced Git users can help them learn how to push that back to the main repository so the developers and wider community benefit from the fix. Everyone can bring snacks and cake! Maybe have a cheese and biscuit day or encourage celebration of diverse backgrounds by asking everyone to bring a food from their hometown. A PhD student went on a Python course and learned to use a new library for fancy interactive plotting. They give a short demonstration and help other group members try it out on their own plots. A postdoc is about to release a new code and has written documentation. Other group members can try to install and use it following their documentation and point out where they get confused or any problems that crop up on different platforms.  Diagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nUnsplash reference: https://unsplash.com/photos/TdpSX7XAcKo\nLicence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-running-a-dugnad-in-rg/","summary":"CW21 - 2021-03-30 Charlie - CI3-CW21\nRunning a Dugnad in a research group Participants Please list the participants here\nSarah Gibson\nSarah Jaffa\nWarrick Ball\nNeil Chue Hong\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4.","title":"Running a dugnad in a research group"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Slack overflow: getting permanent docs from instant messaging - HP9-CW2CC\nHackday Idea Proposer ben krikler - mr.krikler@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Software projects where users and developers use instant messaging tools to support development and / or assist users.\nProblem Instant messaging platforms (slack, gitter, mattermost, etc) are great for providing instant support to users and connecting them with the developers as well as other users. A downside of this approach is that often a good response to a question can be lost in the sea of historic messages from users. How can we convert advice and examples produced on instant messaging services to long-term persisted documentation, in a simple and seamless way?\nSolution A tool that can pull a set of messages, and help or even automate the process of extracting the key points, code snippets, underlying question, and convert this into markdown that can be either posted as a github / gitlab issue or inserted into the documentation of the repository. This could include extracting tags to describe which functions or submodules are discussed, what version of the library was used, and so on.\nDiagrams / Illustrations /shrug (sorry, not sure what would be good here, maybe a slack logo plus a stack overflow logo ?)\n","permalink":"https://robintw.github.io/CW-ideas/cw19-docs-from-messaging/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Slack overflow: getting permanent docs from instant messaging - HP9-CW2CC\nHackday Idea Proposer ben krikler - mr.krikler@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Software projects where users and developers use instant messaging tools to support development and / or assist users.\nProblem Instant messaging platforms (slack, gitter, mattermost, etc) are great for providing instant support to users and connecting them with the developers as well as other users.","title":"Slack overflow: getting permanent docs from instant messaging"},{"content":"CW21 - 2021-03-30 Jasper - CI10-CW21\nParticipants  Morane Gruenpeter (Chair) Mario Antonioletti Emmy Tsang (Scribe) Esther Plomp   This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all of this hint text (Arial, italic, grey, size 11) once you no longer need it.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nSoftware citation videos (to understand why and how to make your software citable)\nProblem Description of the problem you are trying to solve\nPreliminary activity\n Mario: something visual is always very appealing, base it on a theme that has been running through the workshop, need to define the right skill set required when pitching the idea, (I have no definite idea)  For software citation - Stephan Druskat is a good person to talk to https://citation-file-format.github.io/ https://www.doodly.com/   Morane: citing software is still something that isn’t very spread * There are tools available and guidelines - but people are not very good at doing it consistently * https://codemeta.github.io/ * https://codemeta.github.io/create/ Esther: Getting recognition for contributions/career paths? Emmy: Effective and equitable storytelling. Very biased by podcast i listened to this morning + panel, but apparently it only takes 500ms for people to make up their minds about an image (hence dataviz is so important). We should stop writing. But what about people who can’t see? (that’s about the end of my chain of thoughts :p)  Tool developed by Sarthak Sehgal to add CFFs: https://github.com/sarthak-sehgal/software-citation (app is down unfortunately :( )    How should we encourage researchers to use mechanisms to cite software and have their research recognised?\nSolution Explanation of the solution to the problem you have identified\nCreate a set of bite-size videos to get people to cite people’s software, to get people to put a CFF file in their repos/releases - with the aim to promote increasing software citability and getting recognition for research software and RSEs\nYouTube videos.\n Why make your software citable How:  What tooling is available? What is a CFF file Creating CFF Creating codemeta.json BibTeX for software    Audience:\n Academic researcher/RSE that needs the credit to progress in their academic career  Script idea:\n Needs to be humanised: All the good stories have a real experience. Can we have a protagonist RSE that spent a lot of time on something and did not get recognition for it? Maybe this is too negative? Protagonist: researcher working very hard on their research, a major part of their work is creating software  Time is not well-invested in software because the credit is only given to academic papers - coding time is considered wasted and not recognised   Happy person in the end! Why make your software citable?  Potential recognition? Recognition for the time spent on working on their research software. Recognition for downstream dependencies should ideally be tied to recognition of the original piece of software Software must also be available for others to use - demonstrate the impact that it makes, be able to track that impact    Aim to finish a storyboard/script, even if we can’t produce these in 1-hr\n 3-min With a cartoon?  Skill sets needed:\n Artist \u0026amp; video designers a good “story developer” a narrator A Software citation expert  Scripts brainstorm\nMorane:\n“Researchers all over the world are writing papers to advance research and science, these papers are counted for credit and are the “only” way to go forward in an academic career”\n“At the same time, research is not only about writing results in papers, it is also about writing software to create or analyze results.”\n_“Time - how much time a researcher _\nEmmy:\n Protagonist: final year PhD student developing software for their research Antagonist: PI and thesis committee - “where’s your paper? Why are you spending all this time working on this software?” -\u0026gt; Stressed student, worried about their future and career, wanting to leave academia CFF comes to the rescue! WIth a CFF file, you can put in metadata about your software and allow others to easily cite your work Some collaborator of antagonist PI cited student’s software - PI is very pleased with increased impact. Protagonist is able to demonstrate that his software has been reused by 1000+ others around the world and promote CFFs and research software as proper research output to peers. Protagonist is happy.   Prototype based on Emmy’s script: https://youtu.be/6R1v1bYMhZU\nDiagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nLicence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-software-citation-videos/","summary":"CW21 - 2021-03-30 Jasper - CI10-CW21\nParticipants  Morane Gruenpeter (Chair) Mario Antonioletti Emmy Tsang (Scribe) Esther Plomp   This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all of this hint text (Arial, italic, grey, size 11) once you no longer need it.","title":"Software citation videos (to understand why and how to make your software citable)"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Software reporting guidelines - HP6-CW2CC\nHackday Idea Proposer Alexander Konovalov - alexander.konovalov@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Software credit\nProblem How to find out which research software is developed in an organisation?\nSolution Universities are using various information systems to record research outputs, mainly for REF purposes, for example:\n _Pure (St Andrews): https://www.st-andrews.ac.uk/staff/research/pure/ _ _RIS (Nottingham): https://www.nottingham.ac.uk/it-services/research/applications/ris.aspx _ _Simplectic (Leeds): https://library.leeds.ac.uk/info/14061/open_access/9/deposit_your_research_outputs_in_symplectic _  However, it is mainly research publications what is being regularly entered into these systems due to REF. Software outputs are not highly visible there. Moreover, public views of these databases highlight publications and possibly datasets (e.g. https://risweb.st-andrews.ac.uk/portal/en/) but require using the search interface to select only software outputs.\nWe would like to produce a set of recommendations (for example, as a blogpost or a series of pages, one per each system, with screenshots) for:\n Researchers developing and publishing research software (how to publish your software to have meaningful metadata to record) University database and research portal managers (to support software developers, and to increase software visibility in the portal) Developers of information systems (to create a specific template for software)  _We think of a bottom up approach: in each University, having sufficiently many software outputs recorded in the system, one could approach university database and research portal managers suggesting to make software easier discoverable on the research portal. At the same time, identify if there are any changes to made in the template for software outputs by the provider of the information system (Elsevier for Pure, etc.). If they will get sufficiently many demands to change it, they may do this with a higher priority. _\nIdeally a team should consist of at least one representatives of universities using each of the information systems, to be able to log in an explore the form for adding a new entry to the system.\nDiagrams / Illustrations This is an example how the most recent GAP release is represented in the Research Portal, which draws information from Pure. Please ask me to demonstrate the internal view of this record in Pure.\n","permalink":"https://robintw.github.io/CW-ideas/cw19-soft-reporting/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Software reporting guidelines - HP6-CW2CC\nHackday Idea Proposer Alexander Konovalov - alexander.konovalov@gmail.com\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Software credit\nProblem How to find out which research software is developed in an organisation?\nSolution Universities are using various information systems to record research outputs, mainly for REF purposes, for example:","title":"Software reporting guidelines"},{"content":"CW20 - 2020-03-31 to 2020-04-02 Idea 1 - CI1-CW20 - ‘State-of-the-Art’\nParticipants Dan Hobley\nPaddy McCann\nEmily Bell (chair)\nJonathan Frawley (scribe)\nReka Solymosi\nIain Barrass\n Context / Research Domain Meta-research: the context is a user doing a literature review for any research software project (\u0026lsquo;scientometrics\u0026rsquo;). We’re going to focus our proof-of-concept on speech to text research.\nProblem When starting a project on a topic outside current expertise, it can be difficult and time-consuming to ascertain the current state-of-the-art in terms of tools and techniques.\nExisting literature-search methods can be blunt instruments, and may over-weight long-standing methods (that could now be superseded) or methods employed extensively by one particular successful group. They can also be very time-consuming, especially for the non-specialist (e.g. an RSE reading science publications, and vice versa).\nGoogle scholar might be doing something like this when it ranks your searches, but the approach is very unclear. It also cannot separate out the tools from the publications using them.\nSolution Create a tool for end users (non-technical/technical) to be able to search for resources related to a topic of interest to get them started on learning more about it.\nThis tool will help get some sense of what is ‘state-of-the-art’ in an area that’s outside of your expertise, using well-cited papers and well-starred/used Github repositories (weighted by factors such as recency, broadness of uptake, number of contributors etc).\nIn the hackday we can build a proof of concept which will consist of a platform where users can search a topic, and be presented with an output of top papers, tools and techniques related to this topic. For the proof of concept this topic will be speech-to-text technology and our imagined target audience will be non-technical users. (For the purposes of the hackday, the searching may not be \u0026lsquo;live\u0026rsquo;.)\nThe idea is to use data from GitHub API (starring, forking, watching, downloads, etc. stats) and Google Scholar API (eg who’s citing what/when stats) and create a score while weighting also for \u0026lsquo;newness\u0026rsquo; and any other considerations to produce the top resources and present them back to the user. We would aim to build layers on top of this including expert reviews (not for the hackday but as a next step).\nWe also want to present the \u0026lsquo;score\u0026rsquo;, in a user-friendly way, with the aim to balance including as much detail about our methodology as possible with interpretability by a non-technical audience. (Rotten Tomatoes-style presentation?)\nFinally we want to consider the possible biases and other ethical considerations of our project, for example, is it going to result in promotion of established/well known tools and papers at the expense of new/emerging/innovative ones. Consider all possible issues/biases/implications and think about how they can be mitigated, and if they cannot, does this mean this tool should not exist? Documentation is also important to this, so there will be a read.me explaining weighting rationale and contributor guidelines.\nDiagrams / Illustrations  General Notes Daniel idea:\n Look at legacy research code and figure out how wrong it is Look at metrics such as how frequently it is updated, number of bugs, how quickly they are solved, etc. Figure out whether code that research is based on is wrong, and thus whether the conclusions hold up  Jonathan idea:\n Website which gives best tools and top research papers in particular field Goal would be to give someone new to a topic and idea of the state-of-the-art Maybe have voting system as well as looking number of citations, etc. Outcomes: state of the art papers \u0026amp; how do i get started with this the quickest way possible? Distinguish marketing material vs actually best resources (maybe reviews of the paid for services) Research papers v tools? Tools - python packages or large scale? Or anything? - can split by expertise of end user? And techniques and papers? What would the proof of concept look like?  Prototype of what we would want GitHub API (starring forking watching downloads etc stats) and Google Scholar API to automate (eg who’s citing what/when stats)   Aim of proof of concept: work out level of curation burden  Keyword search for idea, and pull themes from github and papers from scholar weighted by metrics (citations, forking, starring, etc) Q: how automatable is this? What are some issues/ biases?   Jonathan: Manual curation of reference codes maybe?  What’s our USP?: This tool will help get some sense of what is ‘state-of-the-art’ in an area that’s outside of your expertise, using well-cited papers and well-starred/used github repositories.\nFor proof of concept (hackday project):\n Topic: machine learning/ neural net/ whatever Jonathan’s project was Audience: non-technical people  Output: results alongside our \u0026lsquo;notes\u0026rsquo; of why we chose them (something rotten-tomatoes style where we show our method) - report on our metric\n","permalink":"https://robintw.github.io/CW-ideas/cw20-state-of-the-art/","summary":"CW20 - 2020-03-31 to 2020-04-02 Idea 1 - CI1-CW20 - ‘State-of-the-Art’\nParticipants Dan Hobley\nPaddy McCann\nEmily Bell (chair)\nJonathan Frawley (scribe)\nReka Solymosi\nIain Barrass\n Context / Research Domain Meta-research: the context is a user doing a literature review for any research software project (\u0026lsquo;scientometrics\u0026rsquo;). We’re going to focus our proof-of-concept on speech to text research.\nProblem When starting a project on a topic outside current expertise, it can be difficult and time-consuming to ascertain the current state-of-the-art in terms of tools and techniques.","title":"State of the Art"},{"content":"A CW20 - 2020-03-31 to 2020-04-02 Idea 9 - CI9-CW20: Storyboarding Sustainability\nParticipants Emma Rand\nMatthew West\nLaurence Brown\nMario Antonioletti\nAlison Clarke\n Context / Research Domain Many research domains where PIs may not have an awareness of reproducibility and sustainability best practice, may not consider it is relevant to their group or may not know where to start.\nProblem PIs are not always aware of the need to consider sustainability from the start of their project. They may be unable to reproduce data, e.g. reproducing figures which were created by a PhD student who has moved on. They may not build time into grants for ensuring sustainability/reproducibility. Alternatively, the PI is aware of gaps in their understanding and little idea of where to start addressing this problem.\nSolution We want to produce a storyboard/script for a 10 minute video which can be sent to PIs. The video will:\n Make the point that it applies to their research group Outline clear benefits of working sustainably Outline issues that arise by not doing so Suggest key questions they can ask their group members Signpost some fundamental small steps they can do quickly/easily Signpost training resources for their group members and for themselves.  The script and storyboard will be made available on GitHub so that groups or institutions can easily produce their own video. Ideally, it will be easily tailored to different domains, e.g. ‘hard’ sciences, social sciences, digital humanities.\nWe could ask our CW20 attendee colleagues for horror stories for non-sustainable approaches to give anecdotes.\nReferences  https://software.ac.uk/resources/guides-everything/software-evaluation-guide https://www.software.ac.uk/software-management-plans https://rdmtoolkit.jisc.ac.uk/manage-store-and-preserve/software/ https://www.openscapes.org/champions/ https://www.nature.com/articles/s41559-017-0160   Diagrams The Difference (https://www.xkcd.com/242/)\nNotes _Our ideas: _\n Multi uni. Issue: reform weekly telcom system. 15-10 people in a meeting, no fixed agenda, n minutes, no action items. Small team culture hasn’t scaled. Domination by one PI. how to change in a positive way. Technology change could be a catalyst for culture change. Overcoming resistance. Gaining senior allies. Lead by example - chair a meeting. FAIR principles of what constitutes good software. Not package-specific, more generic wrt technology and more specific to research context _ Produce a short 10-minute video stating the benefits of sustainability, reproducibility, targeting PIs and to show them how by doing this they can save time and money. Do it for research groups._ _Acronyms clashes between IT and domain. Create a curated list of acronyms to facilitate communication. Research for staff and students. Start computationally using ‘publications’ coming from the dept to identify the list of acronyms. Raises awareness on communicating across disciplines. _  _ Compelling media that articulates to PIs_\n That reproducibility and sustainability applies to their research group even if they don’t consider themselves creators of software It’s valuable wrt time to them It’s do-able for them Any step towards it is good; perfection not required. Find compelling examples that show the benefits of taking a sustainable approach towards doing reproducible research  ","permalink":"https://robintw.github.io/CW-ideas/cw20-storyboarding-sustainability/","summary":"A CW20 - 2020-03-31 to 2020-04-02 Idea 9 - CI9-CW20: Storyboarding Sustainability\nParticipants Emma Rand\nMatthew West\nLaurence Brown\nMario Antonioletti\nAlison Clarke\n Context / Research Domain Many research domains where PIs may not have an awareness of reproducibility and sustainability best practice, may not consider it is relevant to their group or may not know where to start.\nProblem PIs are not always aware of the need to consider sustainability from the start of their project.","title":"Storyboarding Sustainability"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Terminal History Sharing - HP3-CW2CC\nHackday Idea Proposer Jason Gates - jmgate@sandia.gov\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Training\nProblem When running in-person training classes that involve live coding, requiring participants to follow along with what the instructor is doing in a terminal on the screen and replicating that on their own machine, a common complaint is that the terminal input and output winds up scrolling off the top of the screen too soon. Participants can stop the class and ask the instructor to scroll back up so they can see what they missed, but they are often reluctant to do so for a variety of reasons. It would be ideal if all participants had the ability to scroll back through the instructor’s terminal input/output independently. In that way they would always have access to what they need to follow along and catch up, and the pace of the class is unhindered. Unfortunately there are no out-of-the-box solutions for this.\nDesign Specifications:\n Participants will not have login access to the instructor’s machine. Participants may not even be on the same network as the instructor’s machine. Participants should be able to scroll back up to the beginning of class at any time and see everything as it was displayed on the instructor’s screen. Bonus:  If we could implement the solution in such a way that a participant could toggle between viewing just the command line input vs input and output (i.e., “I just want to know what command to type”), that would be great.    Solution Here’s one solution, though there may be others out there. We should be able to do something along the lines of the following:\n At the beginning of a training session:  Redirect the terminals’ stdout and stderr both to the screen and to a file. Start a cron job running every second that:  Checks for an update to that file. If an update exists, commit it to a repository and push.   Have participants pull up this history file in a browser (GitHub, GitLab). Tell them anytime they want to look back in history they can refresh that page.   Continue the class as you normally would. Be sure to switch off that cron job when the class is over.  Diagrams / Illustrations Not applicable.\n","permalink":"https://robintw.github.io/CW-ideas/c19-termshare/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Terminal History Sharing - HP3-CW2CC\nHackday Idea Proposer Jason Gates - jmgate@sandia.gov\n This document should be used to capture the information for a Hack Day Idea.\nContext / Research Domain Training\nProblem When running in-person training classes that involve live coding, requiring participants to follow along with what the instructor is doing in a terminal on the screen and replicating that on their own machine, a common complaint is that the terminal input and output winds up scrolling off the top of the screen too soon.","title":"Terminal History Sharing"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 The Docutor button - CI18-CW2CC\nReporter Dan Hobley - dan.hobley@gmail.com\nParticipants Cerys Lewis, Connah Kendrick, Kirstie Whitaker, Adrian Castravete\nContext / Research Domain Documentation enhancement\nProblem In active projects, it’s very easy for documentation to get out of alignment with or superseded by subsequent code changes. Maintainers of open source projects are hugely overworked and underpaid, so even with the best will in the world, it’s very difficult for the experts who built the code and who wrote the original documentation to review it and catch any of the inconsistencies that appear over time.\nIn contrast, new users read the documentation very closely - it’s their welcome mat and guide to achieve the results they’re looking for. Many developers would like these users to update the documentation and fix these bugs themselves, but contributing to an open source project is often intimidating. New users may not know the expected workflow of opening an issue with the problem they’re having. Still more will feel presumptuous and worried about over burdening an already busy dev team.\nSolution Users look over and interact with the documentation much more than developers, and also see it with “fresh” eyes. So we propose an inline button within Sphinx to allow reporting via Github/Gitlab of where users think they have identified places where the documentation is unclear, contradictory, or confusing. The button will link to a partially pre-populated, standardised form where they can easily report the issue in a friendly manner. This system will be very low friction (e.g., no sign-ins)!\nAn example workflow, is that a user can hover over the subheading for the section of the documentation page that they’re reading and see a 🤔 icon. When they click the 🤔 button a popup box appears that asks 1) What did you think this section should do? 2) What are you experiencing? 3) Do you have a suggested change for this section of the documentation? It will also ask if they - optionally - would like to be tagged in a GitHub issue about this report. On submission an issue at the host github repository will be opened that will link to the file and the specific section that was out of date, report the information provided by the user, and tag them if appropriate. The standard text will be friendly and appreciative. We want all maintainers to feel loved when they receive these - incredibly helpful - reports of inconsistencies in their documentation.\nDiagrams / Illustrations ","permalink":"https://robintw.github.io/CW-ideas/cw19-docutor/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 The Docutor button - CI18-CW2CC\nReporter Dan Hobley - dan.hobley@gmail.com\nParticipants Cerys Lewis, Connah Kendrick, Kirstie Whitaker, Adrian Castravete\nContext / Research Domain Documentation enhancement\nProblem In active projects, it’s very easy for documentation to get out of alignment with or superseded by subsequent code changes. Maintainers of open source projects are hugely overworked and underpaid, so even with the best will in the world, it’s very difficult for the experts who built the code and who wrote the original documentation to review it and catch any of the inconsistencies that appear over time.","title":"The Docutor button"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 2: The Research Data Sandbox - CI7-CW2CC\nReporter Steve Crouch - s.crouch3000@gmail.com / All\nParticipants Sorrel Harriet, Melodee Beals, Lucia Michielin, Steve Crouch, Mosè Giordano\n Context / Research Domain General research data.\nProblem Many researchers who generate research data face a variety of issues with exposing that data to a wider audience including imposter syndrome or a general lack of confidence with \u0026lsquo;putting their data out there\u0026rsquo;. This might similarly apply to unpublished articles or ideas that have either been rejected or have not developed to the point that they are viable as research assets.\nAt the same time, there is a significant amount of value in negative results, unkempt datasets and unpublished analysis \u0026ndash; data that is lost or susceptible to unnecessary duplication of effort owing to a culture that rewards data hoarding and reputation sculpting and fails to reward honest documentation of methodological dead-ends and iterative and incremental improvement.\nSolution The Research Data Sandbox The Research Data Sandbox is a safe place to publish your research data \u0026ndash; perhaps anonymously \u0026ndash; to try things out, pitch ideas, determine levels of interest in the data, and \u0026ndash; most importantly \u0026ndash; attract suggestions for improvement.\nEthos: Foster a community that understands the importance of openness and that failure or incomplete knowledge is not something to fear\n Publishers may choose whether or not to publish anonymously. Reviewers may contribute suggestions; constructive criticism; edits etc. Reviewers cannot contribute anonymously, and there will be some system of ranking/discrimination according to the credentials/’upvotes’/affiliations of the individual  A space for narrative anecdotes (A Funny Thing Happened in the Lab) would be a welcome counter to the culture of “Quit Lit”, where “Academic Horror Stories” reinforce unhealthy perfectionism instead of fostering long-term growth and support through numerous development “failures”.\nPossible Expansions In the future, the further communities Sandboxes could develop around other research assets, such as methodologies, abstracts, research narratives, project case studies, and prose.\nDiagrams / Illustrations Image By Lucia Michielin\n","permalink":"https://robintw.github.io/CW-ideas/cw19-research-data-sandbox/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 2: The Research Data Sandbox - CI7-CW2CC\nReporter Steve Crouch - s.crouch3000@gmail.com / All\nParticipants Sorrel Harriet, Melodee Beals, Lucia Michielin, Steve Crouch, Mosè Giordano\n Context / Research Domain General research data.\nProblem Many researchers who generate research data face a variety of issues with exposing that data to a wider audience including imposter syndrome or a general lack of confidence with \u0026lsquo;putting their data out there\u0026rsquo;.","title":"The Research Data Sandbox"},{"content":"CW20 - 2020-03-31 to 2020-04-02 Remote Conferences and Collaboration: The Turing Way - CI5-CW20\nParticipants Sarah Gibson, Stephan Druskat, Louise Brown, Jurriaan H.Spaaks, Sam Mangham\n Context / Research Domain Issues on The Turing Way repository\nDue to the current COVID-19 crisis, remote work has become the default mode of working for most people in research, but it has also been common practice for different people and projects before that. How can we, working remotely, maintain the communities in this mode, and make sure that the community and the people involved in it remain healthy, and productive, and have all the information and technical support they need? In open source, this sort of remote work has been common. How can we disseminate the lessons learned in these communities to research groups and teams who are experiencing remote work, collaboration, teaching for the first time?\nProblem People may never have worked with any of the available collaboration tools, and may not have seen the necessity of using them. Those that are new to these workflows and tools may find it hard to find and access the available resources. Nevertheless they will need to find answers to questions such as “Are the tools we choose to run our events accessible across all platforms?”, “Do we exclude, e.g., Windows users by picking a particular video conferencing tool?”, “We miss the sociability of the coffee breaks, how can we simulate them?”, ”Are there different opportunities we gain from being remote?”, “How can we counter the dangers of being in a remote event, e.g., doing multiple things at once instead of just ‘being at the conference’?”\nSolution We describe considerations, workflows and tools for running remote activities for people that need to facilitate such an event but don’t have any previous experience. We would also like to capture things about CW20 that worked well for running future online conferences. In the course, we will describe which tools and features work well for which purpose, and other features (e.g., pricing, necessity to download, open/closed source). We also suggest solutions for more general issues, such as scheduling, and work modes suitable for online conferences (e.g., set your away message to be able to concentrate on the online event).\nOutcomeA subsection of a Turing Way chapter on running collaborative online events which describes the use case of running an online event with different requirements.\nStructure:\n Activity types / Use cases (Mix and match these to build your online event!) \\   workshop \\ hack event \\ poster session \\ prototyping/ideas session \\ presentations (including lightning talks) \\ pre-recorded presentations \\ panel sessions \\ async collaboration on a text \\ Tools for pair-programming  Requirements \\   breakout rooms \\ chat \\ video/audio (where can these be tested?) \\ VCS integration \\ live streaming \\ whiteboard \\ Recording tools for pre-recorded talks 1. Available tools \\ feature matrix \\  account needed? How can people join? \\ installation needed? \\   paid-for/free \\ open source 2. How to replicate/simulate the social aspects \\ Zoom backgrounds ;) \\ Virtual water cooler/coffee break \\ Virtual pub quizzes 3. Things you wouldn’t do in person but can do virtually \\ collaborative notetaking \\ pre-recording talks 4. Scheduling (may be an issue particular to online events because people will be in their own timezones, not all in one)  Diagrams / Illustrations Incomplete list of tools to discuss in the chapter\n Zoom Slack Git GitHub/GitLab MS Teams HackMD CryptPad Discord? Trello - can be linked to BitBucket ZenHub - GitHub integration (permissions issues) Easy to record? Presentation tools - Powerpoint? Binder?! Sli.do Mentimeter Live-share VSCode extension Eclipse plugin for pair programming Overleaf Jupyter Notebooks for interactive slideshows Tool for indicating remaining time to speakers VR (+ discord) for social sessions (the virtual pub!)  ","permalink":"https://robintw.github.io/CW-ideas/cw20-the-turing-way/","summary":"CW20 - 2020-03-31 to 2020-04-02 Remote Conferences and Collaboration: The Turing Way - CI5-CW20\nParticipants Sarah Gibson, Stephan Druskat, Louise Brown, Jurriaan H.Spaaks, Sam Mangham\n Context / Research Domain Issues on The Turing Way repository\nDue to the current COVID-19 crisis, remote work has become the default mode of working for most people in research, but it has also been common practice for different people and projects before that. How can we, working remotely, maintain the communities in this mode, and make sure that the community and the people involved in it remain healthy, and productive, and have all the information and technical support they need?","title":"The Turing Way"},{"content":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Hermann-1926 - HP11-CW21\nHack Day idea proposer **Louise Chisholm **\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nTools to recognise underlying software infrastructure visible \u0026amp; funded\nContext and/or research domain Please describe the context and/or research domain to which the problem applies\nResearch often relies on underlying software infrastructure, but their contribution is not recognised and it is difficult to attract funding to maintain software infrastructure.\nProblem Research often relies on underlying software infrastructure, but their contribution is not recognised and it is difficult to attract funding to maintain software infrastructure.\nBecause the contribution of this infrastructure is invisible, it is harder to lobby for funding from policy makers and funders. It is also lack of awareness of what the consequences could be to the wider community if XXX software infrastructure isn’t supported.\nSolution Develop a system or framework to recognise contributions of underlying research software (e.g. numpy) to research. This could be used in parallel to the systems that give credit to individuals.\nDiagrams / illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-tools-to-recognise-underlying-software-infrastructure-visible-and-funded/","summary":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Hermann-1926 - HP11-CW21\nHack Day idea proposer **Louise Chisholm **\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nTools to recognise underlying software infrastructure visible \u0026amp; funded","title":"Tools to recognise underlying software infrastructure visible and funded"},{"content":"CW21 - 2021-03-30 Asparagus - CI1-CW21\nParticipants  Jonathan Frawley / RSE, ARC, Durham University / e: jonathan.frawley@durham.ac.uk t: @df3n5 Gary Leeming / CDC University of Liverpool / gary.leeming@liverpool.ac.uk Jez Cope / Data Services Lead, The British Library, Yorkshire / j.cope@erambler.co.uk / he, him / w: eRambler tw: @jezcope ma: @petrichor@scholar.social gh\u0026amp;gl: jezcope Kirsty Pringle / SSI Project Manager / k.pringle@epcc.ed.ac.uk   Context / Research Domain Please describe the context or research domain to which the problem applies\nUser centred design principles for research apps / citizen science\nProblem Description of the problem you are trying to solve\nSocial science training is essential for designing effective questionnaires, information leaflets and other outputs designed for public consumption. In healthcare there is a similar discipline in public and patient involvement. However, there are no equivalent tools or widespread training in the usability of apps and websites, so software designed to collect data from non-specialists does not always work as intended and sometimes introduces unexpected bias. This can be a major issue in studies relying on citizen science or self-reported healthcare measures, for example.\nSolution Explanation of the solution to the problem you have identified\nThree overlapping parts to the solution:\n Resources: Create a resource of common design principles that can be published. Could be a chapter in The Turing Way, or a Carpentries-style workshop (or both). Tools: Creation and signposting of automated \u0026amp; semi-automated tools to support user centered design and identify potential problems in research instruments \u0026amp; methodologies. People: Build a network of people willing to test each other’s apps, instruments etc.  Diagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\nFor tools, we could develop a website to check how our app / website might be used by people with certain disabilities, e.g - a colour blindness simulator (screenshots from https://www.color-blindness.com/coblis-color-blindness-simulator/ 2021-03-31)\nLicence These materials (unless otherwise specified) are available under the Creative Commons Attribution 4.0 Licence. Please see the human-readable summary of the CC BY 4.0 and the full legal text for further information.\nFree-form notes from discussion  Use of health (and non-health) data in interesting ways, e.g. using bin data to identify frailty risks Catalog of algorithms used by e.g. traffic cameras to improve transparency and trust Sensor data, air quality, blank template for usability? Can’t make data available for health/imaging so can’t make work reproducible. Periodic testing of reproducibility of published software / projects Lots of beginner training for librarians and historians, e.g. library carpentry. But get to intermediate, and bringing into practice. Building peer support network. https://glamdatasci.network/ Opensafely.org  See also https://www.datashield.ac.uk/ (Rebecca Wilson works on this project)    ","permalink":"https://robintw.github.io/CW-ideas/cw21-user-centred-design-principles-for-research-apps/","summary":"CW21 - 2021-03-30 Asparagus - CI1-CW21\nParticipants  Jonathan Frawley / RSE, ARC, Durham University / e: jonathan.frawley@durham.ac.uk t: @df3n5 Gary Leeming / CDC University of Liverpool / gary.leeming@liverpool.ac.uk Jez Cope / Data Services Lead, The British Library, Yorkshire / j.cope@erambler.co.uk / he, him / w: eRambler tw: @jezcope ma: @petrichor@scholar.social gh\u0026amp;gl: jezcope Kirsty Pringle / SSI Project Manager / k.pringle@epcc.ed.ac.uk   Context / Research Domain Please describe the context or research domain to which the problem applies","title":"User centred design principles for research apps / citizen science"},{"content":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Lovelace-1842 - HP16-CW21\nHack Day idea proposer Becca Wilson Irma Hafidz Alison Clarke Talia Caplan Jannetta Steyn\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.\nUsing Raspberry Pis to deliver Carpentries training in remote locations\nContext and/or research domain Please describe the context and/or research domain to which the problem applies\nLow-to-Middle-Income Countries (LMICs) experience several challenges in building capacity of data analysis or software engineering skills that are necessary for contemporary data science. Several training programmes exist online, however these may not be easily accessible or in formats that can be utilised.\nProblem Description of the problem you are trying to solve\nSoftware and data carpentries courses provide training in fundamental data skills essential to conducting research. Training researchers in these data skills is an essential part of empowering researchers in LMICs. However, delivering these courses depends on reliable internet access. That means that individuals who are living in areas with unreliable internet access, quite literally cannot access this valuable training.\nSolution Explanation of the solution to the problem you have identified\nCreate an infrastructure using raspberry pis to deliver software and data carpentries offline and in remote areas. The idea is that a trainer could carry the devices to the training location, use keyboards/mice/displays that are already there, and easily set up a network that contains all the training materials, with no need for external internet access.\nThe materials would all be available on GitHub and licensed so that anyone could take the materials, set up their own network of Raspberry Pis, and deliver the Carpentries training courses.\nThe work could be broken down as follows:\n Identify components/overall structure of PI network, for example:  wifi access point - If access is possible, a mobile network APN can be used. If not a Raspberry Pi access point (eb. RaspAP) can be used to network several Pis. git server (gitlab/github?) - A server (on a Pi) to mimic access to GitHub and avoid the need for Internet access learning materials server - A server (on a Pi) with all necessary downloads and learning materials Workstations - Raspberry Pis to serve as workstations.   Identify and document the minimum hardware requirements. Create images to write to SD cards of Pis. Create ‘Train the trainer’-type materials: 5. How to set up Pi network. 6. How to run course. Create admin system for planning and running workshops: Organising workshops can be quite time consuming having to keep track of registrations, instructors, helpers, sending emails etc. Although specified within the scope of this proposal the system should be usable to any workshop organiser (online and offline). This work package is potentially a project on its own but should include at least the following: 7. An offline program (that could potentially synchronise with an online system) 8. Register an online workshop 9. Registration of learners 10. Keeping track of potential helpers and helpers allocated to a specified workshop 11. Keeping track of potential instructors and instructors allocated to a specified workshop 12. Keeping track of available hardware resources (how many Pis and what is installed on them) 13. Sending emails automatically to learners, instructors and helpers. 14. (This is the very beginning of a functional requirements document which will probably take up a lot of time and space!)  Diagrams / illustrations You can include diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n","permalink":"https://robintw.github.io/CW-ideas/cw21-using-raspberry-pis-to-deliver-carpentries-training-in-remote-locations/","summary":"CW21 Hack Day - 2021-03-31 to 2021-04-01 Lovelace-1842 - HP16-CW21\nHack Day idea proposer Becca Wilson Irma Hafidz Alison Clarke Talia Caplan Jannetta Steyn\n This document should be used to capture the information for a Hack Day Idea.\nIdea name (provisional) This is the provisional name of the Idea, solution or just a title; this can be changed later if a team is formed and you decide on a new team/product name.","title":"Using Raspberry Pis to deliver Carpentries training in remote locations"},{"content":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 6 - CI2-CW2CC\nReporter Raniere Silva - r.gaia.cs@gmail.com\nParticipants Patricia Herterich - @pherterich\nMichael Allaway\nAlessandro Felder\nDaina Bouquin - @dainabouquin\nLouise Brown - @louisepb\nRaniere Silva - @rgaiacs\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two). The document should be no larger than two pages of A4. Don’t delete the details at the top of the document but you should delete all the hint text once you no longer need it.\nContext / Research Domain Please describe the context or research domain to which the problem applies\nPhD students and earlier career researchers are updating their CV.\nProblem Description of the problem you are trying to solve\nDecide what to call your contribution to a open source software project is hard because roles are not well defined, except for author and maintainers. For example, someone might have contributed to improve the documentation in one project but the role of \u0026ldquo;technical writer\u0026rdquo; was never officially defined.\nSolution Explanation of the solution to the problem you have identified\n Extend Contributor Roles Taxonomy (CRediT), a high-level taxonomy to represent the roles typically played by contributors to scientific scholarly output, to have more meaningful terms related with software contribution. For example: technical writer, database designer, API designer, user interface designer, software developer. whatismycontributorrole.org to give advice to people of what their role in the project is. whatismycontributorrole.org would have as input the link a Git repository and user\u0026rsquo;s name and provide as output the recommendation of how people could list their contribution on their CV.  Diagrams / Illustrations You can include one or two diagrams in this section. Please ensure you have the right to use the image(s), and include an attribution if applicable.\n Notes:\n Create really good tombstones for things Do we need guidelines? Can contributor /authorship taxonomies help? (these are highly discipline specific) -\u0026gt; they can at least start a conversation Build a bot!! (the angry librarian) -\u0026gt; open standardised issues on GitHub repos:  You’re missing a citation file -\u0026gt; go here to read some good practice You’re missing a licence Create a branch opening “empty” PRs Have a conversation about authorship! Twittterbot: “Hey guys - I wanna give you credit. Could you please provide a citation file and a licence and anything else I need to do this properly.”   See yesterday’s discussion on crediting contributors https://docs.google.com/document/d/1bec5NVenHSGu2ER3vqJ90Zl4LaepbG7rj-lDe9IK684/edit  ","permalink":"https://robintw.github.io/CW-ideas/cw19-what-is-my-contribution/","summary":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Group 6 - CI2-CW2CC\nReporter Raniere Silva - r.gaia.cs@gmail.com\nParticipants Patricia Herterich - @pherterich\nMichael Allaway\nAlessandro Felder\nDaina Bouquin - @dainabouquin\nLouise Brown - @louisepb\nRaniere Silva - @rgaiacs\n This document should be used to capture the information for a Collaborative Session / Hack Day Idea. (The total amount of text should ideally be between 100-300 words and you can include a diagram or two).","title":"What is my contribution"}]