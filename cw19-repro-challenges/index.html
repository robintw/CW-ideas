<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Reproducibility and Collaboration Challenges in interactive / exploratory research | Collaborations Workshop Ideas & Pitches</title><meta name=keywords content><meta name=description content="Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Reproducibility and Collaboration Challenges in interactive / exploratory research
Reporter Adam Jackson - magicguy@gmail.com
Participants Dav Clark
Programmer / Evangelist at Gigantum.
Adam Jackson
Computational scientist / researcher (from pure PostDoc -> RSE). Produced code as part of research, mostly glue for expensive HPC.
Becky Arnold
_Astrophysics PhD at Sheffield. Worked on Turing Institute project. _
Ben Krikler
More of a user - particle physicist at CERN."><meta name=author content="Adam Jackson, Dav Clark, Adam Jackson, Becky Arnold, Ben Krikler, Joanna Leng"><link rel=canonical href=https://robintw.github.io/CW-ideas/cw19-repro-challenges/><link href=/CW-ideas/assets/css/stylesheet.min.1772ec3a76d63ef85d79195033eb07bd58a7847383ba54ca1a5143c8bf4f8265.css integrity="sha256-F3LsOnbWPvhdeRlQM+sHvVinhHODulTKGlFDyL9PgmU=" rel="preload stylesheet" as=style><link rel=icon href=https://robintw.github.io/CW-ideas/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://robintw.github.io/CW-ideas/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://robintw.github.io/CW-ideas/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://robintw.github.io/CW-ideas/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://robintw.github.io/CW-ideas/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.82.0"><meta property="og:title" content="Reproducibility and Collaboration Challenges in interactive / exploratory research"><meta property="og:description" content="Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Reproducibility and Collaboration Challenges in interactive / exploratory research
Reporter Adam Jackson - magicguy@gmail.com
Participants Dav Clark
Programmer / Evangelist at Gigantum.
Adam Jackson
Computational scientist / researcher (from pure PostDoc -> RSE). Produced code as part of research, mostly glue for expensive HPC.
Becky Arnold
_Astrophysics PhD at Sheffield. Worked on Turing Institute project. _
Ben Krikler
More of a user - particle physicist at CERN."><meta property="og:type" content="article"><meta property="og:url" content="https://robintw.github.io/CW-ideas/cw19-repro-challenges/"><meta property="article:section" content><meta property="og:site_name" content="Collaborations Workshop Ideas & Pitches"><meta name=twitter:card content="summary"><meta name=twitter:title content="Reproducibility and Collaboration Challenges in interactive / exploratory research"><meta name=twitter:description content="Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Reproducibility and Collaboration Challenges in interactive / exploratory research
Reporter Adam Jackson - magicguy@gmail.com
Participants Dav Clark
Programmer / Evangelist at Gigantum.
Adam Jackson
Computational scientist / researcher (from pure PostDoc -> RSE). Produced code as part of research, mostly glue for expensive HPC.
Becky Arnold
_Astrophysics PhD at Sheffield. Worked on Turing Institute project. _
Ben Krikler
More of a user - particle physicist at CERN."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Reproducibility and Collaboration Challenges in interactive / exploratory research","item":"https://robintw.github.io/CW-ideas/cw19-repro-challenges/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Reproducibility and Collaboration Challenges in interactive / exploratory research","name":"Reproducibility and Collaboration Challenges in interactive \/ exploratory research","description":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Reproducibility and Collaboration Challenges in interactive / exploratory research\nReporter Adam Jackson - magicguy@gmail.com\nParticipants Dav Clark\nProgrammer / Evangelist at Gigantum.\nAdam Jackson\nComputational scientist / researcher (from pure PostDoc -\u0026gt; RSE). Produced code as part of research, mostly glue for expensive HPC.\nBecky Arnold\n_Astrophysics PhD at Sheffield. Worked on Turing Institute project. _\nBen Krikler\nMore of a user - particle physicist at CERN.","keywords":[],"articleBody":"Collaborations Workshop 2019 (CW19) #CollabW19 2019-04-01 to 2019-04-03 Reproducibility and Collaboration Challenges in interactive / exploratory research\nReporter Adam Jackson - magicguy@gmail.com\nParticipants Dav Clark\nProgrammer / Evangelist at Gigantum.\nAdam Jackson\nComputational scientist / researcher (from pure PostDoc - RSE). Produced code as part of research, mostly glue for expensive HPC.\nBecky Arnold\n_Astrophysics PhD at Sheffield. Worked on Turing Institute project. _\nBen Krikler\nMore of a user - particle physicist at CERN. Cluster-based computing. Often exploratory, determine appropriate distributions, features, etc. Python - more Jupyter, using Binder for interactive reporting (though not for sharing back very much).\n“Data gravity” is a problem? Data replication with URI is a solution used there. Some increase in sharing software.\nJoanna Leng\nC++ enthusiast. EPSRC (UK org) RSE fellow. Works with physicists on imaging data, recently with sociologists. Also works at Diamond Light Source - funding for soft matter microscopy vs. hard matter. Is working across modalities, which leads to desired common software base.\nNotes from the discussion NOT for inclusion in blog One concern (Dav+Joanna): enabling collaboration between diverse skillsets (e.g. sociology + RSE).\nProblematising current RSE title - maybe needs to be differentiated more, allowing for different kinds of roles.\nFunding for tools that are useful outside of one grant.\nAlso concern about losing true expertise. Faculties are being reduced and integrated - using same tools. Tension between disciplinary boundaries vs. fluid interdisciplinarity.\nMinimizing lines of explanation about the exploratory process (e.g., “this didn’t converge, so we nudged it”).Conversion of programs to a literate product. More on the post-processing (not the expensive stuff).\nConcern about cache hanging around in notebooks.\nInteractive / exploratory visualization.\nChris Woods (from Bristol) about future of Cloud computing - shifting HPC to the cloud. Ben is working on this as well. Working with Oracle for cluster in the cloud. Enables doing viz while computation is happening. Concern about user support for Cloud.\nHow could we do bursty exploratory analysis? Probably leads to under-utilization of system. Maybe if you have a set of expected potential outcomes you can code this a little more efficiently.\nTopics\n Rapid Human QA / Viz  e.g., well-designed plots for brain imaging 3D plots are hard to do any way except interactive Infinite set of ways that things can be wrong - human visual system is so fancy Hypothesis generation - concerns about automated data cleaning   Understanding outputs of complex, automated analyses  Understanding machine learning for separation of examples - what has the algorithm done?   Transparency / Reproducibility  Version control everything Restricted data (esp. for reproducibility) Capture computational environment  Containers are hard to design without knowing what data will be used, what will be persisted   Git all the time, changelog? Capturing meaningful points in time?   Scaling from locally tested to scaled-up/out, etc.  Data portability Data restrictions Availability / cost of compute     Speed Blog Please use the area below to draft the speed blog. Consult https://www.software.ac.uk/speed-blogging-and-tips-writing-one for information, tips and examples.\n At the Software Sustainability Institute’s 2019 Collaborations Workshop, many discussions for the speed-blogging session focused on deposit of relatively fixed data and analysis code. Our group noted that there is value in reproducibility across the research process - e.g., in facilitating collaboration within a team, or even portability across compute environments within a lab. Moreover, it is well documented that even basic computational reproducibility with the same code and data remains a challenge. Baking in concerns about reproducibility starting at the earliest explorations could increase the number of projects that are genuinely reproducible and amenable to extension and further exploration. Below we highlight key topics and include example suggestions, practices, and tools that can facilitate reproducibility and collaboration from the start of the research project.\nReproducibility/transparency\nExploratory research often treads a winding path, circling back on itself and running into dead ends. This presents a barrier to reproducibility as it makes it difficult to track backwards from the final conclusions of a research output and the path of code/results/hypothesis that lead to them.\nMaking extensive use of a version control tool such as Git can be a big step towards mitigating/eliminating this problem. By using atomic commits (committing each small unit of work to version control) with a detailed commit message explaining why the step was taken can allow others (or your future self) to “retrace your steps”.\nAnother important step for making research reproducible is to capture the computational environment it was conducted in as the behaviour of software can change depending on it environment. In research this translated to the same piece of code generating different results on different computers- i.e. the result will be irreproducible. There are a number of ways of capturing computational environments, all of which have their own strengths and weaknesses. Containers offer possibly the most “complete” or fully-controlled approach to replication, but present a steep learning curve. Further they can be inflexible if, after further exploratory research, the environment needs to be changed, for example by adding another piece of software.\nAnother barrier to reproducible research is when the research involves working with confidential information such as medical or commercially sensitive data. In cases like these, full anonymisation of results may be difficult and laborious, making it undesirable to apply to every step of the research process. This skirts the boundaries of open research and reproducible research. Research can be reproduced far more widely if it is open, but reproducible research does not necessarily have to be open. Even if only those with clearance to access the information are able to reproduce it, the research is still reproducible. As such it is good practice to carefully document and version control all steps of the research process, even if those cannot be shared. Working reproducibly has a myriad of benefits for research quality even if the research cannot be shared.\nInteractive exploratory research presents another barrier to reproducibility. Say a researcher generates a 3D plot, interacts with it, spins it around, and comes to a conclusion, then that process and what that researcher exactly saw can be difficult to reproduce. This is an example of why it is so important for researchers to take extensive and detailed notes.\nPortability and Subsetting of data\nExploratory work will often be performed with relatively “raw” data, which in turn can involve large files and mixed formats. In the early stages of a study it may not be clear how high-quality or noisy the data is, or indeed what is relevant to later outcomes. As a result, some of the best-practices for reproducible research (“upload everything with human- and machine-readable metadata to somewhere as available and immutable as possible”) become more cumbersome or even technically or economically infeasible.\nDuring an interactive process we want to access and process data quickly, which generally means working with a local copy. It is not generally practical (or even permissible) to upload all of the data that was even considered for analysis, which means a curation/pruning step is needed to present a reproducible environment. Containers are an emerging and powerful tool for robust well-defined computational processes, but the technology is led with a focus on web applications. The run-time environment of a container is destroyed when the container is stopped, and best-practices around durable data persistence are not well defined. For example, bind-mounts may incur a large performance penalty (especially on Windows or macOS) but at the same time, they provide easy persistence and accessibility.\nThe results is that separate protocols are needed for making data available to a container session, and also for extracting and persisting useful outputs. There seems to be a conflict between the design to make sessions independent and predictable, and the desire to freely explore while logging the progress (a conflict that is similarly expressed in the problems of invisible state persisting between Jupyter cell executions)\n.\nPortability and Easy Configurability of Compute\nMobility of compute is defined by Greg Kurtzer in his paper describing Singularity. The basic idea is that compared to the bits required to describe your data, the bits required to describe your computational steps are typically far fewer - and therefore more portable. A challenge arises due to the dramatic differences between some compute contexts. For example:\n file systems differ, including distributed networks; different compute architectures may be available: multi-core, GPU, other accelerators  (In some cases, libraries (e.g. linear algebra) may need to be compiled specifically for an architecture and may have even have different semantics); and   different modes of interaction may be required, e.g. desktop vs. batch systems.  So, while in theory container approaches like Docker or Singularity “solve” the challenge of portability of compute, there are many details that remain to be addressed.\nWe are aware of a variety of approaches to addressing these remaining challenges. The approach adopted by Gigantum is to reduce cognitive load and streamline standardized strategies. E.g., by defining a dataset which may be attached to a compute project, and which can intelligently fetch only needed data for local tyre-kicking, and provides sensible descriptors for data location on an HPC system. Another class of approaches is to define an API that intelligently maps onto a variety of back end compute architectures. For example, Dask reproduces a subset of numpy and pandas APIs that work on distributed clusters (cf. Spark, etc.), libraries like PyTorch flexibly work across CPU and GPU, and the PARSL library provides annotations that allow users to inform the runtime of what functions can be run in parallel.\nEven having solved these technical challenges, most strategies are still going to require a modest amount of “dev ops” sophistication. Docker can be cumbersome, designing good requirements files for package installation requires a balance between hard requirements and flexibility of working across versions of needed packages. While many voices in reproducible research advocate for training and practices, there remains a clear place for innovation in tools. For example, the repo2docker project provides a set of standard approaches that will reliably support a binder instance that can be inspected by anyone. Tools like Gigantum take this further by automating Git and providing a UI around things like package management and Dockerfile generation and execution.\nRapid Human Quality Assurance / Visualisation\nExploratory data analysis and visualisation is the process of iteratively improving your understanding of the underlying data and physical processes in order to respond to a particular research question.\nIt occurs in two possible research processes, either in incremental research when an existing research approach and work flow is being slightly updated or tested on relatively similar, but new, data; or in disruptive research when a completely new approach to the experiment or analysis is used.\nIn incremental research, one normally has an understanding of what to expect, and open-ended exploration will only kick in when an anomaly is observed. Being able to compare the anomaly to a previous result, or using a simulated or parameterised model can help understand how the anomaly has occurred. Alternatively, variation of the analysis workflow can allow the researcher to test several different hypothesis for what has produced the anomaly. In both cases, getting new updated results quickly and keeping them organised is important to identify what has gone wrong.\nIn a disruptive approach, however, there is some expectation as to what the data will show but the approach needs to be open to spotting problems. Often in this case the research question itself might evolve, as will the analysis workflow, since it is difficult to predict before starting the research process what will be the best approach to answer the research question.\nSummary\nThe contributors to this post widely agreed on the clear challenges for computational reproducibility, and how these challenges are exacerbated by the demands of interactive and exploratory work. Our suggestions range from training and practices for manually tracking activity and computational environments to near-complete automation in an integrated graphical environment. We look forward to hearing from others in the larger conversation as we proceed to improve the state of reproducibility and collaboration across the entire research lifecycle!\n","wordCount":"1998","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":[{"@type":"Person","name":"Adam Jackson"},{"@type":"Person","name":"Dav Clark"},{"@type":"Person","name":"Adam Jackson"},{"@type":"Person","name":"Becky Arnold"},{"@type":"Person","name":"Ben Krikler"},{"@type":"Person","name":"Joanna Leng"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://robintw.github.io/CW-ideas/cw19-repro-challenges/"},"publisher":{"@type":"Organization","name":"Collaborations Workshop Ideas \u0026 Pitches","logo":{"@type":"ImageObject","url":"https://robintw.github.io/CW-ideas/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://robintw.github.io/CW-ideas/ accesskey=h title="Collaborations Workshop Ideas & Pitches (Alt + H)">Collaborations Workshop Ideas & Pitches</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu onscroll=menu_on_scroll()><li><a href=https://robintw.github.io/CW-ideas/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://robintw.github.io/CW-ideas/byyear/ title="By year"><span>By year</span></a></li><li><a href=https://robintw.github.io/CW-ideas/bytype/ title="By type"><span>By type</span></a></li><li><a href=https://robintw.github.io/CW-ideas/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://robintw.github.io/CW-ideas/>Home</a></div><h1 class=post-title>Reproducibility and Collaboration Challenges in interactive / exploratory research</h1><div class=post-meta>10 min&nbsp;·&nbsp;Adam Jackson, Dav Clark, Adam Jackson, Becky Arnold, Ben Krikler, Joanna Leng
|&nbsp;<a href=https://github.com/robintw/CW-ideas/blob/ideas//cw19-repro-challenges.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><h3 id=collaborations-workshop-2019-cw19-collabw19-----2019-04-01to-2019-04-03>Collaborations Workshop 2019 (CW19) #CollabW19          2019-04-01 to 2019-04-03<a hidden class=anchor aria-hidden=true href=#collaborations-workshop-2019-cw19-collabw19-----2019-04-01to-2019-04-03>#</a></h3><p>Reproducibility and Collaboration Challenges in interactive / exploratory research</p><h3 id=reporter><strong>Reporter</strong><a hidden class=anchor aria-hidden=true href=#reporter>#</a></h3><p>Adam Jackson - <a href=mailto:magicguy@gmail.com>magicguy@gmail.com</a></p><h3 id=participants><strong>Participants</strong><a hidden class=anchor aria-hidden=true href=#participants>#</a></h3><p><strong><em>Dav Clark</em></strong></p><p><em>Programmer / Evangelist at <a href=https://gigantum.com/>Gigantum</a>.</em></p><p><strong><em>Adam Jackson</em></strong></p><p><em>Computational scientist / researcher (from pure PostDoc -> RSE). Produced code as part of research, mostly glue for expensive HPC.</em></p><p><strong><em>Becky Arnold</em></strong></p><p>_Astrophysics PhD at Sheffield. Worked on <a href=https://www.turing.ac.uk/>Turing Institute</a> project. _</p><p><strong><em>Ben Krikler</em></strong></p><p><em>More of a user - particle physicist at CERN. Cluster-based computing. Often exploratory, determine appropriate distributions, features, etc. Python - more Jupyter, using Binder for interactive reporting (though not for sharing back very much).</em></p><p><em>“Data gravity” is a problem? Data replication with URI is a solution used there. Some increase in sharing software.</em></p><p><strong><em>Joanna Leng</em></strong></p><p><em>C++ enthusiast. EPSRC (UK org) RSE fellow. Works with physicists on imaging data, recently with sociologists. Also works at Diamond Light Source - funding for soft matter microscopy vs. hard matter. Is working across modalities, which leads to desired common software base.</em></p><h3 id=notes-from-the-discussion-not-for-inclusion-in-blog><strong>Notes from the discussion NOT for inclu</strong>sion in blog<a hidden class=anchor aria-hidden=true href=#notes-from-the-discussion-not-for-inclusion-in-blog>#</a></h3><p><em>One concern (Dav+Joanna): enabling collaboration between diverse skillsets (e.g. sociology + RSE).</em></p><p><em>Problematising current RSE title - maybe needs to be differentiated more, allowing for different kinds of roles.</em></p><p><em>Funding for tools that are useful outside of one grant.</em></p><p><em>Also concern about losing true expertise. Faculties are being reduced and integrated - using same tools. Tension between disciplinary boundaries vs. fluid interdisciplinarity.</em></p><p><em>Minimizing lines of explanation about the exploratory process (e.g., “this didn’t converge, so we nudged it”).Conversion of programs to a literate product. More on the post-processing (not the expensive stuff).</em></p><p><em>Concern about cache hanging around in notebooks.</em></p><p><em>Interactive / exploratory visualization.</em></p><p><em>Chris Woods (from Bristol) about future of Cloud computing -> shifting HPC to the cloud. Ben is working on this as well. Working with Oracle for cluster in the cloud. Enables doing viz while computation is happening. Concern about user support for Cloud.</em></p><p><em>How could we do bursty exploratory analysis? Probably leads to under-utilization of system. Maybe if you have a set of expected potential outcomes you can code this a little more efficiently.</em></p><p><strong><em>Topics</em></strong></p><ul><li><em>Rapid Human QA / Viz</em><ul><li><em>e.g., well-designed plots for brain imaging</em></li><li><em>3D plots are hard to do any way except interactive</em></li><li><em>Infinite set of ways that things can be wrong - human visual system is so fancy</em></li><li><em>Hypothesis generation - concerns about automated data cleaning</em></li></ul></li><li><em>Understanding outputs of complex, automated analyses</em><ul><li><em>Understanding machine learning for separation of examples - what has the algorithm done?</em></li></ul></li><li><em>Transparency / Reproducibility</em><ul><li><em>Version control everything</em></li><li><em>Restricted data (esp. for reproducibility)</em></li><li><em>Capture computational environment</em><ul><li><em>Containers are hard to design without knowing what data will be used, what will be persisted</em></li></ul></li><li><em>Git all the time, changelog? Capturing meaningful points in time?</em></li></ul></li><li><em>Scaling from locally tested to scaled-up/out, etc.</em><ul><li><em>Data portability</em></li><li><em>Data restrictions</em></li><li><em>Availability / cost of compute</em></li></ul></li></ul><hr><h3 id=speed-blog><strong>Speed Blog</strong><a hidden class=anchor aria-hidden=true href=#speed-blog>#</a></h3><p><em>Please use the area below to draft the speed blog. Consult <a href="https://www.google.com/url?q=https://www.software.ac.uk/speed-blogging-and-tips-writing-one&sa=D&ust=1554127339457000">https://www.software.ac.uk/speed-blogging-and-tips-writing-one</a> for information, tips and examples.</em></p><hr><p>At the Software Sustainability Institute’s 2019 Collaborations Workshop, many discussions for the speed-blogging session focused on deposit of relatively fixed data and analysis code. Our group noted that there is value in reproducibility across the research process - e.g., in facilitating collaboration within a team, or even portability across compute environments within a lab. Moreover, it is well documented that even basic computational reproducibility with the same code and data remains a challenge. Baking in concerns about reproducibility starting at the earliest explorations could increase the number of projects that are genuinely reproducible and amenable to extension and further exploration. Below we highlight key topics and include example suggestions, practices, and tools that can facilitate reproducibility and collaboration from the start of the research project.</p><p><strong>Reproducibility/transparency</strong></p><p>Exploratory research often treads a winding path, circling back on itself and running into dead ends. This presents a barrier to reproducibility as it makes it difficult to track backwards from the final conclusions of a research output and the path of code/results/hypothesis that lead to them.</p><p>Making extensive use of a version control tool such as <a href=https://git-scm.com/>Git</a> can be a big step towards mitigating/eliminating this problem. By using atomic commits (committing each small unit of work to version control) with a detailed commit message explaining why the step was taken can allow others (or your future self) to “retrace your steps”.</p><p>Another important step for making research reproducible is to capture the computational environment it was conducted in as the behaviour of software can change depending on it environment. In research this translated to the same piece of code generating different results on different computers- i.e. the result will be irreproducible. There are a number of ways of capturing computational environments, all of which have their own strengths and weaknesses. Containers offer possibly the most “complete” or fully-controlled approach to replication, but present a steep learning curve. Further they can be inflexible if, after further exploratory research, the environment needs to be changed, for example by adding another piece of software.</p><p>Another barrier to reproducible research is when the research involves working with confidential information such as medical or commercially sensitive data. In cases like these, full anonymisation of results may be difficult and laborious, making it undesirable to apply to every step of the research process. This skirts the boundaries of open research and reproducible research. Research can be reproduced far more widely if it is open, but reproducible research does not <em>necessarily</em> have to be open. Even if only those with clearance to access the information are able to reproduce it, the research is still reproducible. As such it is good practice to carefully document and version control all steps of the research process, even if those cannot be shared. Working reproducibly has a myriad of benefits for research quality even if the research cannot be shared.</p><p>Interactive exploratory research presents another barrier to reproducibility. Say a researcher generates a 3D plot, interacts with it, spins it around, and comes to a conclusion, then that process and what that researcher exactly saw can be difficult to reproduce. This is an example of why it is so important for researchers to take extensive and detailed notes.</p><p><strong>Portability and Subsetting of data</strong></p><p>Exploratory work will often be performed with relatively “raw” data, which in turn can involve large files and mixed formats. In the early stages of a study it may not be clear how high-quality or noisy the data is, or indeed what is relevant to later outcomes. As a result, some of the best-practices for reproducible research (<em>“upload everything with human- and machine-readable metadata to somewhere as available and immutable as possible”</em>) become more cumbersome or even technically or economically infeasible.</p><p>During an interactive process we want to access and process data quickly, which generally means working with a local copy. It is not generally practical (or even permissible) to upload all of the data that was even considered for analysis, which means a curation/pruning step is needed to present a reproducible environment. Containers are an emerging and powerful tool for robust well-defined computational processes, but the technology is led with a focus on web applications. The run-time environment of a container is destroyed when the container is stopped, and best-practices around durable data persistence are not well defined. For example, bind-mounts may incur a large performance penalty (especially on Windows or macOS) but at the same time, they provide easy persistence and accessibility.</p><p>The results is that separate protocols are needed for making data available to a container session, and also for extracting and persisting useful outputs. There seems to be a conflict between the design to make sessions independent and predictable, and the desire to freely explore while logging the progress (a conflict that is similarly expressed in the problems of invisible state persisting between Jupyter cell executions)</p><p>.</p><p><strong>Portability and Easy Configurability of Compute</strong></p><p>Mobility of compute is defined by Greg Kurtzer in <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0177459">his paper describing Singularity</a>. The basic idea is that compared to the bits required to describe your data, the bits required to describe your computational steps are typically far fewer - and therefore more portable. A challenge arises due to the dramatic differences between some compute contexts. For example:</p><ul><li>file systems differ, including distributed networks;</li><li>different compute architectures may be available: multi-core, GPU, other accelerators<ul><li>(In some cases, libraries (e.g. linear algebra) may need to be compiled specifically for an architecture and may have even have different semantics); and</li></ul></li><li>different modes of interaction may be required, e.g. desktop vs. batch systems.</li></ul><p>So, while in theory container approaches like Docker or Singularity “solve” the challenge of portability of compute, there are many details that remain to be addressed.</p><p>We are aware of a variety of approaches to addressing these remaining challenges. The approach adopted by Gigantum is to reduce cognitive load and streamline standardized strategies. E.g., by defining a dataset which may be attached to a compute project, and which can intelligently fetch only needed data for local tyre-kicking, and provides sensible descriptors for data location on an HPC system. Another class of approaches is to define an API that intelligently maps onto a variety of back end compute architectures. For example, Dask reproduces a subset of numpy and pandas APIs that work on distributed clusters (cf. Spark, etc.), libraries like PyTorch flexibly work across CPU and GPU, and the PARSL library provides annotations that allow users to inform the runtime of what functions can be run in parallel.</p><p>Even having solved these technical challenges, most strategies are still going to require a modest amount of “dev ops” sophistication. Docker can be cumbersome, designing good requirements files for package installation requires a balance between hard requirements and flexibility of working across versions of needed packages. While many voices in reproducible research advocate for training and practices, there remains a clear place for innovation in tools. For example, the repo2docker project provides a set of standard approaches that will reliably support a binder instance that can be inspected by anyone. Tools like Gigantum take this further by automating Git and providing a UI around things like package management and Dockerfile generation and execution.</p><p><strong>Rapid Human Quality Assurance / Visualisation</strong></p><p>Exploratory data analysis and visualisation is the process of iteratively improving your understanding of the underlying data and physical processes in order to respond to a particular research question.</p><p>It occurs in two possible research processes, either in incremental research when an existing research approach and work flow is being slightly updated or tested on relatively similar, but new, data; or in disruptive research when a completely new approach to the experiment or analysis is used.</p><p>In incremental research, one normally has an understanding of what to expect, and open-ended exploration will only kick in when an anomaly is observed. Being able to compare the anomaly to a previous result, or using a simulated or parameterised model can help understand how the anomaly has occurred. Alternatively, variation of the analysis workflow can allow the researcher to test several different hypothesis for what has produced the anomaly. In both cases, getting new updated results quickly and keeping them organised is important to identify what has gone wrong.</p><p>In a disruptive approach, however, there is some expectation as to what the data will show but the approach needs to be open to spotting problems. Often in this case the research question itself might evolve, as will the analysis workflow, since it is difficult to predict before starting the research process what will be the best approach to answer the research question.</p><p><strong>Summary</strong></p><p>The contributors to this post widely agreed on the clear challenges for computational reproducibility, and how these challenges are exacerbated by the demands of interactive and exploratory work. Our suggestions range from training and practices for manually tracking activity and computational environments to near-complete automation in an integrated graphical environment. We look forward to hearing from others in the larger conversation as we proceed to improve the state of reproducibility and collaboration across the entire research lifecycle!</p></div><footer class=post-footer><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Reproducibility and Collaboration Challenges in interactive / exploratory research on twitter" href="https://twitter.com/intent/tweet/?text=Reproducibility%20and%20Collaboration%20Challenges%20in%20interactive%20%2f%20exploratory%20research&url=https%3a%2f%2frobintw.github.io%2fCW-ideas%2fcw19-repro-challenges%2f&hashtags="><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Reproducibility and Collaboration Challenges in interactive / exploratory research on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2frobintw.github.io%2fCW-ideas%2fcw19-repro-challenges%2f&title=Reproducibility%20and%20Collaboration%20Challenges%20in%20interactive%20%2f%20exploratory%20research&summary=Reproducibility%20and%20Collaboration%20Challenges%20in%20interactive%20%2f%20exploratory%20research&source=https%3a%2f%2frobintw.github.io%2fCW-ideas%2fcw19-repro-challenges%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Reproducibility and Collaboration Challenges in interactive / exploratory research on reddit" href="https://reddit.com/submit?url=https%3a%2f%2frobintw.github.io%2fCW-ideas%2fcw19-repro-challenges%2f&title=Reproducibility%20and%20Collaboration%20Challenges%20in%20interactive%20%2f%20exploratory%20research"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Reproducibility and Collaboration Challenges in interactive / exploratory research on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frobintw.github.io%2fCW-ideas%2fcw19-repro-challenges%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Reproducibility and Collaboration Challenges in interactive / exploratory research on whatsapp" href="https://api.whatsapp.com/send?text=Reproducibility%20and%20Collaboration%20Challenges%20in%20interactive%20%2f%20exploratory%20research%20-%20https%3a%2f%2frobintw.github.io%2fCW-ideas%2fcw19-repro-challenges%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Reproducibility and Collaboration Challenges in interactive / exploratory research on telegram" href="https://telegram.me/share/url?text=Reproducibility%20and%20Collaboration%20Challenges%20in%20interactive%20%2f%20exploratory%20research&url=https%3a%2f%2frobintw.github.io%2fCW-ideas%2fcw19-repro-challenges%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2021 <a href=https://robintw.github.io/CW-ideas/>Collaborations Workshop Ideas & Pitches</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=/CW-ideas/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><script>window.onload=function(){localStorage.getItem("menu-scroll-position")&&(document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position"))};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft)}document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>